#!/usr/bin/env python3
"""
YourTTS HTTP æœåŠ¡ï¼ˆZero-shot TTSï¼‰

ç”¨äºä» Rust ä»£ç è°ƒç”¨ YourTTS æ¨¡å‹è¿›è¡Œè¯­éŸ³åˆæˆï¼Œæ”¯æŒéŸ³è‰²å…‹éš†ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python yourtts_service.py [--gpu] [--port PORT] [--host HOST]

å‚æ•°ï¼š
    --gpu: ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    --port: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š5004ï¼‰
    --host: æœåŠ¡åœ°å€ï¼ˆé»˜è®¤ï¼š127.0.0.1ï¼‰

API ç«¯ç‚¹ï¼š
    POST /synthesize
    Body: {
        "text": "è¦åˆæˆçš„æ–‡æœ¬",
        "reference_audio": [0.1, 0.2, ...],  # å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼Œç”¨äºéŸ³è‰²å…‹éš†ï¼‰
        "language": "zh"  # è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
    }
    Response: {
        "audio": [0.1, 0.2, ...],  # åˆæˆçš„éŸ³é¢‘æ•°æ®ï¼ˆf32ï¼‰
        "sample_rate": 22050
    }
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from flask import Flask, request, jsonify
import numpy as np
import torch
import base64
import tempfile
import soundfile as sf
from scipy import signal
import requests

app = Flask(__name__)
tts_model = None
device = None

# Speaker ç¼“å­˜ï¼šå­˜å‚¨ speaker_id -> reference_audio çš„æ˜ å°„
# æ ¼å¼ï¼š{speaker_id: {"reference_audio": np.ndarray, "sample_rate": int, "voice_embedding": np.ndarray}}
speaker_cache = {}

# çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤ speaker_cache çš„å¹¶å‘è®¿é—®
import threading
speaker_cache_lock = threading.Lock()

def get_device(use_gpu=False):
    """è·å–è®¡ç®—è®¾å¤‡"""
    if use_gpu:
        if torch.cuda.is_available():
            device = "cuda"
            print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
            print(f"   CUDA version: {torch.version.cuda}")
            print(f"   PyTorch version: {torch.__version__}")
        else:
            device = "cpu"
            print("âš ï¸  GPU requested but not available, using CPU")
            print("   Check:")
            print("   1. NVIDIA drivers installed in WSL")
            print("   2. CUDA toolkit installed in WSL")
            print("   3. PyTorch with CUDA support installed")
            print("   4. Run 'nvidia-smi' in WSL to verify GPU access")
    else:
        device = "cpu"
        print("â„¹ï¸  Using CPU (GPU not requested)")
    return device

def check_and_install_tts():
    """æ£€æŸ¥å¹¶å®‰è£… TTS æ¨¡å—"""
    try:
        import TTS
        return True
    except ImportError:
        print("âš ï¸  TTS module not found. Attempting to install...")
        try:
            import subprocess
            import sys
            subprocess.check_call([sys.executable, "-m", "pip", "install", "TTS"])
            print("âœ… TTS module installed successfully")
            return True
        except Exception as e:
            print(f"âŒ Failed to install TTS module: {e}")
            print("\nPlease install manually:")
            print("  pip install TTS")
            return False

def extract_voice_info(audio_array, label="Audio"):
    """æå–éŸ³é¢‘çš„éŸ³è‰²ä¿¡æ¯ï¼ˆé€šè¿‡ Speaker Embedding æœåŠ¡ï¼‰"""
    try:
        # å°è¯•è°ƒç”¨ Speaker Embedding æœåŠ¡
        speaker_embedding_url = "http://127.0.0.1:5003/extract"
        
        # å‡†å¤‡è¯·æ±‚æ•°æ®
        request_data = {
            "audio": audio_array.tolist(),
            "sample_rate": 16000
        }
        
        try:
            response = requests.post(
                speaker_embedding_url,
                json=request_data,
                timeout=5.0
            )
            
            if response.status_code == 200:
                result = response.json()
                embedding = np.array(result.get("embedding", []))
                stats = result.get("stats", {})
                
                if len(embedding) > 0:
                    print(f"[YourTTS Service] ğŸ¤ {label} Voice Info:")
                    print(f"   Embedding dimension: {len(embedding)}")
                    print(f"   Norm (L2): {stats.get('norm', np.linalg.norm(embedding)):.4f}")
                    print(f"   Mean: {stats.get('mean', np.mean(embedding)):.6f}, Std: {stats.get('std', np.std(embedding)):.6f}")
                    print(f"   Range: [{stats.get('min', np.min(embedding)):.6f}, {stats.get('max', np.max(embedding)):.6f}]")
                    print(f"   Abs Mean: {stats.get('abs_mean', np.mean(np.abs(embedding))):.6f}")
                    
                    return {
                        "embedding": embedding,
                        "stats": stats,
                        "available": True
                    }
        except (requests.exceptions.RequestException, Exception) as e:
            print(f"[YourTTS Service] âš ï¸  Could not extract voice info from Speaker Embedding service: {e}")
            
    except Exception as e:
        print(f"[YourTTS Service] âš ï¸  Error extracting voice info: {e}")
    
    # å¦‚æœæ— æ³•è·å– embeddingï¼Œè‡³å°‘æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
    audio_array_np = np.array(audio_array, dtype=np.float32)
    basic_stats = {
        "mean": float(np.mean(audio_array_np)),
        "std": float(np.std(audio_array_np)),
        "min": float(np.min(audio_array_np)),
        "max": float(np.max(audio_array_np)),
        "rms": float(np.sqrt(np.mean(audio_array_np ** 2)))
    }
    
    print(f"[YourTTS Service] ğŸ¤ {label} Basic Audio Stats:")
    print(f"   RMS: {basic_stats['rms']:.6f}")
    print(f"   Mean: {basic_stats['mean']:.6f}, Std: {basic_stats['std']:.6f}")
    print(f"   Range: [{basic_stats['min']:.6f}, {basic_stats['max']:.6f}]")
    
    return {
        "embedding": None,
        "stats": basic_stats,
        "available": False
    }

def _get_default_speaker(tts_model):
    """è·å–é»˜è®¤è¯´è¯è€…"""
    try:
        # æ–¹æ³•1ï¼šæ£€æŸ¥ tts_model.speakers å±æ€§
        if hasattr(tts_model, 'speakers') and tts_model.speakers:
            if isinstance(tts_model.speakers, list) and len(tts_model.speakers) > 0:
                return tts_model.speakers[0]
            elif isinstance(tts_model.speakers, dict) and len(tts_model.speakers) > 0:
                return list(tts_model.speakers.keys())[0]
        # æ–¹æ³•2ï¼šæ£€æŸ¥ speaker_manager
        if hasattr(tts_model, 'speaker_manager'):
            if hasattr(tts_model.speaker_manager, 'speaker_names') and tts_model.speaker_manager.speaker_names:
                return tts_model.speaker_manager.speaker_names[0]
            elif hasattr(tts_model.speaker_manager, 'speakers') and tts_model.speaker_manager.speakers:
                if isinstance(tts_model.speaker_manager.speakers, list) and len(tts_model.speaker_manager.speakers) > 0:
                    return tts_model.speaker_manager.speakers[0]
                elif isinstance(tts_model.speaker_manager.speakers, dict) and len(tts_model.speaker_manager.speakers) > 0:
                    return list(tts_model.speaker_manager.speakers.keys())[0]
    except Exception as e:
        print(f"Warning: Could not get default speaker: {e}")
    return None

def load_model(model_path, device="cpu"):
    """åŠ è½½ YourTTS æ¨¡å‹"""
    global tts_model
    
    # æ£€æŸ¥å¹¶å®‰è£… TTS æ¨¡å—
    if not check_and_install_tts():
        raise ImportError("TTS module is required but not available")
    
    try:
        from TTS.api import TTS
        
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found at {model_path}")
        
        print(f"ğŸ“ Loading YourTTS model from: {model_path}")
        print(f"ğŸ”§ Device: {device}")
        
        # YourTTS æ¨¡å‹è·¯å¾„
        # æ³¨æ„ï¼šTTS API å¯èƒ½éœ€è¦æ¨¡å‹åç§°è€Œä¸æ˜¯è·¯å¾„
        # å¦‚æœç›´æ¥ä½¿ç”¨è·¯å¾„ï¼Œå¯èƒ½éœ€è¦è‡ªå®šä¹‰åŠ è½½
        
        # æ–¹å¼1ï¼šä½¿ç”¨ TTS APIï¼ˆå¦‚æœæ¨¡å‹å·²æ³¨å†Œï¼‰
        try:
            # å°è¯•ä½¿ç”¨æ¨¡å‹è·¯å¾„
            tts_model = TTS(model_path=str(model_path), progress_bar=False, gpu=(device == "cuda"))
            print("âœ… YourTTS model loaded via TTS API")
        except:
            # æ–¹å¼2ï¼šç›´æ¥åŠ è½½æ¨¡å‹æ–‡ä»¶
            # éœ€è¦æ ¹æ® YourTTS çš„å®é™…åŠ è½½æ–¹å¼è°ƒæ•´
            print("âš ï¸  TTS API loading failed, trying direct load...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ model.pth
            model_file = model_path / "model.pth"
            if model_file.exists():
                # è¿™é‡Œéœ€è¦æ ¹æ® YourTTS çš„å®é™…ç»“æ„åŠ è½½
                # æš‚æ—¶ä½¿ç”¨ TTS API çš„å¤‡ç”¨æ–¹å¼ï¼Œå¹¶æŒ‡å®š GPU
                tts_model = TTS("tts_models/multilingual/multi-dataset/your_tts", gpu=(device == "cuda"))
                print("âœ… YourTTS model loaded (using default model)")
            else:
                raise FileNotFoundError(f"Model file not found: {model_file}")
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆå¦‚æœ TTS API æ²¡æœ‰è‡ªåŠ¨å¤„ç†ï¼‰
        if hasattr(tts_model, 'to') and device == "cuda":
            try:
                tts_model = tts_model.to(device)
                print(f"âœ… Model moved to {device}")
            except Exception as e:
                print(f"âš ï¸  Warning: Failed to move model to {device}: {e}")
                print("   Model may still work on CPU")
        
        print(f"âœ… YourTTS model loaded successfully")
        print(f"   Device: {device}")
        print(f"   Supports zero-shot: Yes")
        
        return tts_model
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    with speaker_cache_lock:
        cache_size = len(speaker_cache)
    return jsonify({
        "status": "ok",
        "model_loaded": tts_model is not None,
        "device": device,
        "cached_speakers": cache_size
    })

@app.route('/register_speaker', methods=['POST'])
def register_speaker():
    """æ³¨å†Œè¯´è¯è€…ï¼ˆå¼‚æ­¥æ¥æ”¶ reference_audioï¼‰
    
    å½“è¯†åˆ«åˆ°æ–°è¯´è¯è€…æ—¶ï¼Œå¼‚æ­¥è°ƒç”¨æ­¤ç«¯ç‚¹æ³¨å†Œå…¶ reference_audioã€‚
    åç»­åˆæˆè¯·æ±‚åªéœ€ä¼ é€’ speaker_id å³å¯ä½¿ç”¨ç¼“å­˜çš„ reference_audioã€‚
    
    Request Body:
        {
            "speaker_id": "speaker_123",
            "reference_audio": [0.1, 0.2, ...],  # å‚è€ƒéŸ³é¢‘ï¼ˆf32 æ•°ç»„ï¼‰
            "reference_sample_rate": 16000,  # å‚è€ƒéŸ³é¢‘é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000 Hzï¼‰
            "voice_embedding": [0.1, 0.2, ...]  # å¯é€‰ï¼ŒéŸ³è‰²embeddingï¼ˆç”¨äºéªŒè¯ï¼‰
        }
    
    Response:
        {
            "status": "ok",
            "speaker_id": "speaker_123",
            "message": "Speaker registered successfully"
        }
    """
    try:
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        speaker_id = data.get('speaker_id')
        if not speaker_id:
            return jsonify({"error": "Missing 'speaker_id' field"}), 400
        
        reference_audio = data.get('reference_audio')
        if not reference_audio:
            return jsonify({"error": "Missing 'reference_audio' field"}), 400
        
        reference_sample_rate = data.get('reference_sample_rate', 16000)
        voice_embedding = data.get('voice_embedding')  # å¯é€‰
        
        # å°†å‚è€ƒéŸ³é¢‘è½¬æ¢ä¸º numpy æ•°ç»„
        ref_audio_array = np.array(reference_audio, dtype=np.float32)
        
        # YourTTS éœ€è¦ 22050 Hz çš„å‚è€ƒéŸ³é¢‘ï¼Œé¢„å…ˆé‡é‡‡æ ·
        target_sample_rate = 22050
        if reference_sample_rate != target_sample_rate:
            num_samples = int(len(ref_audio_array) * target_sample_rate / reference_sample_rate)
            ref_audio_array = signal.resample(ref_audio_array, num_samples)
            print(f"[YourTTS Service] Resampled reference audio from {reference_sample_rate} Hz to {target_sample_rate} Hz for speaker {speaker_id}")
        
        # ä¿å­˜ voice_embeddingï¼ˆå¦‚æœæä¾›ï¼‰
        embedding_array = None
        if voice_embedding:
            embedding_array = np.array(voice_embedding, dtype=np.float32)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        with speaker_cache_lock:
            speaker_cache[speaker_id] = {
                "reference_audio": ref_audio_array,
                "sample_rate": target_sample_rate,
                "voice_embedding": embedding_array
            }
            cache_size = len(speaker_cache)
        
        print(f"[YourTTS Service] âœ… Registered speaker '{speaker_id}' (reference_audio: {len(ref_audio_array)} samples @ {target_sample_rate} Hz, cache size: {cache_size})")
        
        return jsonify({
            "status": "ok",
            "speaker_id": speaker_id,
            "message": "Speaker registered successfully",
            "cache_size": cache_size
        })
    
    except Exception as e:
        print(f"[YourTTS Service] âŒ Failed to register speaker: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/synthesize', methods=['POST'])
def synthesize():
    """è¯­éŸ³åˆæˆï¼ˆæ”¯æŒ zero-shotï¼‰"""
    try:
        # å…ˆéªŒè¯è¾“å…¥ï¼Œå†æ£€æŸ¥æ¨¡å‹
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        if 'text' not in data:
            return jsonify({"error": "Missing 'text' field"}), 400
        
        text = data['text']
        speaker_id = data.get('speaker_id')  # å¯é€‰ï¼Œè¯´è¯è€…IDï¼ˆç”¨äºæŸ¥æ‰¾ç¼“å­˜çš„ reference_audioï¼‰
        reference_audio = data.get('reference_audio')  # å¯é€‰ï¼ˆå¦‚æœæ²¡æœ‰æä¾› speaker_idï¼‰
        reference_sample_rate = data.get('reference_sample_rate', 16000)  # å‚è€ƒéŸ³é¢‘é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000 Hzï¼‰
        voice_embedding = data.get('voice_embedding')  # å¯é€‰ï¼Œè¯´è¯è€…éŸ³è‰²embeddingï¼ˆä¼˜å…ˆä½¿ç”¨ï¼Œé¿å…æŸ¥è¯¢æœåŠ¡ï¼‰
        speaker = data.get('speaker')  # å¯é€‰ï¼Œè¯´è¯è€…åç§°ï¼ˆå½“æ²¡æœ‰ reference_audio æ—¶ä½¿ç”¨ï¼‰
        language = data.get('language', 'zh')  # é»˜è®¤ä¸­æ–‡
        speech_rate = data.get('speech_rate')  # å¯é€‰ï¼Œè¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰ï¼Œç”¨äºè°ƒæ•´åˆæˆé€Ÿåº¦
        
        # è®°å½•è¯­é€Ÿå‚æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if speech_rate is not None:
            print(f"[YourTTS Service] ğŸ“Š Received speech_rate parameter: {speech_rate:.2} chars/s")
        else:
            print(f"[YourTTS Service] ğŸ“Š No speech_rate parameter provided (will use default/normal rate)")
        
        # éªŒè¯æ–‡æœ¬
        if not text or len(text.strip()) == 0:
            return jsonify({"error": "Empty text"}), 400
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
        if tts_model is None:
            return jsonify({"error": "Model not loaded"}), 500
        
        # å‡†å¤‡å‚è€ƒéŸ³é¢‘ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æä¾›çš„ï¼‰
        speaker_wav = None
        cached_ref_audio = None
        cached_sample_rate = None
        
        # å¦‚æœæä¾›äº† speaker_idï¼Œå°è¯•ä»ç¼“å­˜ä¸­è·å– reference_audio
        if speaker_id:
            with speaker_cache_lock:
                cached_entry = speaker_cache.get(speaker_id)
                if cached_entry:
                    cached_ref_audio = cached_entry["reference_audio"]
                    cached_sample_rate = cached_entry["sample_rate"]
                    print(f"[YourTTS Service] âœ… Using cached reference_audio for speaker_id '{speaker_id}' ({len(cached_ref_audio)} samples @ {cached_sample_rate} Hz)")
                else:
                    print(f"[YourTTS Service] âš ï¸  Speaker_id '{speaker_id}' not found in cache yet (async registration may be in progress)")
                    print(f"[YourTTS Service]    Will use default voice for now (synthesis won't wait for async registration)")
        
        # ç¡®å®šä½¿ç”¨å“ªä¸ª reference_audio
        use_cached = cached_ref_audio is not None
        ref_audio_to_use = cached_ref_audio if use_cached else reference_audio
        ref_sample_rate_to_use = cached_sample_rate if use_cached else reference_sample_rate
        
        try:
            if ref_audio_to_use is not None:
                # å°†å‚è€ƒéŸ³é¢‘è½¬æ¢ä¸º numpy æ•°ç»„
                if use_cached:
                    # ä½¿ç”¨ç¼“å­˜çš„å‚è€ƒéŸ³é¢‘ï¼ˆå·²ç»é‡é‡‡æ ·åˆ° 22050 Hzï¼‰
                    ref_audio_array = ref_audio_to_use
                else:
                    # ä½¿ç”¨æä¾›çš„å‚è€ƒéŸ³é¢‘ï¼ˆéœ€è¦é‡é‡‡æ ·ï¼‰
                    ref_audio_array = np.array(ref_audio_to_use, dtype=np.float32)
                
                # YourTTS éœ€è¦ 22050 Hz çš„å‚è€ƒéŸ³é¢‘
                target_sample_rate = 22050
                
                # å¦‚æœä½¿ç”¨ç¼“å­˜çš„å‚è€ƒéŸ³é¢‘ï¼Œå·²ç»é‡é‡‡æ ·è¿‡äº†
                # å¦‚æœä½¿ç”¨æä¾›çš„å‚è€ƒéŸ³é¢‘ï¼Œéœ€è¦é‡é‡‡æ ·
                if not use_cached:
                    if ref_sample_rate_to_use != target_sample_rate:
                        print(f"[YourTTS Service] Resampling reference audio from {ref_sample_rate_to_use} Hz to {target_sample_rate} Hz")
                        num_samples = int(len(ref_audio_array) * target_sample_rate / ref_sample_rate_to_use)
                        ref_audio_array = signal.resample(ref_audio_array, num_samples)
                        print(f"[YourTTS Service] Resampled: {len(ref_audio_to_use)} samples -> {len(ref_audio_array)} samples")
                    else:
                        print(f"[YourTTS Service] Reference audio sample rate matches target ({target_sample_rate} Hz)")
                else:
                    # ä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘ï¼Œæ— éœ€é‡å¤è¾“å‡ºä¿¡æ¯ï¼ˆå·²åœ¨ä¸Šé¢è¾“å‡ºï¼‰
                    pass
                
                # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼ˆYourTTS éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œç¡®ä¿åœ¨ Windows ä¸Šä¹Ÿèƒ½æ­£ç¡®æ¸…ç†
                tmp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                tmp_file.close()  # å…³é—­æ–‡ä»¶å¥æŸ„ï¼Œé¿å… Windows é”å®šé—®é¢˜
                try:
                    sf.write(tmp_file.name, ref_audio_array, target_sample_rate)
                    speaker_wav = tmp_file.name
                    print(f"[YourTTS Service] âœ… Reference audio saved to temp file: {speaker_wav} ({len(ref_audio_array)} samples @ {target_sample_rate} Hz)")
                except Exception as e:
                    # å¦‚æœå†™å…¥å¤±è´¥ï¼Œæ¸…ç†æ–‡ä»¶
                    if os.path.exists(tmp_file.name):
                        os.unlink(tmp_file.name)
                    raise
            
            # åˆæˆè¯­éŸ³
            # YourTTS API ä½¿ç”¨æ–¹å¼
            if speaker_wav:
                # Zero-shot æ¨¡å¼ï¼šä½¿ç”¨å‚è€ƒéŸ³é¢‘
                # è®°å½•ä½¿ç”¨çš„ reference_audio æ¥æºï¼ˆç®€åŒ–æ—¥å¿—ï¼Œé¿å…é‡å¤ï¼‰
                if use_cached:
                    print(f"[YourTTS Service] ğŸ¤ Synthesizing with cached reference_audio (speaker_id: '{speaker_id}', {len(ref_audio_array)} samples)")
                else:
                    print(f"[YourTTS Service] ğŸ¤ Synthesizing with provided reference_audio ({len(ref_audio_array)} samples @ {target_sample_rate} Hz)")
                
                wav = tts_model.tts(
                    text=text,
                    speaker_wav=speaker_wav,  # ä½¿ç”¨å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼ˆæ¨¡å‹å†…éƒ¨ä¼šæå– embedding ç”¨äºåˆæˆï¼‰
                    language=language
                )
                print(f"[YourTTS Service] âœ… Synthesis completed, output: {len(wav)} samples")
            elif speaker:
                # ä½¿ç”¨æŒ‡å®šçš„è¯´è¯è€…ï¼ˆä» voice å­—æ®µä¼ é€’è¿‡æ¥ï¼‰
                # æ³¨æ„ï¼šspeaker å‚æ•°åº”è¯¥æ˜¯ YourTTS æ¨¡å‹æ”¯æŒçš„è¯´è¯è€…åç§°
                # å¦‚æœä¼ é€’çš„æ˜¯ voice IDï¼ˆå¦‚ "zh_CN-huayan-medium"ï¼‰ï¼Œéœ€è¦æ˜ å°„åˆ° YourTTS çš„ speaker
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå…ˆå°è¯•ä½¿ç”¨ä¼ é€’çš„ speaker å€¼ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤è¯´è¯è€…
                print(f"[YourTTS Service] âš ï¸  Using predefined speaker '{speaker}' (NOT using reference_audio for voice cloning)")
                default_speaker = _get_default_speaker(tts_model)
                try:
                    wav = tts_model.tts(
                        text=text,
                        speaker=speaker,
                        language=language
                    )
                    print(f"[YourTTS Service] âœ… Synthesis completed with predefined speaker '{speaker}' (default voice, no voice cloning)")
                except Exception as e:
                    # å¦‚æœæŒ‡å®šçš„ speaker ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è¯´è¯è€…
                    print(f"[YourTTS Service] âš ï¸  Warning: Speaker '{speaker}' not found, using default speaker: {e}")
                    if default_speaker:
                        wav = tts_model.tts(
                            text=text,
                            speaker=default_speaker,
                            language=language
                        )
                        print(f"[YourTTS Service] âœ… Synthesis completed with default speaker '{default_speaker}' (default voice, no voice cloning)")
                    else:
                        raise ValueError(f"Speaker '{speaker}' not found and no default speaker available. Error: {e}")
            else:
                # é»˜è®¤æ¨¡å¼ï¼šæ²¡æœ‰ reference_audioï¼Œä¹Ÿæ²¡æœ‰ speaker_idï¼Œä¹Ÿæ²¡æœ‰ speaker å‚æ•°
                # å¦‚æœæä¾›äº† speaker_id ä½†ç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä¹Ÿèµ°è¿™é‡Œï¼ˆä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼‰
                default_speaker = _get_default_speaker(tts_model)
                if speaker_id:
                    print(f"[YourTTS Service] âš ï¸  Speaker_id '{speaker_id}' not yet registered in cache, using default voice")
                    print(f"[YourTTS Service] âš ï¸  NOT using reference_audio - voice cloning NOT applied (fallback to default voice)")
                else:
                    print(f"[YourTTS Service] âš ï¸  WARNING: No reference audio and no speaker specified, using default speaker")
                    print(f"[YourTTS Service] âš ï¸  NOT using reference_audio - voice cloning NOT applied (using default voice)")
                if default_speaker:
                    # ä½¿ç”¨é»˜è®¤è¯´è¯è€…
                    wav = tts_model.tts(
                        text=text,
                        speaker=default_speaker,
                        language=language
                    )
                    print(f"[YourTTS Service] âœ… Synthesis completed with default speaker '{default_speaker}' (default voice, no voice cloning)")
                else:
                    # å¦‚æœæ²¡æœ‰å¯ç”¨çš„è¯´è¯è€…ï¼Œè¿”å›é”™è¯¯
                    raise ValueError(
                        "YourTTS is a multi-speaker model. Please provide either:\n"
                        "1. A reference audio (reference_audio parameter) for zero-shot voice cloning, or\n"
                        "2. A speaker name (speaker parameter), or\n"
                        "3. Ensure the model has speaker configurations available."
                    )
            
            # å¦‚æœæä¾›äº†è¯­é€Ÿå‚æ•°ï¼Œè°ƒæ•´éŸ³é¢‘é€Ÿåº¦ï¼ˆåœ¨æ‰€æœ‰åˆæˆè·¯å¾„ä¹‹åç»Ÿä¸€å¤„ç†ï¼‰
            if speech_rate is not None:
                print(f"[YourTTS Service] ğŸ¯ Processing speech_rate adjustment: {speech_rate:.2} chars/s")
                # è®¡ç®—ç›®æ ‡è¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰
                # æ­£å¸¸è¯­é€Ÿå¤§çº¦æ˜¯ 4-6 å­—ç¬¦/ç§’ï¼ˆä¸­æ–‡ï¼‰æˆ– 10-15 å­—ç¬¦/ç§’ï¼ˆè‹±æ–‡ï¼‰
                # å¦‚æœ speech_rate ä¸æ­£å¸¸è¯­é€Ÿä¸åŒï¼Œéœ€è¦è°ƒæ•´éŸ³é¢‘é€Ÿåº¦
                # ä¼˜å…ˆä½¿ç”¨ librosa è¿›è¡Œæ—¶é—´æ‹‰ä¼¸ï¼ˆä¿æŒéŸ³è°ƒï¼‰ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ scipy é‡é‡‡æ ·
                use_librosa = False
                use_scipy = False
                
                try:
                    import librosa
                    use_librosa = True
                except ImportError:
                    # librosa ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨ scipy
                    try:
                        # scipy å·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
                        use_scipy = True
                    except ImportError:
                        print(f"[YourTTS Service] âš ï¸  Warning: Neither librosa nor scipy available, cannot adjust speech rate. Install with: pip install librosa")
                
                if use_librosa or use_scipy:
                    try:
                        # ç¡®ä¿ wav æ˜¯ numpy.ndarray ç±»å‹ï¼Œå¹¶è½¬æ¢ä¸º float64
                        # librosa.effects.time_stretch éœ€è¦ float64 ç±»å‹ï¼ˆnumba ç¼–è¯‘çš„å‡½æ•°ä¸æ”¯æŒ float32ï¼‰
                        if isinstance(wav, torch.Tensor):
                            # ä» Tensor è½¬æ¢ä¸º numpyï¼Œç›´æ¥è½¬æ¢ä¸º float64
                            wav_np = wav.cpu().numpy().astype(np.float64)
                        elif isinstance(wav, np.ndarray):
                            # ç¡®ä¿æ˜¯ float64 ç±»å‹
                            wav_np = wav.astype(np.float64)
                        elif isinstance(wav, list):
                            # ä»åˆ—è¡¨åˆ›å»ºï¼Œç›´æ¥ä½¿ç”¨ float64
                            wav_np = np.array(wav, dtype=np.float64)
                        else:
                            # å°è¯•è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œä½¿ç”¨ float64
                            wav_np = np.array(wav, dtype=np.float64)
                        
                        # ç¡®ä¿æ˜¯ä¸€ç»´æ•°ç»„
                        if wav_np.ndim > 1:
                            wav_np = wav_np.flatten()
                        
                        # å†æ¬¡ç¡®ä¿æ˜¯ float64ï¼ˆé˜²æ­¢ä¹‹å‰çš„è½¬æ¢å¤±è´¥ï¼‰
                        if wav_np.dtype != np.float64:
                            print(f"[YourTTS Service] âš ï¸  Warning: wav_np dtype is {wav_np.dtype}, converting to float64")
                            wav_np = wav_np.astype(np.float64)
                        
                        # éªŒè¯ç±»å‹
                        if wav_np.dtype != np.float64:
                            raise ValueError(f"Failed to convert audio to float64, current dtype: {wav_np.dtype}")
                        
                        # è®¡ç®—é€Ÿåº¦å› å­
                        # é‡è¦ï¼šspeech_rate æ˜¯åŸºäºå‚è€ƒéŸ³é¢‘è®¡ç®—çš„ï¼Œå¯èƒ½åŒ…å«åœé¡¿æ—¶é—´
                        # éœ€è¦æ ¹æ®ç›®æ ‡è¯­è¨€å’Œç›®æ ‡æ–‡æœ¬é•¿åº¦è°ƒæ•´
                        # æ­£å¸¸è¯­é€Ÿï¼šä¸­æ–‡çº¦ 4-5 å­—ç¬¦/ç§’ï¼Œè‹±æ–‡çº¦ 12-15 å­—ç¬¦/ç§’
                        # æ¯”ä¾‹ï¼šè‹±æ–‡æ­£å¸¸è¯­é€Ÿçº¦ä¸ºä¸­æ–‡çš„ 2.4-3 å€
                        
                        # è®¡ç®—å½“å‰æ–‡æœ¬çš„ç›®æ ‡è¯­é€Ÿï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦ï¼‰
                        text_length = len(text)
                        if language.startswith('zh'):
                            # ä¸­æ–‡ï¼šæ­£å¸¸è¯­é€Ÿçº¦ 5 å­—ç¬¦/ç§’
                            normal_rate = 5.0
                            target_rate = speech_rate  # ä¸­æ–‡ç›´æ¥ä½¿ç”¨
                            speed_factor = speech_rate / normal_rate
                        else:
                            # è‹±æ–‡æˆ–å…¶ä»–è¯­è¨€ï¼šæ­£å¸¸è¯­é€Ÿçº¦ 12 å­—ç¬¦/ç§’
                            normal_rate = 12.0
                            
                            # å¦‚æœ speech_rate å¾ˆå°ï¼ˆ< 6ï¼‰ï¼Œå¯èƒ½æ˜¯ä¸­æ–‡è¯­é€Ÿï¼Œéœ€è¦è½¬æ¢
                            # å‡è®¾ä¸­æ–‡å’Œè‹±æ–‡çš„è¯­é€Ÿæ¯”ä¾‹çº¦ä¸º 2.4:1ï¼ˆè‹±æ–‡æ˜¯ä¸­æ–‡çš„ 2.4 å€ï¼‰
                            if speech_rate < 6.0:
                                # å¯èƒ½æ˜¯ä¸­æ–‡è¯­é€Ÿï¼Œè½¬æ¢ä¸ºè‹±æ–‡ç­‰æ•ˆè¯­é€Ÿ
                                # ä¾‹å¦‚ï¼šä¸­æ–‡ 3 å­—ç¬¦/ç§’ -> è‹±æ–‡çº¦ 7.2 å­—ç¬¦/ç§’ï¼ˆ3 * 2.4ï¼‰
                                converted_rate = speech_rate * 2.4
                                target_rate = converted_rate
                                speed_factor = converted_rate / normal_rate
                                print(f"[YourTTS Service] âš ï¸  Detected Chinese-like speech rate ({speech_rate:.2} chars/s), converted to English equivalent ({converted_rate:.2} chars/s)")
                            else:
                                # å·²ç»æ˜¯è‹±æ–‡è¯­é€ŸèŒƒå›´ï¼Œç›´æ¥ä½¿ç”¨
                                target_rate = speech_rate
                                speed_factor = speech_rate / normal_rate
                        
                        # é™åˆ¶é€Ÿåº¦å› å­èŒƒå›´ï¼ˆ0.5x - 2.0xï¼‰ï¼Œä½†å…è®¸æ›´å®½çš„èŒƒå›´ä»¥è·Ÿéšç”¨æˆ·è¯­é€Ÿ
                        # å¦‚æœç”¨æˆ·è¯´å¾—å¾ˆå¿«æˆ–å¾ˆæ…¢ï¼Œåº”è¯¥åæ˜ å‡ºæ¥
                        speed_factor = max(0.4, min(2.5, speed_factor))
                        
                        if abs(speed_factor - 1.0) > 0.05:  # åªæœ‰å½“å·®å¼‚è¶…è¿‡ 5% æ—¶æ‰è°ƒæ•´
                            print(f"[YourTTS Service] Adjusting speech rate: {target_rate:.2} chars/s (normal: {normal_rate:.2} chars/s, factor: {speed_factor:.2}x)")
                            print(f"[YourTTS Service] Audio dtype before stretch: {wav_np.dtype}, shape: {wav_np.shape}")
                            
                            # ä½¿ç”¨ librosa è¿›è¡Œæ—¶é—´æ‹‰ä¼¸ï¼ˆä¿æŒéŸ³è°ƒï¼‰
                            if use_librosa:
                                try:
                                    # æ³¨æ„ï¼šç¡®ä¿è¾“å…¥æ˜¯ float64ï¼Œå¹¶ä¸”æ˜¯è¿ç»­çš„æ•°ç»„ï¼ˆC-contiguousï¼‰
                                    if not wav_np.flags['C_CONTIGUOUS']:
                                        wav_np = np.ascontiguousarray(wav_np, dtype=np.float64)
                                    
                                    wav_np = librosa.effects.time_stretch(wav_np, rate=speed_factor)
                                    print(f"[YourTTS Service] âœ… Speech rate adjusted using librosa, new length: {len(wav_np)} samples, dtype: {wav_np.dtype}")
                                    
                                    # æ›´æ–° wav å˜é‡ï¼ˆä¿æŒåŸå§‹ç±»å‹ï¼Œä½†ä½¿ç”¨è°ƒæ•´åçš„æ•°æ®ï¼‰
                                    wav = wav_np
                                except Exception as librosa_error:
                                    print(f"[YourTTS Service] âŒ Error: librosa.effects.time_stretch failed: {librosa_error}")
                                    import traceback
                                    traceback.print_exc()
                                    # ä¿æŒåŸå§‹éŸ³é¢‘ï¼Œä¸è¿›è¡Œè°ƒæ•´
                            else:
                                print(f"[YourTTS Service] âš ï¸  Warning: librosa not available, cannot adjust speech rate")
                        else:
                            print(f"[YourTTS Service] Speech rate ({speech_rate:.2} chars/s) is close to normal ({normal_rate:.2} chars/s), no adjustment needed")
                    except Exception as e:
                        print(f"[YourTTS Service] âš ï¸  Warning: Failed to adjust speech rate: {e}")
                        import traceback
                        traceback.print_exc()
                        # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«æ¸…ç†ï¼ˆå³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼‰
            if speaker_wav and os.path.exists(speaker_wav):
                try:
                    os.unlink(speaker_wav)
                except Exception as e:
                    print(f"Warning: Failed to delete temp file {speaker_wav}: {e}")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        # å¤„ç†ä¸åŒçš„è¿”å›ç±»å‹ï¼šnp.ndarray, torch.Tensor, æˆ– list
        # æ³¨æ„ï¼šéœ€è¦å°† numpy float32 è½¬æ¢ä¸º Python floatï¼Œä»¥ä¾¿ JSON åºåˆ—åŒ–
        if isinstance(wav, np.ndarray):
            # ç¡®ä¿è½¬æ¢ä¸º Python float ç±»å‹
            audio_list = [float(x) for x in wav.flatten()]
        elif isinstance(wav, torch.Tensor):
            # ä» Tensor è½¬æ¢ä¸º numpyï¼Œå†è½¬æ¢ä¸º Python float
            audio_array = wav.cpu().numpy()
            audio_list = [float(x) for x in audio_array.flatten()]
        else:
            # å¦‚æœæ˜¯ listï¼Œä¹Ÿéœ€è¦ç¡®ä¿æ˜¯ Python float
            audio_list = [float(x) for x in wav]
        
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨äº† reference_audio
        used_reference = speaker_wav is not None
        
        # è¾“å‡ºæœ€ç»ˆçŠ¶æ€æ—¥å¿—
        print(f"[YourTTS Service] " + "=" * 70)
        if used_reference:
            if use_cached and speaker_id:
                print(f"[YourTTS Service] ğŸ¯ FINAL STATUS: âœ… Voice cloning APPLIED")
                print(f"[YourTTS Service]    âœ“ Used cached reference_audio (speaker_id: '{speaker_id}')")
                print(f"[YourTTS Service]    âœ“ Reference audio was successfully used for zero-shot voice cloning")
            else:
                print(f"[YourTTS Service] ğŸ¯ FINAL STATUS: âœ… Voice cloning APPLIED")
                print(f"[YourTTS Service]    âœ“ Used provided reference_audio")
                print(f"[YourTTS Service]    âœ“ Reference audio was successfully used for zero-shot voice cloning")
        else:
            if speaker_id:
                print(f"[YourTTS Service] ğŸ¯ FINAL STATUS: âš ï¸  Voice cloning NOT applied")
                print(f"[YourTTS Service]    âœ— Speaker_id '{speaker_id}' not found in cache")
                print(f"[YourTTS Service]    âœ— Used default voice instead (no voice cloning)")
            else:
                print(f"[YourTTS Service] ğŸ¯ FINAL STATUS: âš ï¸  Voice cloning NOT applied")
                print(f"[YourTTS Service]    âœ— No reference_audio available")
                print(f"[YourTTS Service]    âœ— Used default voice instead (no voice cloning)")
        print(f"[YourTTS Service] " + "=" * 70)
        
        return jsonify({
            "audio": audio_list,
            "sample_rate": 22050,  # YourTTS é»˜è®¤é‡‡æ ·ç‡
            "text": text,
            "used_reference": used_reference,  # æŒ‡ç¤ºæ˜¯å¦ä½¿ç”¨äº†å‚è€ƒéŸ³é¢‘
            "speaker_applied": used_reference  # æŒ‡ç¤ºéŸ³è‰²æ˜¯å¦è¢«åº”ç”¨ï¼ˆzero-shotï¼‰
        })
        
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        return jsonify({
            "error": error_msg,
            "type": type(e).__name__
        }), 500

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="YourTTS HTTP Service")
    parser.add_argument('--gpu', action='store_true', help='Use GPU if available')
    parser.add_argument('--port', type=int, default=5004, help='Server port (default: 5004)')
    parser.add_argument('--host', type=str, default='127.0.0.1', help='Server host (default: 127.0.0.1, use 0.0.0.0 for WSL)')
    parser.add_argument('--check-deps', action='store_true', help='Check dependencies and exit')
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯æ£€æŸ¥ä¾èµ–ï¼Œè¿è¡Œæ£€æŸ¥åé€€å‡º
    if args.check_deps:
        import check_dependencies
        sys.exit(check_dependencies.main())
    
    print("=" * 60)
    print("  YourTTS HTTP Service (Zero-shot TTS)")
    print("=" * 60)
    
    # å¦‚æœ host æ˜¯ 0.0.0.0ï¼Œæç¤ºå¯ä»¥ä» Windows è®¿é—®
    if args.host == '0.0.0.0':
        print("  Running in WSL mode (accessible from Windows)")
        print(f"  Windows endpoint: http://127.0.0.1:{args.port}")
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„
    model_path = project_root / "core" / "engine" / "models" / "tts" / "your_tts"
    if not model_path.exists():
        model_path = Path("core/engine/models/tts/your_tts")
    
    # è·å–è®¾å¤‡
    device = get_device(args.gpu)
    
    # å¦‚æœè¯·æ±‚ä½¿ç”¨ GPU ä½†æ£€æµ‹åˆ° CPUï¼Œè¾“å‡ºè­¦å‘Š
    if args.gpu and device == "cpu":
        print("âš ï¸  WARNING: GPU was requested but not available!")
        print("   Make sure:")
        print("   1. NVIDIA drivers are installed in WSL")
        print("   2. CUDA toolkit is installed in WSL")
        print("   3. PyTorch with CUDA support is installed")
        print("   4. Run: nvidia-smi in WSL to verify GPU access")
        print("")
    
    # åŠ è½½æ¨¡å‹
    try:
        load_model(model_path, device)
    except Exception as e:
        print(f"\nâŒ Failed to start service: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Check dependencies: python core/engine/scripts/check_dependencies.py")
        print("   2. Install TTS: pip install TTS")
        print("   3. Install other dependencies: pip install torch torchaudio soundfile")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print(f"\nğŸš€ Starting server on http://{args.host}:{args.port}")
    print("   Endpoints:")
    print("     GET  /health     - Health check")
    print("     POST /synthesize - Synthesize speech (zero-shot supported)")
    print(f"   Device: {device}")
    print("\n   Press Ctrl+C to stop")
    print("=" * 60)
    
    app.run(host=args.host, port=args.port, debug=False)


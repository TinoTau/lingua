#!/usr/bin/env python3
"""
Speaker Embedding HTTP æœåŠ¡

ç”¨äºä» Rust ä»£ç è°ƒç”¨ SpeechBrain ECAPA-TDNN æ¨¡å‹æå–è¯´è¯è€…ç‰¹å¾å‘é‡ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python speaker_embedding_service.py [--gpu] [--port PORT] [--host HOST]

å‚æ•°ï¼š
    --gpu: ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    --port: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š5003ï¼‰
    --host: æœåŠ¡åœ°å€ï¼ˆé»˜è®¤ï¼š127.0.0.1ï¼‰

æœåŠ¡å°†åœ¨ http://127.0.0.1:5003 å¯åŠ¨

API ç«¯ç‚¹ï¼š
    POST /extract
    Body: {"audio": [0.1, 0.2, ...]}  # 16kHz å•å£°é“éŸ³é¢‘æ•°æ®ï¼ˆf32ï¼‰
    Response: {"embedding": [0.1, 0.2, ...], "dimension": 192}
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ä¿®å¤ torchaudio å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
def fix_torchaudio_compatibility():
    """ä¿®å¤ torchaudio 2.9+ å…¼å®¹æ€§é—®é¢˜"""
    try:
        import torchaudio
        # torchaudio 2.9+ ç§»é™¤äº† list_audio_backends æ–¹æ³•
        if not hasattr(torchaudio, 'list_audio_backends'):
            # åˆ›å»ºæ¨¡æ‹Ÿå‡½æ•°
            def mock_list_audio_backends():
                return ['soundfile']  # é»˜è®¤åç«¯
            torchaudio.list_audio_backends = mock_list_audio_backends
            # ä¸æ‰“å°ï¼Œé¿å…åœ¨å¯¼å…¥æ—¶è¾“å‡ºï¼ˆä¼šåœ¨ load_model æ—¶æ˜¾ç¤ºï¼‰
    except ImportError:
        pass  # torchaudio æœªå®‰è£…ï¼Œç¨åä¼šæŠ¥é”™

# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰åº”ç”¨ä¿®å¤
fix_torchaudio_compatibility()

# è¿›ä¸€æ­¥ä¿®å¤ï¼šåœ¨ SpeechBrain å¯¼å…¥å‰ä¿®è¡¥å…¶ backend æ£€æŸ¥æ¨¡å—
def patch_speechbrain_backend_check():
    """åœ¨ SpeechBrain å¯¼å…¥å‰ä¿®è¡¥ backend æ£€æŸ¥"""
    import types
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ backend æ£€æŸ¥æ¨¡å—
    backend_module_name = 'speechbrain.utils.torch_audio_backend'
    
    # å¦‚æœæ¨¡å—è¿˜æœªå¯¼å…¥ï¼Œåˆ›å»ºå¹¶æ³¨å†Œ
    if backend_module_name not in sys.modules:
        backend_module = types.ModuleType(backend_module_name)
        
        def patched_check_torchaudio_backend():
            """ä¿®è¡¥çš„æ£€æŸ¥å‡½æ•°ï¼Œè·³è¿‡ list_audio_backends è°ƒç”¨"""
            try:
                import torchaudio
                # åªæ£€æŸ¥ torchaudio æ˜¯å¦å­˜åœ¨ï¼Œä¸è°ƒç”¨ list_audio_backends
                if not hasattr(torchaudio, '__version__'):
                    raise RuntimeError("torchaudio not properly installed")
            except ImportError:
                raise RuntimeError("torchaudio is not installed. Install it with: pip install torchaudio")

        # SpeechBrain æ–°ç‰ˆæœ¬è¿˜ä¼šä»è¯¥æ¨¡å—å¯¼å…¥ validate_backend / get_audio_backend / set_audio_backend
        # è¿™é‡Œæä¾›ç®€å•çš„å…¼å®¹å®ç°ï¼Œé¿å… ImportErrorï¼Œä½†ä¸åšå¤æ‚æ£€æŸ¥
        def patched_validate_backend():
            """å…¼å®¹ç”¨çš„ validate_backendï¼Œå†…éƒ¨å¤ç”¨æ£€æŸ¥é€»è¾‘"""
            return patched_check_torchaudio_backend()

        def get_audio_backend():
            """è¿”å›ä¸€ä¸ªå›ºå®šçš„åç«¯åç§°ï¼ˆä¾‹å¦‚ soundfileï¼‰"""
            return "soundfile"

        def set_audio_backend(_backend: str):
            """å…¼å®¹å‡½æ•°ï¼Œå ä½ï¼Œä¸æ‰§è¡Œå®é™…åˆ‡æ¢"""
            # åœ¨å½“å‰åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦é¿å…å¯¼å…¥é”™è¯¯
            return None

        backend_module.check_torchaudio_backend = patched_check_torchaudio_backend
        backend_module.validate_backend = patched_validate_backend
        backend_module.get_audio_backend = get_audio_backend
        backend_module.set_audio_backend = set_audio_backend
        sys.modules[backend_module_name] = backend_module
        print("âœ… Patched SpeechBrain backend check module (check/validate/get/set)")

# åº”ç”¨ä¿®è¡¥ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
patch_speechbrain_backend_check()

# ä¿®å¤ huggingface_hub å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
def patch_huggingface_hub():
    """ä¿®å¤ huggingface_hub çš„ use_auth_token å‚æ•°å…¼å®¹æ€§é—®é¢˜"""
    try:
        import huggingface_hub
        import functools
        
        # ä¿å­˜åŸå§‹çš„ hf_hub_download å‡½æ•°
        original_hf_hub_download = huggingface_hub.hf_hub_download
        
        @functools.wraps(original_hf_hub_download)
        def patched_hf_hub_download(*args, **kwargs):
            """ä¿®è¡¥çš„ hf_hub_downloadï¼Œå°† use_auth_token è½¬æ¢ä¸º token"""
            # å¦‚æœæä¾›äº† use_auth_tokenï¼Œè½¬æ¢ä¸º token
            if 'use_auth_token' in kwargs:
                token = kwargs.pop('use_auth_token')
                # åªæœ‰å½“ token ä¸ä¸º None æ—¶æ‰è®¾ç½®
                if token is not None and 'token' not in kwargs:
                    kwargs['token'] = token
            return original_hf_hub_download(*args, **kwargs)
        
        # æ›¿æ¢å‡½æ•°
        huggingface_hub.hf_hub_download = patched_hf_hub_download
        print("âœ… Patched huggingface_hub.hf_hub_download (use_auth_token -> token)")
    except ImportError:
        pass  # huggingface_hub æœªå®‰è£…ï¼Œç¨åä¼šæŠ¥é”™
    except Exception as e:
        print(f"âš ï¸  Failed to patch huggingface_hub: {e}")

# åº”ç”¨ huggingface_hub ä¿®è¡¥ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
patch_huggingface_hub()

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥å…¶ä»–æ¨¡å—
from flask import Flask, request, jsonify
import numpy as np
import torch

# å†æ¬¡ç¡®ä¿ torchaudio ä¿®å¤å·²åº”ç”¨ï¼ˆåœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
fix_torchaudio_compatibility()

app = Flask(__name__)
classifier = None
device = None

def get_device(use_gpu=False):
    """è·å–è®¡ç®—è®¾å¤‡"""
    if use_gpu and torch.cuda.is_available():
        device = "cuda"
        print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        if use_gpu:
            print("âš ï¸  GPU requested but not available, using CPU")
        else:
            print("â„¹ï¸  Using CPU")
    return device

def load_model(model_path, device="cpu"):
    """åŠ è½½ SpeechBrain ECAPA-TDNN æ¨¡å‹"""
    global classifier
    
    # ç¡®ä¿å…¼å®¹æ€§ä¿®å¤å·²åº”ç”¨ï¼ˆåœ¨å¯¼å…¥ SpeechBrain ä¹‹å‰ï¼‰
    fix_torchaudio_compatibility()
    patch_speechbrain_backend_check()
    patch_huggingface_hub()
    
    try:
        from speechbrain.inference.speaker import EncoderClassifier
        
        if not model_path.exists():
            raise FileNotFoundError(f"Model not found at {model_path}")
        
        print(f"ğŸ“ Loading model from: {model_path}")
        print(f"ğŸ”§ Device: {device}")
        
        classifier = EncoderClassifier.from_hparams(
            source=str(model_path),
            run_opts={"device": device}
        )
        
        print("âœ… Speaker Embedding model loaded successfully")
        print(f"   Model output dimension: 192")
        print(f"   Device: {device}")
        
        return classifier
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "ok",
        "model_loaded": classifier is not None
    })

@app.route('/extract', methods=['POST'])
def extract_embedding():
    """æå–è¯´è¯è€…ç‰¹å¾å‘é‡"""
    try:
        # å…ˆéªŒè¯è¾“å…¥ï¼Œå†æ£€æŸ¥æ¨¡å‹
        data = request.json
        if data is None:
            return jsonify({"error": "Invalid JSON"}), 400
        
        if 'audio' not in data:
            return jsonify({"error": "Missing 'audio' field"}), 400
        
        # è·å–éŸ³é¢‘æ•°æ®
        try:
            audio_data = np.array(data['audio'], dtype=np.float32)
        except (ValueError, TypeError) as e:
            return jsonify({"error": f"Invalid audio data: {str(e)}"}), 400
        
        # éªŒè¯éŸ³é¢‘æ•°æ®
        if len(audio_data) == 0:
            return jsonify({"error": "Empty audio data"}), 400
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
        if classifier is None:
            return jsonify({"error": "Model not loaded"}), 500
        
        # è½¬æ¢ä¸º tensor [batch, samples]
        # ECAPA-TDNN æœŸæœ›è¾“å…¥ï¼š16kHz å•å£°é“éŸ³é¢‘
        # æ£€æŸ¥éŸ³é¢‘é•¿åº¦ï¼ŒECAPA-TDNN éœ€è¦è‡³å°‘ 1 ç§’çš„éŸ³é¢‘ï¼ˆ16000 æ ·æœ¬ï¼‰
        min_samples = 16000  # 1 ç§’ @ 16kHz
        if len(audio_data) < min_samples:
            # éŸ³é¢‘å¤ªçŸ­ï¼Œæ— æ³•æå– embeddingï¼Œè¿”å›æ ‡è®°ä½¿ç”¨é»˜è®¤å£°éŸ³
            # å°è¯•ç®€å•åˆ¤æ–­æ€§åˆ«ï¼ˆåŸºäºéŸ³é¢‘èƒ½é‡å’Œé¢‘ç‡ç‰¹å¾ï¼‰
            # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼Œä¸ä¿è¯å‡†ç¡®æ€§
            audio_array = np.array(audio_data, dtype=np.float32)
            # è®¡ç®—éŸ³é¢‘çš„å‡æ–¹æ ¹èƒ½é‡
            rms = np.sqrt(np.mean(audio_array ** 2))
            # ç®€å•çš„æ€§åˆ«åˆ¤æ–­ï¼šèƒ½é‡è¾ƒé«˜å¯èƒ½æ˜¯ç”·æ€§ï¼Œèƒ½é‡è¾ƒä½å¯èƒ½æ˜¯å¥³æ€§ï¼ˆè¿™åªæ˜¯ç²—ç•¥ä¼°è®¡ï¼‰
            # å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç‰¹å¾
            estimated_gender = "male" if rms > 0.01 else "female"
            
            return jsonify({
                "embedding": None,
                "too_short": True,
                "use_default": True,
                "estimated_gender": estimated_gender,
                "input_samples": len(audio_data),
                "sample_rate": 16000,
                "message": f"Audio too short ({len(audio_data)} samples < {min_samples} required), using default voice"
            }), 200
        
        audio_tensor = torch.from_numpy(audio_data).unsqueeze(0)
        
        # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        # æ³¨æ„ï¼šdevice æ˜¯å…¨å±€å˜é‡ï¼Œåœ¨ load_model æ—¶è®¾ç½®
        current_device = device if device else "cpu"
        if current_device != "cpu":
            audio_tensor = audio_tensor.to(current_device)
        
        # æå– embedding
        # è¾“å‡ºå½¢çŠ¶ï¼š[batch, 1, 192]
        embeddings = classifier.encode_batch(audio_tensor)
        
        # è½¬æ¢ä¸ºåˆ—è¡¨ [192]ï¼ˆç¡®ä¿ç§»å› CPUï¼‰
        embedding = embeddings.squeeze().cpu().numpy()
        
        # ç¡®ä¿æ˜¯ 1D æ•°ç»„
        if embedding.ndim > 1:
            embedding = embedding.flatten()
        
        embedding_list = embedding.tolist()
        
        # è®¡ç®—éŸ³è‰²ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºå’Œè°ƒè¯•ï¼‰
        embedding_array = np.array(embedding_list)
        embedding_stats = {
            "mean": float(np.mean(embedding_array)),
            "std": float(np.std(embedding_array)),
            "min": float(np.min(embedding_array)),
            "max": float(np.max(embedding_array)),
            "norm": float(np.linalg.norm(embedding_array)),  # L2 èŒƒæ•°
            "abs_mean": float(np.mean(np.abs(embedding_array))),  # ç»å¯¹å€¼å‡å€¼
        }
        
        # æ˜¾ç¤ºéŸ³è‰²ä¿¡æ¯
        print(f"[Speaker Embedding] âœ… Extracted embedding:")
        print(f"   Dimension: {len(embedding_list)}")
        print(f"   Norm (L2): {embedding_stats['norm']:.4f}")
        print(f"   Mean: {embedding_stats['mean']:.6f}, Std: {embedding_stats['std']:.6f}")
        print(f"   Range: [{embedding_stats['min']:.6f}, {embedding_stats['max']:.6f}]")
        print(f"   Abs Mean: {embedding_stats['abs_mean']:.6f}")
        print(f"   Input: {len(audio_data)} samples @ 16kHz ({len(audio_data)/16000:.2f}s)")
        
        # æ˜¾ç¤º embedding çš„å‰å‡ ä¸ªå€¼ï¼ˆç”¨äºå¿«é€Ÿæ£€æŸ¥ï¼‰
        preview_values = embedding_list[:10]
        print(f"   Preview (first 10): {[f'{v:.4f}' for v in preview_values]}")
        
        return jsonify({
            "embedding": embedding_list,
            "dimension": len(embedding_list),
            "input_samples": len(audio_data),
            "sample_rate": 16000,  # ECAPA-TDNN æœŸæœ› 16kHz
            "stats": embedding_stats  # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        })
        
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        return jsonify({
            "error": error_msg,
            "type": type(e).__name__
        }), 500

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Speaker Embedding HTTP Service")
    parser.add_argument('--gpu', action='store_true', help='Use GPU if available')
    parser.add_argument('--port', type=int, default=5003, help='Server port (default: 5003)')
    parser.add_argument('--host', type=str, default='127.0.0.1', help='Server host (default: 127.0.0.1, use 0.0.0.0 for WSL)')
    parser.add_argument('--check-deps', action='store_true', help='Check dependencies and exit')
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯æ£€æŸ¥ä¾èµ–ï¼Œè¿è¡Œæ£€æŸ¥åé€€å‡º
    if args.check_deps:
        import check_dependencies
        sys.exit(check_dependencies.main())
    
    print("=" * 60)
    print("  Speaker Embedding HTTP Service")
    print("=" * 60)
    
    # å¦‚æœ host æ˜¯ 0.0.0.0ï¼Œæç¤ºå¯ä»¥ä» Windows è®¿é—®
    if args.host == '0.0.0.0':
        print("  Running in WSL mode (accessible from Windows)")
        print(f"  Windows endpoint: http://127.0.0.1:{args.port}")
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„
    model_path = project_root / "core" / "engine" / "models" / "speaker_embedding" / "cache"
    if not model_path.exists():
        model_path = Path("core/engine/models/speaker_embedding/cache")
    
    # è·å–è®¾å¤‡
    device = get_device(args.gpu)
    
    # åŠ è½½æ¨¡å‹
    try:
        print("\nğŸ”§ Applying compatibility fixes...")
        fix_torchaudio_compatibility()
        patch_speechbrain_backend_check()
        print("âœ… Compatibility fixes applied")
        
        load_model(model_path, device)
    except Exception as e:
        print(f"\nâŒ Failed to start service: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Check dependencies: python core/engine/scripts/check_dependencies.py")
        print("   2. Install missing packages: pip install speechbrain torch 'torchaudio<2.9' soundfile")
        print("   3. If torchaudio 2.9+, try: pip install 'torchaudio<2.9'")
        print("   4. Or the compatibility fix should be applied automatically")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print(f"\nğŸš€ Starting server on http://{args.host}:{args.port}")
    print("   Endpoints:")
    print("     GET  /health  - Health check")
    print("     POST /extract - Extract speaker embedding")
    print(f"   Device: {device}")
    print("\n   Press Ctrl+C to stop")
    print("=" * 60)
    
    app.run(host=args.host, port=args.port, debug=False)


#!/usr/bin/env python3
"""
YourTTS æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python export_yourtts_to_onnx.py [--output-dir OUTPUT_DIR] [--model-path MODEL_PATH]

å‚æ•°ï¼š
    --output-dir: ONNX æ¨¡å‹è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šcore/engine/models/tts/your_tts_onnxï¼‰
    --model-path: YourTTS æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤ï¼šcore/engine/models/tts/your_ttsï¼‰
"""

import sys
import os
import argparse
from pathlib import Path

# æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–
def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–"""
    missing_deps = []
    
    # æ£€æŸ¥ torch
    try:
        import torch
    except ImportError:
        missing_deps.append("torch")
    
    # æ£€æŸ¥ onnx
    try:
        import onnx
    except ImportError:
        missing_deps.append("onnx")
    
    # æ£€æŸ¥ onnxruntime
    try:
        import onnxruntime
    except ImportError:
        missing_deps.append("onnxruntime")
    
    if missing_deps:
        print("âš ï¸  ç¼ºå°‘ä»¥ä¸‹ä¾èµ–:", ", ".join(missing_deps))
        print("æ­£åœ¨å°è¯•å®‰è£…...")
        import subprocess
        for dep in missing_deps:
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", dep])
                print(f"âœ… {dep} å®‰è£…æˆåŠŸ")
            except Exception as e:
                print(f"âŒ {dep} å®‰è£…å¤±è´¥: {e}")
                print(f"   è¯·æ‰‹åŠ¨å®‰è£…: pip install {dep}")
                return False
        print("âœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ")
        print()
    
    return True

# åœ¨å¯¼å…¥ä¹‹å‰æ£€æŸ¥ä¾èµ–
if not check_and_install_dependencies():
    print("âŒ ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…:")
    print("   pip install torch onnx onnxruntime")
    sys.exit(1)

import torch
import torch.onnx

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def export_yourtts_to_onnx(model_path, output_dir, verbose=True):
    """
    å°† YourTTS æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼
    
    Args:
        model_path: YourTTS æ¨¡å‹è·¯å¾„
        output_dir: ONNX æ¨¡å‹è¾“å‡ºç›®å½•
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    try:
        from TTS.api import TTS
        import torch
        import numpy as np
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…: pip install TTS torch onnx")
        return False
    
    model_path = Path(model_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if verbose:
        print("=" * 60)
        print("  YourTTS æ¨¡å‹å¯¼å‡ºä¸º ONNX")
        print("=" * 60)
        print(f"æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print()
    
    try:
        # åŠ è½½ YourTTS æ¨¡å‹
        if verbose:
            print("ğŸ“¦ åŠ è½½ YourTTS æ¨¡å‹...")
        
        # ä½¿ç”¨ TTS API åŠ è½½æ¨¡å‹
        # å¦‚æœ model_path å­˜åœ¨ï¼Œå°è¯•ä»è·¯å¾„åŠ è½½ï¼›å¦åˆ™ä½¿ç”¨æ¨¡å‹åç§°
        if model_path.exists():
            try:
                tts = TTS(model_path=str(model_path), progress_bar=False)
                if verbose:
                    print("âœ… ä»è·¯å¾„åŠ è½½æ¨¡å‹æˆåŠŸ")
            except:
                # å¦‚æœè·¯å¾„åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ¨¡å‹åç§°
                tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts", 
                          progress_bar=False)
                if verbose:
                    print("âœ… ä½¿ç”¨æ¨¡å‹åç§°åŠ è½½æˆåŠŸ")
        else:
            tts = TTS(model_name="tts_models/multilingual/multi-dataset/your_tts", 
                      progress_bar=False)
            if verbose:
                print("âœ… ä½¿ç”¨æ¨¡å‹åç§°åŠ è½½æˆåŠŸ")
        
        if verbose:
            print()
        
        # è·å–æ¨¡å‹å¯¹è±¡
        model = tts.tts_model
        if model is None:
            print("âŒ æ— æ³•è·å–æ¨¡å‹å¯¹è±¡")
            print("   å°è¯•è®¿é—® tts.model...")
            if hasattr(tts, 'model'):
                model = tts.model
            else:
                return False
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        if verbose:
            print("ğŸ”§ åˆ†ææ¨¡å‹ç»“æ„...")
            print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
            print(f"   æ¨¡å‹å±æ€§: {[attr for attr in dir(model) if not attr.startswith('_')]}")
            print()
        
        # å‡†å¤‡ç¤ºä¾‹è¾“å…¥
        if verbose:
            print("ğŸ”§ å‡†å¤‡ç¤ºä¾‹è¾“å…¥...")
        
        # YourTTS çš„è¾“å…¥é€šå¸¸æ˜¯æ–‡æœ¬åºåˆ—
        # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬
        example_text = "Hello, this is a test."
        
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºåºåˆ—ï¼ˆå¦‚æœ TTS å¯¹è±¡æœ‰è¿™ä¸ªæ–¹æ³•ï¼‰
        if hasattr(tts, 'text_to_sequence'):
            try:
                example_inputs = tts.text_to_sequence(example_text)
                if not isinstance(example_inputs, torch.Tensor):
                    example_inputs = torch.tensor(example_inputs)
            except:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥
                example_inputs = torch.randint(0, 100, (1, 50))  # batch_size=1, sequence_length=50
        else:
            # ä½¿ç”¨é»˜è®¤è¾“å…¥
            example_inputs = torch.randint(0, 100, (1, 50))
        
        if verbose:
            print(f"   ç¤ºä¾‹è¾“å…¥å½¢çŠ¶: {example_inputs.shape}")
            print()
        
        # å¯¼å‡ºä¸º ONNX
        output_path = output_dir / "yourtts.onnx"
        
        if verbose:
            print(f"ğŸ“¤ å¯¼å‡ºæ¨¡å‹åˆ°: {output_path}")
        
        try:
            torch.onnx.export(
                model,
                example_inputs,
                str(output_path),
                export_params=True,
                opset_version=13,  # ä½¿ç”¨ ONNX opset 13
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={
                    'input': {0: 'batch_size', 1: 'sequence_length'},
                    'output': {0: 'batch_size', 1: 'sequence_length'}
                } if len(example_inputs.shape) > 1 else {
                    'input': {0: 'batch_size'},
                    'output': {0: 'batch_size'}
                },
                verbose=verbose
            )
            
            if verbose:
                print(f"âœ… æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {output_path}")
            
            # éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
            if verbose:
                print()
                print("ğŸ” éªŒè¯å¯¼å‡ºçš„æ¨¡å‹...")
            
            try:
                import onnx
                onnx_model = onnx.load(str(output_path))
                onnx.checker.check_model(onnx_model)
                if verbose:
                    print("âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
                return True
            except ImportError:
                if verbose:
                    print("âš ï¸  æ— æ³•éªŒè¯æ¨¡å‹ï¼ˆç¼ºå°‘ onnx åº“ï¼‰")
                return True
            except Exception as e:
                if verbose:
                    print(f"âš ï¸  æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
                return False
                
        except Exception as e:
            if verbose:
                print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
                print()
                print("ğŸ’¡ æç¤º:")
                print("   1. YourTTS æ¨¡å‹å¯èƒ½åŒ…å«å¤šä¸ªç»„ä»¶ï¼Œéœ€è¦åˆ†åˆ«å¯¼å‡º")
                print("   2. å°è¯•ä½¿ç”¨ export_yourtts_to_onnx_advanced.py è„šæœ¬")
                print("   3. æ£€æŸ¥æ¨¡å‹è¾“å…¥æ ¼å¼æ˜¯å¦æ­£ç¡®")
            import traceback
            traceback.print_exc()
            return False
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_onnx_support():
    """æ£€æŸ¥ ONNX å¯¼å‡ºæ”¯æŒ"""
    try:
        import onnx
        import onnxruntime
        print("âœ… ONNX ç›¸å…³åº“å·²å®‰è£…")
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ ONNX åº“: {e}")
        print("è¯·å®‰è£…: pip install onnx onnxruntime")
        return False

def main():
    parser = argparse.ArgumentParser(description="å¯¼å‡º YourTTS æ¨¡å‹ä¸º ONNX æ ¼å¼")
    parser.add_argument('--output-dir', type=str, 
                       default='core/engine/models/tts/your_tts_onnx',
                       help='ONNX æ¨¡å‹è¾“å‡ºç›®å½•')
    parser.add_argument('--model-path', type=str,
                       default='core/engine/models/tts/your_tts',
                       help='YourTTS æ¨¡å‹è·¯å¾„')
    parser.add_argument('--check-only', action='store_true',
                       help='ä»…æ£€æŸ¥ä¾èµ–ï¼Œä¸æ‰§è¡Œå¯¼å‡º')
    args = parser.parse_args()
    
    print("=" * 60)
    print("  YourTTS ONNX å¯¼å‡ºå·¥å…·")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ä¾èµ–
    print("ğŸ“Œ æ£€æŸ¥ä¾èµ–...")
    if not check_onnx_support():
        return 1
    
    try:
        from TTS.api import TTS
        print("âœ… TTS åº“å·²å®‰è£…")
    except ImportError:
        print("âŒ TTS åº“æœªå®‰è£…")
        print("è¯·å®‰è£…: pip install TTS")
        return 1
    
    print()
    
    if args.check_only:
        print("âœ… ä¾èµ–æ£€æŸ¥å®Œæˆ")
        return 0
    
    # æ‰§è¡Œå¯¼å‡º
    model_path = project_root / args.model_path
    output_dir = project_root / args.output_dir
    
    success = export_yourtts_to_onnx(model_path, output_dir)
    
    if success:
        print()
        print("=" * 60)
        print("âœ… å¯¼å‡ºæˆåŠŸï¼")
        print(f"ONNX æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
        print("=" * 60)
        return 0
    else:
        print()
        print("=" * 60)
        print("âŒ å¯¼å‡ºå¤±è´¥")
        print("=" * 60)
        print()
        print("ğŸ’¡ æç¤º:")
        print("   1. YourTTS æ¨¡å‹ç»“æ„å¤æ‚ï¼Œå¯èƒ½éœ€è¦åˆ†åˆ«å¯¼å‡ºä¸åŒç»„ä»¶")
        print("   2. æŸ¥çœ‹ TTS åº“æ–‡æ¡£: https://github.com/coqui-ai/TTS")
        print("   3. æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ ONNX å¯¼å‡º")
        print("   4. å¯èƒ½éœ€è¦ä¿®æ”¹ TTS åº“çš„æºä»£ç ä»¥æ”¯æŒå¯¼å‡º")
        return 1

if __name__ == '__main__':
    sys.exit(main())


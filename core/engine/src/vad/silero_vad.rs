//! Silero VAD å®ç°
//! 
//! ä½¿ç”¨ ONNX Runtime åŠ è½½å’Œè¿è¡Œ Silero VAD æ¨¡å‹ï¼Œç”¨äºè‡ªç„¶åœé¡¿è¯†åˆ«

use async_trait::async_trait;
use std::path::Path;
use std::sync::Arc;
use std::sync::Mutex;
use std::collections::VecDeque;
use ort::{Environment, Session, SessionBuilder, Value};
use ndarray::{Array1, Array2, Array3, Ix2, Ix3};
use ndarray::CowArray;

use crate::error::EngineResult;
use crate::types::AudioFrame;
use crate::vad::{DetectionOutcome, VoiceActivityDetector, BoundaryType};

// å¯¼å…¥æ‹†åˆ†çš„æ¨¡å—
use super::config::SileroVadConfig;
use super::adaptive_state::SpeakerAdaptiveState;
use super::feedback::VadFeedbackType;

/// Silero VAD å®ç°
pub struct SileroVad {
    session: Arc<Mutex<Session>>,
    config: SileroVadConfig,
    /// è¿ç»­é™éŸ³å¸§æ•°
    silence_frame_count: Arc<Mutex<usize>>,
    /// ä¸Šä¸€ä¸ªæ£€æµ‹åˆ°è¯­éŸ³çš„å¸§çš„æ—¶é—´æˆ³
    last_speech_timestamp: Arc<Mutex<Option<u64>>>,
    /// éšè—çŠ¶æ€ï¼ˆç”¨äº VAD æ¨¡å‹çš„çŠ¶æ€ä¼ é€’ï¼‰
    hidden_state: Arc<Mutex<Option<Array2<f32>>>>,
    /// å…¨å±€è‡ªé€‚åº”çŠ¶æ€ï¼ˆä¸æŒ‰è¯´è¯è€…åŒºåˆ†ï¼Œæ¯ä¸ªçŸ­å¥éƒ½æ ¹æ®ä¸Šä¸€ä¸ªçŸ­å¥çš„è¯­é€Ÿè°ƒæ•´ï¼‰
    adaptive_state: Arc<Mutex<SpeakerAdaptiveState>>,
    /// ä¸Šä¸€æ¬¡è¾¹ç•Œæ£€æµ‹çš„æ—¶é—´æˆ³ï¼ˆç”¨äºå†·å´æœŸï¼‰
    last_boundary_timestamp: Arc<Mutex<Option<u64>>>,
    /// å¸§ç¼“å†²åŒºï¼ˆç”¨äºç´¯ç§¯å°å¸§ï¼Œç›´åˆ°è¾¾åˆ° frame_sizeï¼‰
    frame_buffer: Arc<Mutex<Vec<f32>>>,
}

impl SileroVad {
    /// ä»æ¨¡å‹è·¯å¾„åˆ›å»º SileroVad
    /// 
    /// # Arguments
    /// * `model_path` - ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„
    pub fn new(model_path: impl AsRef<Path>) -> EngineResult<Self> {
        Self::with_config(SileroVadConfig {
            model_path: model_path.as_ref().to_string_lossy().to_string(),
            ..Default::default()
        })
    }
    
    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»º SileroVad
    pub fn with_config(config: SileroVadConfig) -> EngineResult<Self> {
        // åˆå§‹åŒ– ONNX Runtime ç¯å¢ƒ
        crate::onnx_utils::init_onnx_runtime()
            .map_err(|e| crate::error::EngineError::new(format!("Failed to init ONNX runtime: {}", e)))?;
        
        // åˆ›å»º ONNX Runtime ç¯å¢ƒ
        let env = Arc::new(
            Environment::builder()
                .with_name("silero_vad")
                .build()
                .map_err(|e| crate::error::EngineError::new(format!("Failed to create ONNX environment: {}", e)))?
        );
        
        // åŠ è½½æ¨¡å‹
        let session = SessionBuilder::new(&env)
            .map_err(|e| crate::error::EngineError::new(format!("Failed to create session builder: {}", e)))?
            .with_model_from_file(&config.model_path)
            .map_err(|e| crate::error::EngineError::new(format!("Failed to load model from {}: {}", config.model_path, e)))?;
        
        // æ‰“å°æ¨¡å‹è¾“å…¥ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        eprintln!("[SileroVad] Model inputs:");
        for (i, input) in session.inputs.iter().enumerate() {
            eprintln!("  Input[{}]: name='{}', dimensions={:?}, input_type={:?}", 
                     i, input.name, input.dimensions, input.input_type);
        }
        
        Ok(Self {
            session: Arc::new(Mutex::new(session)),
            config: config.clone(),
            silence_frame_count: Arc::new(Mutex::new(0)),
            last_speech_timestamp: Arc::new(Mutex::new(None)),
            hidden_state: Arc::new(Mutex::new(None)),
            adaptive_state: Arc::new(Mutex::new(SpeakerAdaptiveState::new(
                (config.base_threshold_min_ms + config.base_threshold_max_ms) / 2
            ))),
            last_boundary_timestamp: Arc::new(Mutex::new(None)),
            frame_buffer: Arc::new(Mutex::new(Vec::new())),
        })
    }
    
    /// æ£€æµ‹è¯­éŸ³æ´»åŠ¨æ¦‚ç‡
    /// 
    /// # Arguments
    /// * `audio` - éŸ³é¢‘æ•°æ®ï¼ˆf32ï¼ŒèŒƒå›´ -1.0 åˆ° 1.0ï¼‰
    /// 
    /// # Returns
    /// è¿”å›è¯­éŸ³æ¦‚ç‡ï¼ˆ0.0-1.0ï¼‰
    fn detect_voice_activity(&self, audio: &[f32]) -> EngineResult<f32> {
        // é¢„å¤„ç†ï¼šç¡®ä¿éŸ³é¢‘é•¿åº¦æ­£ç¡®
        if audio.len() != self.config.frame_size {
            return Err(crate::error::EngineError::new(
                format!("Audio length {} does not match frame size {}", audio.len(), self.config.frame_size)
            ));
        }
        
        // å½’ä¸€åŒ–åˆ° [-1, 1]ï¼ˆSilero VAD è¦æ±‚ï¼‰
        let normalized: Vec<f32> = audio.iter()
            .map(|&x| x.clamp(-1.0, 1.0))
            .collect();
        
        // åˆ›å»ºéŸ³é¢‘è¾“å…¥æ•°ç»„ï¼ˆå½¢çŠ¶ï¼š[1, frame_size]ï¼‰
        let input_array = Array2::from_shape_vec((1, normalized.len()), normalized)
            .map_err(|e| crate::error::EngineError::new(format!("Failed to create input array: {}", e)))?;
        
        // è·å–æˆ–åˆå§‹åŒ–éšè—çŠ¶æ€ï¼ˆå½¢çŠ¶ï¼š[2, 1, 128]ï¼‰
        let state_array = {
            let mut state_guard = self.hidden_state.lock().unwrap();
            if let Some(ref state_2d) = *state_guard {
                // çŠ¶æ€å­˜å‚¨ä¸º [2, 128]ï¼Œéœ€è¦æ‰©å±•ä¸º [2, 1, 128]
                let state_3d = state_2d.clone().into_shape((2, 1, 128))
                    .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape state: {}", e)))?;
                state_3d
            } else {
                // åˆå§‹åŒ–éšè—çŠ¶æ€ä¸ºé›¶ [2, 1, 128]
                let new_state = Array3::<f32>::zeros((2, 1, 128));
                // å­˜å‚¨ä¸º [2, 128] ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
                *state_guard = Some(new_state.clone().into_shape((2, 128))
                    .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape new state: {}", e)))?);
                new_state
            }
        };
        
        // è½¬æ¢ä¸ºåŠ¨æ€ç»´åº¦
        let arr_dyn = input_array.into_dyn();
        let arr_owned = arr_dyn.to_owned();
        let cow_arr = CowArray::from(arr_owned);
        
        let state_dyn = state_array.into_dyn();
        let state_owned = state_dyn.to_owned();
        let state_cow = CowArray::from(state_owned);
        
        // åˆ›å»ºé‡‡æ ·ç‡è¾“å…¥ï¼ˆInt64 æ ‡é‡ï¼Œå½¢çŠ¶ï¼š[]ï¼‰
        // æ³¨æ„ï¼šSilero VAD çš„ sr è¾“å…¥æ˜¯ Int64ï¼Œä¸æ˜¯ Float32
        let sr_array = Array1::from_vec(vec![self.config.sample_rate as i64]);
        let sr_dyn = sr_array.into_dyn();
        let sr_owned = sr_dyn.to_owned();
        let sr_cow = CowArray::from(sr_owned);
        
        // åˆ›å»º ONNX è¾“å…¥ï¼ˆéœ€è¦åœ¨åŒä¸€ä¸ªä½œç”¨åŸŸå†…åˆ›å»ºï¼Œç¡®ä¿ç”Ÿå‘½å‘¨æœŸæ­£ç¡®ï¼‰
        use std::ptr;
        let audio_input = {
            let audio_val = Value::from_array(ptr::null_mut(), &cow_arr)
                .map_err(|e| crate::error::EngineError::new(format!("Failed to create audio input: {}", e)))?;
            unsafe { std::mem::transmute::<Value, Value<'static>>(audio_val) }
        };
        
        let state_input = {
            let state_val = Value::from_array(ptr::null_mut(), &state_cow)
                .map_err(|e| crate::error::EngineError::new(format!("Failed to create state input: {}", e)))?;
            unsafe { std::mem::transmute::<Value, Value<'static>>(state_val) }
        };
        
        let sr_input = {
            let sr_val = Value::from_array(ptr::null_mut(), &sr_cow)
                .map_err(|e| crate::error::EngineError::new(format!("Failed to create sr input: {}", e)))?;
            unsafe { std::mem::transmute::<Value, Value<'static>>(sr_val) }
        };
        
        // æ¨ç†ï¼ˆæŒ‰æ¨¡å‹è¾“å…¥é¡ºåºä¼ é€’ï¼šinput, state, srï¼‰
        let session_guard = self.session.lock().unwrap();
        let outputs = session_guard
            .run(vec![audio_input, state_input, sr_input])
            .map_err(|e| crate::error::EngineError::new(format!("ONNX inference failed: {}", e)))?;
        
        // æå–è¾“å‡º
        // Silero VAD è¾“å‡ºï¼š[output, new_state]
        // output å½¢çŠ¶ï¼š[1, 2]ï¼Œç¬¬ä¸€åˆ—æ˜¯é™éŸ³æ¦‚ç‡ï¼Œç¬¬äºŒåˆ—æ˜¯è¯­éŸ³æ¦‚ç‡
        // new_state å½¢çŠ¶ï¼š[2, 1, 128]ï¼Œæ–°çš„éšè—çŠ¶æ€
        use ort::tensor::OrtOwnedTensor;
        use ndarray::IxDyn;
        
        // æå– outputï¼ˆç¬¬ä¸€ä¸ªè¾“å‡ºï¼‰
        let output_tensor: OrtOwnedTensor<f32, IxDyn> = outputs[0]
            .try_extract()
            .map_err(|e| crate::error::EngineError::new(format!("Failed to extract output: {}", e)))?;
        
        // æå– new_stateï¼ˆç¬¬äºŒä¸ªè¾“å‡ºï¼‰å¹¶æ›´æ–°éšè—çŠ¶æ€
        if outputs.len() > 1 {
            let state_tensor: OrtOwnedTensor<f32, IxDyn> = outputs[1]
                .try_extract()
                .map_err(|e| crate::error::EngineError::new(format!("Failed to extract state: {}", e)))?;
            
            let state_view = state_tensor.view();
            let new_state_3d: Array3<f32> = state_view
                .to_owned()
                .into_dimensionality::<Ix3>()
                .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape state: {}", e)))?;
            
            // å°†çŠ¶æ€ä» [2, 1, 128] è½¬æ¢ä¸º [2, 128] å­˜å‚¨
            let new_state_2d = new_state_3d.into_shape((2, 128))
                .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape state for storage: {}", e)))?;
            
            // æ›´æ–°éšè—çŠ¶æ€
            let mut state_guard = self.hidden_state.lock().unwrap();
            *state_guard = Some(new_state_2d);
        }
        
        // æå–è¾“å‡ºå€¼
        // æ ¹æ®å®é™…è¾“å‡ºå½¢çŠ¶å¤„ç†ï¼š
        // - å¦‚æœè¾“å‡ºæ˜¯ [1, 2]ï¼Œå– [0, 1]ï¼ˆç¬¬äºŒåˆ—ï¼Œè¯­éŸ³æ¦‚ç‡ï¼‰
        // - å¦‚æœè¾“å‡ºæ˜¯ [1, 1] æˆ– [1]ï¼Œå– [0, 0] æˆ– [0]ï¼ˆç›´æ¥æ˜¯è¯­éŸ³æ¦‚ç‡ï¼‰
        let view = output_tensor.view();
        let shape = view.shape();
        
        // ä¸å†è¾“å‡ºæ¨¡å‹è¾“å‡ºçš„è°ƒè¯•ä¿¡æ¯
        let should_log = false;
        
        let raw_output = if shape.len() == 2 {
            // 2ç»´æ•°ç»„
            let output_array: Array2<f32> = view
                .to_owned()
                .into_dimensionality::<Ix2>()
                .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape output: {}", e)))?;
            
            if should_log {
                eprintln!("[SileroVad] ğŸ”¬ Output array shape: {:?}, values: {:?}", output_array.shape(), 
                         if output_array.len() <= 10 { format!("{:?}", output_array.iter().collect::<Vec<_>>()) } else { "too many".to_string() });
            }
            
            if output_array.shape()[1] >= 2 {
                // æœ‰2åˆ—ï¼Œå–ç¬¬äºŒåˆ—ï¼ˆè¯­éŸ³æ¦‚ç‡ï¼‰
                output_array[[0, 1]]
            } else {
                // åªæœ‰1åˆ—ï¼Œç›´æ¥ä½¿ç”¨
                output_array[[0, 0]]
            }
        } else if shape.len() == 1 {
            // 1ç»´æ•°ç»„ï¼Œç›´æ¥å–ç¬¬ä¸€ä¸ªå€¼
            let output_array: Array1<f32> = view
                .to_owned()
                .into_dimensionality::<ndarray::Ix1>()
                .map_err(|e| crate::error::EngineError::new(format!("Failed to reshape output: {}", e)))?;
            output_array[0]
        } else {
            // å…¶ä»–å½¢çŠ¶ï¼Œå°è¯• flatten åå–ç¬¬ä¸€ä¸ªå€¼
            let flat: Vec<f32> = view.iter().copied().collect();
            if flat.is_empty() {
                return Err(crate::error::EngineError::new("Output tensor is empty"));
            }
            flat[0]
        };
        
        // å¤„ç†è¾“å‡ºå€¼ï¼šæ ¹æ® Silero VAD çš„å®˜æ–¹å®ç°ï¼Œæ¨¡å‹è¾“å‡ºå¯èƒ½æ˜¯ï¼š
        // 1. [1, 2] å½¢çŠ¶ï¼šç¬¬ä¸€åˆ—æ˜¯é™éŸ³æ¦‚ç‡ï¼Œç¬¬äºŒåˆ—æ˜¯è¯­éŸ³æ¦‚ç‡
        // 2. [1, 1] å½¢çŠ¶ï¼šå¯èƒ½æ˜¯ logitï¼ˆéœ€è¦ sigmoidï¼‰ï¼Œæˆ–è€…éœ€è¦ä¹˜ä»¥ç³»æ•°
        // 
        // æ ¹æ®é—®é¢˜æŠ¥å‘Šï¼Œå½“å‰è¾“å‡ºæ˜¯ [1, 1] å½¢çŠ¶ï¼Œå€¼ä¸º 0.0006-0.0013ï¼ˆéå¸¸å°ï¼‰
        // å¦‚æœç›´æ¥åº”ç”¨ sigmoidï¼Œæ‰€æœ‰å€¼éƒ½ä¼šå˜æˆçº¦ 0.5ï¼Œæ— æ³•åŒºåˆ†
        // 
        // å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
        // 1. è¾“å‡ºå€¼éœ€è¦ä¹˜ä»¥ç³»æ•°ï¼ˆæ¯”å¦‚ 100 æˆ– 1000ï¼‰åå†åº”ç”¨ sigmoid
        // 2. æˆ–è€…è¾“å‡ºå€¼å·²ç»æ˜¯æ¦‚ç‡ï¼Œä½†éœ€è¦ä¸åŒçš„é˜ˆå€¼
        // 3. æˆ–è€…è¾“å‡ºå€¼éœ€è¦å–åï¼ˆå¦‚æœæ˜¯é™éŸ³æ¦‚ç‡ï¼‰
        //
        // æ ¹æ® Silero VAD çš„å¸¸è§å®ç°ï¼Œå¦‚æœè¾“å‡ºå€¼éå¸¸å°ï¼ˆ< 0.01ï¼‰ï¼Œ
        // å¯èƒ½éœ€è¦ä¹˜ä»¥ä¸€ä¸ªç³»æ•°ï¼ˆæ¯”å¦‚ 100ï¼‰åå†åº”ç”¨ sigmoid
        let speech_prob = if raw_output < -10.0 || raw_output > 10.0 {
            // çœ‹èµ·æ¥æ˜¯ logitï¼Œä½¿ç”¨ sigmoid è½¬æ¢
            let prob = 1.0 / (1.0 + (-raw_output).exp());
            if should_log {
                eprintln!("[SileroVad] ğŸ”¬ Raw output {} looks like logit, applying sigmoid: {}", raw_output, prob);
            }
            prob
        } else if raw_output < 0.2 && raw_output > -0.01 {
            // æ ¹æ®è¯Šæ–­ç»“æœï¼Œå®é™…æ¨¡å‹çš„è¾“å‡ºå€¼èŒƒå›´ï¼š
            // - é™éŸ³å¸§ï¼š0.004 - 0.044ï¼ˆå‡å€¼ 0.016ï¼‰
            // - è¯­éŸ³å¸§ï¼š0.089 - 0.124ï¼ˆå‡å€¼ 0.099ï¼‰
            // 
            // è¿™äº›å€¼çœ‹èµ·æ¥åƒæ˜¯ç›´æ¥çš„è¯­éŸ³æ¦‚ç‡ï¼ˆæˆ–æ¥è¿‘ï¼‰ï¼Œä½†å€¼åŸŸåœ¨ 0-0.2 ä¹‹é—´
            // å¦‚æœç›´æ¥ä½¿ç”¨ï¼Œé™éŸ³å¸§ï¼ˆ0.016ï¼‰ä¼šè¢«è¯†åˆ«ä¸ºé™éŸ³ï¼Œè¯­éŸ³å¸§ï¼ˆ0.099ï¼‰ä¹Ÿä¼šè¢«è¯†åˆ«ä¸ºé™éŸ³
            // 
            // å¯èƒ½çš„è§£é‡Šï¼š
            // 1. è¾“å‡ºå€¼éœ€è¦ä¹˜ä»¥ç³»æ•°ï¼ˆæ¯”å¦‚ 5-10ï¼‰æ‰èƒ½å¾—åˆ° 0-1 èŒƒå›´çš„æ¦‚ç‡
            // 2. æˆ–è€…è¾“å‡ºå€¼å·²ç»æ˜¯æ¦‚ç‡ï¼Œä½†éœ€è¦ä¸åŒçš„é˜ˆå€¼
            // 
            // æ ¹æ®è¯Šæ–­ï¼Œå¦‚æœä½¿ç”¨ç³»æ•° 10ï¼š
            // - é™éŸ³ 0.016 * 10 = 0.16 â†’ sigmoid(0.16) â‰ˆ 0.54ï¼ˆä»ç„¶æ¥è¿‘ 0.5ï¼‰
            // - è¯­éŸ³ 0.099 * 10 = 0.99 â†’ sigmoid(0.99) â‰ˆ 0.73ï¼ˆå¯ä»¥åŒºåˆ†ï¼‰
            // 
            // ä½†æ›´å¥½çš„æ–¹æ³•æ˜¯ï¼šç›´æ¥ä½¿ç”¨åŸå§‹å€¼ï¼Œä½†è°ƒæ•´é˜ˆå€¼
            // æˆ–è€…ï¼šå°†è¾“å‡ºå€¼è§†ä¸º logitï¼Œä½¿ç”¨è¾ƒå°çš„ç³»æ•°ï¼ˆæ¯”å¦‚ 10-20ï¼‰
            // 
            // æ ¹æ®å®é™…æµ‹è¯•ï¼Œä½¿ç”¨ç³»æ•° 10 å¯ä»¥åŒºåˆ†é™éŸ³å’Œè¯­éŸ³ï¼š
            let scaled_logit = raw_output * 10.0;
            let prob = 1.0 / (1.0 + (-scaled_logit).exp());
            // ä¸å†è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            prob
        } else if raw_output < 0.5 {
            // å€¼åœ¨ 0-0.5 ä¹‹é—´ï¼Œå¯èƒ½æ˜¯é™éŸ³æ¦‚ç‡ï¼Œå–åå¾—åˆ°è¯­éŸ³æ¦‚ç‡
            let prob = 1.0 - raw_output;
            if should_log {
                eprintln!("[SileroVad] ğŸ”¬ Raw output {} might be silence prob, inverting: {}", raw_output, prob);
            }
            prob
        } else {
            // å€¼ >= 0.5ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå·²ç»æ˜¯è¯­éŸ³æ¦‚ç‡ï¼‰
            if should_log {
                eprintln!("[SileroVad] ğŸ”¬ Raw output {} used directly as speech prob", raw_output);
            }
            raw_output
        };
        
        Ok(speech_prob)
    }
}

#[async_trait]
impl VoiceActivityDetector for SileroVad {
    async fn detect(&self, frame: AudioFrame) -> EngineResult<DetectionOutcome> {
        // æ£€æŸ¥é‡‡æ ·ç‡æ˜¯å¦åŒ¹é…
        if frame.sample_rate != self.config.sample_rate {
            return Err(crate::error::EngineError::new(
                format!("Sample rate mismatch: expected {}, got {}", self.config.sample_rate, frame.sample_rate)
            ));
        }
        
        // æ¸…ç† FINAL_FRAME_FLAGï¼ˆå¦‚æœè®¾ç½®äº†çš„è¯ï¼‰
        // FINAL_FRAME_FLAG = 1u64 << 63ï¼Œç”¨äºæ ‡è®°æœ€åä¸€å¸§
        const FINAL_FRAME_FLAG: u64 = 1u64 << 63;
        let cleaned_timestamp = frame.timestamp_ms & !FINAL_FRAME_FLAG;
        let mut cleaned_frame = frame.clone();
        cleaned_frame.timestamp_ms = cleaned_timestamp;
        
        // ç´¯ç§¯å¸§åˆ°ç¼“å†²åŒºï¼Œç›´åˆ°è¾¾åˆ° frame_size
        let mut buffer = self.frame_buffer.lock().unwrap();
        buffer.extend_from_slice(&cleaned_frame.data);
        
        // å¦‚æœç¼“å†²åŒºè¿˜æ²¡æœ‰è¾¾åˆ° frame_sizeï¼Œè¿”å›ä¸€ä¸ª"éè¾¹ç•Œ"çš„ç»“æœ
        // æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦è‡³å°‘ç´¯ç§¯åˆ° frame_size æ‰èƒ½è¿›è¡Œ VAD æ£€æµ‹
        if buffer.len() < self.config.frame_size {
            drop(buffer); // é‡Šæ”¾é”
            // ä¸å†è¾“å‡ºç¼“å†²åŒºç´¯ç§¯æ—¥å¿—
            return Ok(DetectionOutcome {
                is_boundary: false,
                confidence: 0.5,
                frame: cleaned_frame.clone(),
                boundary_type: None,
            });
        }
        
        // æå–ä¸€ä¸ªå®Œæ•´çš„ frame_size æ ·æœ¬è¿›è¡Œæ£€æµ‹
        let audio_data: Vec<f32> = buffer[..self.config.frame_size].to_vec();
        
        // è®¡ç®—éŸ³é¢‘æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼Œç›®å‰æœªä½¿ç”¨ï¼‰
        // let audio_max = audio_data.iter().fold(0.0f32, |a, &b| a.max(b.abs()));
        // let audio_mean = audio_data.iter().sum::<f32>() / audio_data.len() as f32;
        // let audio_rms = (audio_data.iter().map(|x| x * x).sum::<f32>() / audio_data.len() as f32).sqrt();
        
        // ä¿ç•™å‰©ä½™çš„æ ·æœ¬åœ¨ç¼“å†²åŒºä¸­ï¼ˆç”¨äºä¸‹ä¸€æ¬¡æ£€æµ‹ï¼‰
        let remaining = buffer.len() - self.config.frame_size;
        if remaining > 0 {
            let remaining_data = buffer[self.config.frame_size..].to_vec();
            *buffer = remaining_data;
        } else {
            buffer.clear();
        }
        drop(buffer); // é‡Šæ”¾é”
        
        // ä¸å†è¾“å‡ºæ¯æ¬¡æ£€æµ‹çš„è¯¦ç»†ä¿¡æ¯
        // æ£€æµ‹è¯­éŸ³æ´»åŠ¨
        let speech_prob = self.detect_voice_activity(&audio_data)?;
        
        // åˆ¤æ–­æ˜¯å¦ä¸ºé™éŸ³
        let is_silence = speech_prob < self.config.silence_threshold;
        
        // æ›´æ–°é™éŸ³å¸§è®¡æ•°
        let mut silence_count = self.silence_frame_count.lock().unwrap();
        let mut last_speech = self.last_speech_timestamp.lock().unwrap();
        
        if is_silence {
            *silence_count += 1;
        } else {
            // æ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡ç½®é™éŸ³è®¡æ•°
            *silence_count = 0;
            *last_speech = Some(cleaned_timestamp);
        }
        
        // è®¡ç®—é™éŸ³æŒç»­æ—¶é—´
        let silence_duration_ms = (*silence_count as u64 * self.config.frame_size as u64 * 1000) 
            / self.config.sample_rate as u64;
        
        // è·å–å…¨å±€è‡ªé€‚åº”é˜ˆå€¼
        // æ³¨æ„ï¼šè¿™ä¸ªæ“ä½œéå¸¸å¿«ï¼ˆ< 0.01msï¼‰ï¼Œä¸éœ€è¦æ€§èƒ½ç›‘æ§
        let effective_threshold = self.get_adjusted_duration_ms();
        
        // è®°å½•è¾¹ç•Œæ£€æµ‹ä¿¡æ¯ï¼ˆä»…åœ¨æ¥è¿‘æˆ–è¶…è¿‡é˜ˆå€¼æ—¶è®°å½•ï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼‰
        if silence_duration_ms >= effective_threshold * 8 / 10 {
            let state = self.adaptive_state.lock().unwrap();
            let base = state.base_threshold_ms;
            let delta = state.delta_ms;
            drop(state);
            eprintln!("[SileroVad] ğŸ” Boundary check: silence={}ms, effective_threshold={}ms (base={}ms, delta={:+}ms, adaptive={})", 
                     silence_duration_ms, effective_threshold, base, delta, self.config.adaptive_enabled);
        }
        
        // åˆ¤æ–­æ˜¯å¦ä¸ºè¾¹ç•Œï¼ˆè‡ªç„¶åœé¡¿ï¼‰
        // æ³¨æ„ï¼šåªæœ‰åœ¨è¿ç»­é™éŸ³è¾¾åˆ°æœ€å°æ—¶é•¿æ—¶æ‰åˆ¤å®šä¸ºè¾¹ç•Œ
        // åŒæ—¶ï¼Œéœ€è¦æ£€æŸ¥å†·å´æœŸï¼ˆé¿å…åœ¨è¿ç»­é™éŸ³æœŸé—´é¢‘ç¹è§¦å‘è¾¹ç•Œï¼‰
        // è¿˜éœ€è¦æ£€æŸ¥æœ€å°è¯è¯­æ—¶é•¿ï¼ˆé˜²æ­¢åŠå¥è¯è¢«åˆ‡æ‰ï¼‰
        let mut last_boundary_ts = self.last_boundary_timestamp.lock().unwrap();
        
        // æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦å¼‚å¸¸ï¼ˆé˜²æ­¢æº¢å‡ºæˆ–æœªåˆå§‹åŒ–çš„å€¼ï¼‰
        // u64::MAX çš„ä¸€åŠä½œä¸ºåˆç†ä¸Šé™ï¼ˆçº¦ 292 å¹´ï¼‰
        // æ³¨æ„ï¼šcleaned_timestamp å·²ç»æ¸…ç†äº† FINAL_FRAME_FLAG
        const MAX_REASONABLE_TIMESTAMP: u64 = u64::MAX / 2;
        if cleaned_timestamp > MAX_REASONABLE_TIMESTAMP {
            eprintln!("[SileroVad] âš ï¸  Warning: Abnormal timestamp detected: {}ms, resetting boundary tracking", cleaned_timestamp);
            *last_boundary_ts = None;
            *last_speech = None;
            drop(last_boundary_ts);
            drop(last_speech);
            drop(silence_count);
            return Ok(DetectionOutcome {
                is_boundary: false,
                confidence: 0.5,
                frame: cleaned_frame.clone(),
                boundary_type: None,
            });
        }
        
        // å†·å´æœŸï¼šé˜²æ­¢åœ¨è¿ç»­é™éŸ³æœŸé—´é¢‘ç¹è§¦å‘è¾¹ç•Œ
        // é™ä½å†·å´æœŸï¼ˆä»1.5å€é™åˆ°1.0å€ï¼‰ä»¥æ”¯æŒæ›´å¿«çš„çŸ­å¥æ£€æµ‹
        // å¦‚æœç”¨æˆ·æ¯ä¸ªçŸ­å¥ä¹‹é—´éƒ½åœäº†1ç§’ï¼Œå†·å´æœŸä¸åº”è¯¥é˜»æ­¢è¾¹ç•Œæ£€æµ‹
        let cooldown_ms = effective_threshold; // ä»1.5å€é™åˆ°1.0å€ï¼Œå‡å°‘å»¶è¿Ÿ
        let is_in_cooldown = if let Some(last_ts) = *last_boundary_ts {
            // æ£€æŸ¥ last_ts æ˜¯å¦ä¹Ÿå¼‚å¸¸
            if last_ts > MAX_REASONABLE_TIMESTAMP {
                eprintln!("[SileroVad] âš ï¸  Warning: Abnormal last_boundary_timestamp: {}ms, resetting", last_ts);
                *last_boundary_ts = None;
                false
            } else {
                let elapsed = cleaned_timestamp.saturating_sub(last_ts);
                elapsed < cooldown_ms
            }
        } else {
            false
        };
        
        // åªæœ‰åœ¨æ£€æµ‹åˆ°è¯­éŸ³ä¹‹åï¼Œé™éŸ³æ‰èƒ½è§¦å‘è¾¹ç•Œ
        // å¦‚æœä»æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å¤´çš„é™éŸ³ä¸åº”è¯¥è§¦å‘è¾¹ç•Œ
        let has_detected_speech = last_speech.is_some();
        
        // æ£€æŸ¥æœ€å°è¯è¯­æ—¶é•¿ï¼ˆé˜²æ­¢åŠå¥è¯è¢«åˆ‡æ‰ï¼‰
        // å¦‚æœä»ä¸Šæ¬¡è¯­éŸ³å¼€å§‹åˆ°ç°åœ¨çš„æ—¶é—´å°äº min_utterance_msï¼Œå³ä½¿è¾¾åˆ°é™éŸ³é˜ˆå€¼ä¹Ÿä¸åº”è¯¥è§¦å‘è¾¹ç•Œ
        let utterance_duration_ok = if let Some(last_speech_ts) = *last_speech {
            let utterance_duration = cleaned_timestamp.saturating_sub(last_speech_ts);
            utterance_duration >= self.config.min_utterance_ms
        } else {
            false  // å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œä¸å…è®¸è§¦å‘è¾¹ç•Œ
        };
        
        let is_boundary = is_silence 
            && silence_duration_ms >= effective_threshold 
            && !is_in_cooldown
            && has_detected_speech  // åªæœ‰åœ¨æ£€æµ‹åˆ°è¯­éŸ³åæ‰å…è®¸è§¦å‘è¾¹ç•Œ
            && utterance_duration_ok;  // ç¡®ä¿è¯è¯­æ—¶é•¿è¶³å¤Ÿï¼Œé˜²æ­¢åŠå¥è¯è¢«åˆ‡æ‰
        
        // å¦‚æœå› ä¸ºè¯è¯­æ—¶é•¿ä¸è¶³è€Œé˜»æ­¢è¾¹ç•Œæ£€æµ‹ï¼Œè®°å½•æ—¥å¿—
        if is_silence 
            && silence_duration_ms >= effective_threshold 
            && !is_in_cooldown
            && has_detected_speech
            && !utterance_duration_ok {
            if let Some(last_speech_ts) = *last_speech {
                let utterance_duration = cleaned_timestamp.saturating_sub(last_speech_ts);
                eprintln!("[SileroVad] â¸ï¸  Boundary blocked by min_utterance: utterance_duration={}ms < min_utterance={}ms (preventing mid-sentence cut)", 
                         utterance_duration, self.config.min_utterance_ms);
            }
        }
        
        // åªè¾“å‡ºè¾¹ç•Œæ£€æµ‹ç»“æœ
        // æ³¨æ„ï¼šè¾¹ç•Œæ£€æµ‹åï¼ŒASR/ç¿»è¯‘/TTS ä¼šç«‹å³å¼€å§‹å¤„ç†ï¼ˆæµå¼å¤„ç†ï¼‰
        // è¿™æ ·å¯ä»¥å®ç°ï¼šç”¨æˆ·è¯´å®Œè¯åç«‹å³å¼€å§‹ç¿»è¯‘ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´éŸ³é¢‘
        // å¯¹äºæ‰‹æœºç«¯ AECï¼ˆå£°å­¦å›å“æ¶ˆé™¤ï¼‰åœºæ™¯ï¼Œè¿™å¯ä»¥æ˜¾è‘—å‡å°‘ç«¯åˆ°ç«¯å»¶è¿Ÿ
        if is_boundary {
            eprintln!("[SileroVad] âœ… Boundary detected: silence_duration={}ms (threshold={}ms), timestamp={}ms â†’ ğŸš€ Pipeline will start immediately", 
                     silence_duration_ms, effective_threshold, cleaned_timestamp);
            // æ›´æ–°ä¸Šä¸€æ¬¡è¾¹ç•Œæ£€æµ‹çš„æ—¶é—´æˆ³
            *last_boundary_ts = Some(cleaned_timestamp);
        }
        
        // é‡ç½®é™éŸ³è®¡æ•°ï¼ˆå¦‚æœæ£€æµ‹åˆ°è¾¹ç•Œï¼‰
        if is_boundary {
            *silence_count = 0;
        }
        
        // å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ¸…é™¤å†·å´æœŸï¼ˆå…è®¸ç«‹å³æ£€æµ‹æ–°çš„è¾¹ç•Œï¼‰
        // æ³¨æ„ï¼šè¿™å…è®¸åœ¨è¯­éŸ³ç»“æŸåç«‹å³æ£€æµ‹è¾¹ç•Œï¼Œå‡å°‘å»¶è¿Ÿ
        if !is_silence {
            *last_boundary_ts = None;
        }
        
        Ok(DetectionOutcome {
            is_boundary,
            confidence: speech_prob,
            frame: cleaned_frame,
            boundary_type: if is_boundary {
                Some(BoundaryType::NaturalPause)
            } else {
                None
            },
        })
    }
    
    async fn reset(&self) -> EngineResult<()> {
        let mut silence_count = self.silence_frame_count.lock().unwrap();
        let mut last_speech = self.last_speech_timestamp.lock().unwrap();
        let mut hidden_state = self.hidden_state.lock().unwrap();
        let mut adaptive_state = self.adaptive_state.lock().unwrap();
        let mut last_boundary_ts = self.last_boundary_timestamp.lock().unwrap();
        let mut frame_buffer = self.frame_buffer.lock().unwrap();
        *silence_count = 0;
        *last_speech = None;
        *hidden_state = None;  // é‡ç½®éšè—çŠ¶æ€
        *adaptive_state = SpeakerAdaptiveState::new(
            (self.config.base_threshold_min_ms + self.config.base_threshold_max_ms) / 2
        );  // é‡ç½®è‡ªé€‚åº”çŠ¶æ€
        frame_buffer.clear();  // æ¸…ç©ºå¸§ç¼“å†²åŒº
        *last_boundary_ts = None;  // é‡ç½®è¾¹ç•Œå†·å´æœŸ
        Ok(())
    }
    
    fn get_info(&self) -> String {
        format!(
            "SileroVad(model={}, threshold={}, min_silence={}ms, adaptive={})",
            self.config.model_path,
            self.config.silence_threshold,
            self.config.min_silence_duration_ms,
            self.config.adaptive_enabled
        )
    }
}

// ä¸º SileroVad æ·»åŠ è‡ªé€‚åº”ç›¸å…³æ–¹æ³•
impl SileroVad {
    /// æ›´æ–°è¯­é€Ÿï¼ˆç”¨äºè‡ªé€‚åº”è°ƒæ•´ï¼‰
    /// 
    /// æ¯ä¸ªçŸ­å¥è¯†åˆ«å®Œæˆåï¼Œæ ¹æ®è¯¥çŸ­å¥çš„è¯­é€Ÿæ›´æ–°å…¨å±€é˜ˆå€¼ã€‚
    /// ä¸åŒºåˆ†è¯´è¯è€…ï¼Œå› ä¸ºåŒä¸€ä¸ªäººè¯´è¯çš„è¯­é€Ÿä¹Ÿä¼šå˜åŒ–ã€‚
    /// 
    /// # Arguments
    /// * `text` - è¯†åˆ«çš„æ–‡æœ¬
    /// * `audio_duration_ms` - éŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pub fn update_speech_rate(&self, text: &str, audio_duration_ms: u64) {
        use std::time::Instant;
        let perf_start = Instant::now();
        
        if !self.config.adaptive_enabled {
            eprintln!("[SileroVad] âš ï¸  update_speech_rate: adaptive_enabled is false, skipping");
            return;
        }
        
        if audio_duration_ms == 0 {
            eprintln!("[SileroVad] âš ï¸  update_speech_rate: audio_duration_ms is 0, skipping");
            return;
        }
        
        // è®¡ç®—è¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰
        // å¯¹äºä¸­æ–‡ï¼Œä½¿ç”¨å­—ç¬¦æ•°ï¼›å¯¹äºè‹±æ–‡ï¼Œå¯ä»¥ä½¿ç”¨è¯æ•°ï¼ˆè¿™é‡Œç®€åŒ–ä½¿ç”¨å­—ç¬¦æ•°ï¼‰
        let text_length = text.chars().count() as f32;
        let audio_duration_sec = audio_duration_ms as f32 / 1000.0;
        let speech_rate = text_length / audio_duration_sec;
        
        // âš ï¸ é‡è¦ï¼šæ£€æŸ¥è¯­é€Ÿæ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        // çœŸå®è¯­éŸ³è¾“å…¥çš„è¯­é€Ÿé€šå¸¸åœ¨ 1-30 å­—ç¬¦/ç§’ä¹‹é—´
        // è¯¯è¯†åˆ«æ–‡æœ¬ï¼ˆå¦‚æ¨¡å‹"å¹»è§‰"äº§ç”Ÿçš„"(ç¬‘)"ç­‰ï¼‰å¯èƒ½äº§ç”Ÿå¼‚å¸¸è¯­é€Ÿï¼š
        // - å¦‚æœæ–‡æœ¬å¾ˆçŸ­ä½†éŸ³é¢‘æ—¶é•¿å¾ˆé•¿ï¼ˆé™éŸ³æœŸé—´è¯¯è¯†åˆ«ï¼‰ï¼Œè¯­é€Ÿä¼šéå¸¸ä½ï¼ˆ< 0.5 å­—ç¬¦/ç§’ï¼‰
        // - å¦‚æœæ–‡æœ¬å¾ˆçŸ­ä½†éŸ³é¢‘æ—¶é•¿å¾ˆçŸ­ï¼ˆæçŸ­é™éŸ³ï¼‰ï¼Œè¯­é€Ÿå¯èƒ½å¼‚å¸¸é«˜ï¼ˆ> 50 å­—ç¬¦/ç§’ï¼‰
        // è¿™äº›å¼‚å¸¸è¯­é€Ÿä¸åº”è¯¥ç”¨äºæ›´æ–°è¯­é€Ÿå†å²ï¼Œå› ä¸ºå®ƒä»¬ä¸ä»£è¡¨çœŸå®çš„è¯­éŸ³è¾“å…¥
        const MIN_REASONABLE_RATE: f32 = 0.5;  // æœ€å°åˆç†è¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰
        const MAX_REASONABLE_RATE: f32 = 50.0;  // æœ€å¤§åˆç†è¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰
        
        if speech_rate < MIN_REASONABLE_RATE || speech_rate > MAX_REASONABLE_RATE {
            eprintln!("[SileroVad] âš ï¸  update_speech_rate: Abnormal speech rate {:.2} chars/s (text='{}', {} chars, {}ms) - likely misrecognition, skipping", 
                     speech_rate, text.chars().take(30).collect::<String>(), text_length, audio_duration_ms);
            return;
        }
        
        eprintln!("[SileroVad] ğŸ“ update_speech_rate: text='{}' ({} chars), duration={}ms, rate={:.2} chars/s", 
                 text.chars().take(30).collect::<String>(), text_length, audio_duration_ms, speech_rate);
        
        // æ›´æ–°å…¨å±€è‡ªé€‚åº”çŠ¶æ€
        let mut state = self.adaptive_state.lock().unwrap();
        let old_sample_count = state.sample_count;
        state.update_speech_rate(speech_rate, &self.config);
        
        let perf_ms = perf_start.elapsed().as_micros() as f32 / 1000.0;
        
        // è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆåŒ…å«æ€§èƒ½æ•°æ®å’Œè°ƒæ•´è¯¦æƒ…ï¼‰
        if let Some(avg_rate) = state.get_avg_speech_rate() {
            let effective_threshold = state.get_effective_threshold(&self.config);
            let base_threshold = state.base_threshold_ms;
            let delta = state.delta_ms;
            eprintln!("[SileroVad] ğŸ“Š Global speech_rate={:.2} chars/s, effective_threshold={}ms (base={}ms, delta={:+}ms) [samples={}->{}, update_time={:.3}ms]", 
                     avg_rate, effective_threshold, base_threshold, delta, old_sample_count, state.sample_count, perf_ms);
        } else {
            eprintln!("[SileroVad] âš ï¸  update_speech_rate: After update, speech_rate_history is still empty (samples: {})", state.sample_count);
        }
    }
    
    /// è·å–å…¨å±€è‡ªé€‚åº”é˜ˆå€¼
    /// 
    /// # Returns
    /// è¿”å›è°ƒæ•´åçš„æœ€å°é™éŸ³æ—¶é•¿é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
    pub fn get_adjusted_duration_ms(&self) -> u64 {
        if !self.config.adaptive_enabled {
            return self.config.min_silence_duration_ms;
        }
        
        let state = self.adaptive_state.lock().unwrap();
        let adjusted = state.get_adjusted_duration(&self.config);
        
        // è®°å½•å¼‚å¸¸é«˜çš„é˜ˆå€¼ï¼ˆå¯èƒ½æ˜¯é—®é¢˜ï¼‰
        // é™ä½è­¦å‘Šé˜ˆå€¼ï¼Œä» 80% é™åˆ° 90%ï¼Œé¿å…é¢‘ç¹è­¦å‘Š
        if adjusted > self.config.final_threshold_max_ms * 9 / 10 {
            eprintln!("[SileroVad] âš ï¸  High threshold detected: {}ms (base={}ms, delta={:+}ms, samples={}, history_len={})", 
                     adjusted, state.base_threshold_ms, state.delta_ms, state.sample_count, state.speech_rate_history.len());
        }
        
        adjusted
    }
    
    /// è·å–å…¨å±€å¹³å‡è¯­é€Ÿï¼ˆç”¨äºä¼ é€’ç»™TTSï¼‰
    /// 
    /// # Returns
    /// è¿”å›å¹³å‡è¯­é€Ÿï¼ˆå­—ç¬¦/ç§’ï¼‰ï¼Œå¦‚æœæ•°æ®ä¸è¶³åˆ™è¿”å›None
    pub fn get_speech_rate(&self) -> Option<f32> {
        if !self.config.adaptive_enabled {
            eprintln!("[SileroVad] âš ï¸  get_speech_rate: adaptive_enabled is false");
            return None;
        }
        
        let state = self.adaptive_state.lock().unwrap();
        let rate = state.get_avg_speech_rate();
        
        // å‡å°‘æ—¥å¿—è¾“å‡ºé¢‘ç‡ï¼ˆåªåœ¨é¦–æ¬¡è·å–æˆ–çŠ¶æ€å˜åŒ–æ—¶è¾“å‡ºï¼‰
        // é¿å…æ¯æ¬¡è°ƒç”¨éƒ½è¾“å‡ºæ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—å™ªéŸ³
        if rate.is_none() && state.sample_count == 0 {
            eprintln!("[SileroVad] âš ï¸  get_speech_rate: speech_rate_history is empty (samples: {})", state.sample_count);
        }
        // åªåœ¨æœ‰è¯­é€Ÿæ•°æ®æ—¶è¾“å‡ºä¸€æ¬¡ç¡®è®¤æ—¥å¿—ï¼ˆå‡å°‘æ—¥å¿—å™ªéŸ³ï¼‰
        
        rate
    }
    
    /// è·å–ä¸Šä¸€ä¸ªæ£€æµ‹åˆ°è¯­éŸ³çš„æ—¶é—´æˆ³ï¼ˆç”¨äºè¿‡æ»¤é™éŸ³å¸§ï¼‰
    /// 
    /// # Returns
    /// è¿”å›ä¸Šä¸€ä¸ªæ£€æµ‹åˆ°è¯­éŸ³çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
    pub fn get_last_speech_timestamp(&self) -> Option<u64> {
        let last_speech = self.last_speech_timestamp.lock().unwrap();
        *last_speech
    }
    
    /// åŸºäºåé¦ˆè°ƒæ•´ deltaï¼ˆç”¨äºè‡ªé€‚åº”ä¼˜åŒ–ï¼‰
    /// 
    /// # Arguments
    /// * `feedback_type` - åé¦ˆç±»å‹ï¼š`BoundaryTooLong`ï¼ˆè¾¹ç•Œè¿‡é•¿ï¼Œéœ€è¦é™ä½é˜ˆå€¼ï¼‰æˆ– `BoundaryTooShort`ï¼ˆè¾¹ç•Œè¿‡çŸ­ï¼Œéœ€è¦æé«˜é˜ˆå€¼ï¼‰
    /// * `adjustment_ms` - è°ƒæ•´é‡ï¼ˆæ¯«ç§’ï¼‰ï¼Œé€šå¸¸ä¸º 150ms
    /// 
    /// # ä½¿ç”¨åœºæ™¯
    /// - å¦‚æœæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥ä½†ASRé•¿æ—¶é—´æ— è¾“å‡ºï¼Œè¯´æ˜è¾¹ç•Œè¿‡é•¿ï¼Œåº”è¯¥é™ä½é˜ˆå€¼
    /// - å¦‚æœASRè¯†åˆ«ç»“æœæ··ä¹±ã€è¢«è¿‡æ»¤ã€æˆ–NMTç¿»è¯‘å¼‚å¸¸ï¼Œè¯´æ˜è¾¹ç•Œè¿‡çŸ­ï¼Œåº”è¯¥æé«˜é˜ˆå€¼
    /// 
    /// # ä¿®è®¢ç‰ˆè®¾è®¡
    /// - åªè°ƒæ•´ deltaï¼Œä¸ç›´æ¥ä¿®æ”¹ base_threshold
    /// - BoundaryTooLong â†’ delta -= 150ms
    /// - BoundaryTooShort â†’ delta += 150ms
    /// - effective_threshold = clamp(base_threshold + delta, 500-1500ms)
    pub fn adjust_delta_by_feedback(&self, feedback_type: VadFeedbackType, adjustment_ms: i64) {
        if !self.config.adaptive_enabled {
            return;
        }
        
        let mut state = self.adaptive_state.lock().unwrap();
        let old_delta = state.delta_ms;
        let old_base = state.base_threshold_ms;
        let old_effective = state.get_effective_threshold(&self.config);
        
        let delta_adjustment = match feedback_type {
            VadFeedbackType::BoundaryTooLong => {
                // è¾¹ç•Œè¿‡é•¿ï¼šé™ä½é˜ˆå€¼ï¼ˆå‡å°‘ç­‰å¾…æ—¶é—´ï¼‰
                -adjustment_ms
            }
            VadFeedbackType::BoundaryTooShort => {
                // è¾¹ç•Œè¿‡çŸ­ï¼šæé«˜é˜ˆå€¼ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´ï¼‰
                adjustment_ms
            }
        };
        
        // æ›´æ–° deltaï¼Œå¹¶é™åˆ¶åœ¨èŒƒå›´å†…
        state.delta_ms = (state.delta_ms + delta_adjustment)
            .clamp(self.config.delta_min_ms, self.config.delta_max_ms);
        
        let new_effective = state.get_effective_threshold(&self.config);
        
        eprintln!("[SileroVad] ğŸ”§ Delta adjusted by feedback: {}ms -> {}ms (type={:?}, adjustment={:+}ms, base={}ms, effective={}ms -> {}ms)", 
                 old_delta, state.delta_ms, feedback_type, delta_adjustment, old_base, old_effective, new_effective);
    }
    
    /// åŸºäºåé¦ˆè°ƒæ•´é˜ˆå€¼ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œå·²åºŸå¼ƒï¼‰
    #[deprecated(note = "Use adjust_delta_by_feedback instead")]
    pub fn adjust_threshold_by_feedback(&self, feedback_type: VadFeedbackType, _adjustment_factor: f32) {
        // ä½¿ç”¨å›ºå®šçš„ 150ms è°ƒæ•´é‡
        self.adjust_delta_by_feedback(feedback_type, 150);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    fn create_test_frame(timestamp_ms: u64, data: Vec<f32>) -> AudioFrame {
        AudioFrame {
            sample_rate: 16000,
            channels: 1,
            data,
            timestamp_ms,
        }
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦æ¨¡å‹æ–‡ä»¶ï¼Œé»˜è®¤å¿½ç•¥
    async fn test_silero_vad_with_model() {
        // è¿™ä¸ªæµ‹è¯•éœ€è¦å®é™…çš„æ¨¡å‹æ–‡ä»¶
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !Path::new(model_path).exists() {
            eprintln!("Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        
        // åˆ›å»ºæµ‹è¯•éŸ³é¢‘ï¼ˆé™éŸ³ï¼‰
        let silence_audio = vec![0.0f32; 512];
        let frame = create_test_frame(0, silence_audio);
        let result = vad.detect(frame).await.unwrap();
        
        // é™éŸ³åº”è¯¥è¢«æ£€æµ‹åˆ°
        assert!(result.confidence < 0.5);
    }
    
    #[test]
    fn test_speaker_adaptive_state() {
        let config = SileroVadConfig::default();
        let mut state = SpeakerAdaptiveState::new(600);
        
        // æµ‹è¯•åˆå§‹çŠ¶æ€
        assert_eq!(state.get_adjusted_duration(&config), 600);
        assert_eq!(state.sample_count, 0);
        assert!(state.get_avg_speech_rate().is_none());
        
        // æ›´æ–°è¯­é€Ÿï¼ˆå¿«è¯­é€Ÿï¼‰
        state.update_speech_rate(10.0, &config);
        assert_eq!(state.sample_count, 1);
        assert!(state.get_avg_speech_rate().is_some());
        
        // æ›´æ–°è¯­é€Ÿï¼ˆæ…¢è¯­é€Ÿï¼‰
        state.update_speech_rate(3.0, &config);
        assert_eq!(state.sample_count, 2);
        
        // æ›´æ–°è¯­é€Ÿï¼ˆæ­£å¸¸è¯­é€Ÿï¼‰
        state.update_speech_rate(6.0, &config);
        assert_eq!(state.sample_count, 3);
        
        // ç°åœ¨åº”è¯¥ä½¿ç”¨è°ƒæ•´åçš„é˜ˆå€¼
        let adjusted = state.get_adjusted_duration(&config);
        assert!(adjusted >= config.adaptive_min_duration_ms);
        assert!(adjusted <= config.adaptive_max_duration_ms);
    }
    
    #[test]
    fn test_silero_vad_config_default() {
        let config = SileroVadConfig::default();
        assert_eq!(config.sample_rate, 16000);
        assert_eq!(config.frame_size, 512);
        assert_eq!(config.silence_threshold, 0.2);  // æ›´æ–°ä¸ºæ–°çš„é»˜è®¤å€¼
        assert_eq!(config.min_silence_duration_ms, 600);
        assert!(config.adaptive_enabled);
        assert_eq!(config.adaptive_min_samples, 3);
        assert_eq!(config.adaptive_rate, 0.1);
        assert_eq!(config.adaptive_min_duration_ms, 300);
        assert_eq!(config.adaptive_max_duration_ms, 1200);
    }
    
    /// åˆ›å»ºæµ‹è¯•ç”¨çš„è¯­éŸ³éŸ³é¢‘å¸§
    fn create_speech_frame(timestamp_ms: u64) -> AudioFrame {
        // åˆ›å»º 512 æ ·æœ¬çš„éŸ³é¢‘å¸§ï¼ˆ32ms @ 16kHzï¼‰
        // ä½¿ç”¨æ­£å¼¦æ³¢æ¨¡æ‹Ÿè¯­éŸ³
        let data: Vec<f32> = (0..512)
            .map(|i| {
                // ç”Ÿæˆ 440Hz çš„æ­£å¼¦æ³¢ï¼ˆA4 éŸ³ç¬¦ï¼‰
                let t = i as f32 / 16000.0;
                (2.0 * std::f32::consts::PI * 440.0 * t).sin() * 0.5
            })
            .collect();
        
        AudioFrame {
            sample_rate: 16000,
            channels: 1,
            data,
            timestamp_ms,
        }
    }
    
    #[tokio::test]
    async fn test_boundary_detection_requires_speech_first() {
        // æµ‹è¯•ï¼šåªæœ‰åœ¨æ£€æµ‹åˆ°è¯­éŸ³åï¼Œé™éŸ³æ‰èƒ½è§¦å‘è¾¹ç•Œ
        // å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !std::path::Path::new(model_path).exists() {
            eprintln!("âš ï¸  Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        
        // 1. å¼€å¤´çš„é™éŸ³ä¸åº”è¯¥è§¦å‘è¾¹ç•Œï¼ˆå³ä½¿è¾¾åˆ°é˜ˆå€¼ï¼‰
        // æ³¨æ„ï¼šç”±äºéœ€è¦å®é™…è¿è¡Œ ONNX æ¨¡å‹ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸»è¦æµ‹è¯•é€»è¾‘
        // å®é™…æµ‹è¯•ä¸­ï¼Œå¦‚æœ speech_prob ä¸€ç›´å¾ˆä½ï¼Œè¾¹ç•Œä¸åº”è¯¥è§¦å‘
        
        // 2. é‡ç½® VAD
        vad.reset().await.unwrap();
        
        // éªŒè¯é‡ç½®åçŠ¶æ€
        assert!(vad.get_last_speech_timestamp().is_none());
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦æ¨¡å‹æ–‡ä»¶ï¼Œé»˜è®¤å¿½ç•¥
    async fn test_cooldown_mechanism() {
        // æµ‹è¯•å†·å´æœŸæœºåˆ¶ï¼šåœ¨å†·å´æœŸå†…ä¸åº”è¯¥è§¦å‘æ–°çš„è¾¹ç•Œ
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !std::path::Path::new(model_path).exists() {
            eprintln!("âš ï¸  Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        vad.reset().await.unwrap();
        
        // è¿™ä¸ªæµ‹è¯•éœ€è¦å®é™…è¿è¡Œæ¨¡å‹ï¼Œæ‰€ä»¥ä¸»è¦æ˜¯éªŒè¯é€»è¾‘æ­£ç¡®æ€§
        // å®é™…è¡Œä¸ºä¼šåœ¨é›†æˆæµ‹è¯•ä¸­éªŒè¯
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦æ¨¡å‹æ–‡ä»¶ï¼Œé»˜è®¤å¿½ç•¥
    async fn test_speech_detection_updates_timestamp() {
        // æµ‹è¯•ï¼šæ£€æµ‹åˆ°è¯­éŸ³æ—¶ï¼Œåº”è¯¥æ›´æ–° last_speech_timestamp
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !std::path::Path::new(model_path).exists() {
            eprintln!("âš ï¸  Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        vad.reset().await.unwrap();
        
        // åˆå§‹çŠ¶æ€ï¼šæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³
        assert!(vad.get_last_speech_timestamp().is_none());
        
        // å¤„ç†ä¸€äº›å¸§ï¼ˆå®é™…æµ‹è¯•éœ€è¦è¿è¡Œæ¨¡å‹ï¼‰
        // è¿™é‡Œä¸»è¦éªŒè¯æ¥å£å¯ç”¨æ€§
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦æ¨¡å‹æ–‡ä»¶ï¼Œé»˜è®¤å¿½ç•¥
    async fn test_reset_clears_state() {
        // æµ‹è¯•ï¼šreset åº”è¯¥æ¸…é™¤æ‰€æœ‰çŠ¶æ€
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !std::path::Path::new(model_path).exists() {
            eprintln!("âš ï¸  Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        
        // å¤„ç†ä¸€äº›å¸§
        let frame = create_test_frame(0, vec![0.0; 512]);
        let _ = vad.detect(frame).await;
        
        // é‡ç½®
        vad.reset().await.unwrap();
        
        // éªŒè¯çŠ¶æ€å·²æ¸…é™¤
        assert!(vad.get_last_speech_timestamp().is_none());
    }
    
    #[tokio::test]
    async fn test_adaptive_speech_rate_update() {
        // æµ‹è¯•ï¼šè‡ªé€‚åº”è¯­é€Ÿæ›´æ–°åŠŸèƒ½
        let model_path = "models/vad/silero/silero_vad.onnx";
        if !std::path::Path::new(model_path).exists() {
            eprintln!("âš ï¸  Skipping test: model file not found at {}", model_path);
            return;
        }
        
        let vad = SileroVad::new(model_path).unwrap();
        
        // æ›´æ–°å…¨å±€è¯­é€Ÿ
        vad.update_speech_rate("Hello world", 1000);
        
        // è·å–å…¨å±€è¯­é€Ÿ
        let speech_rate = vad.get_speech_rate();
        assert!(speech_rate.is_some());
        
        // éªŒè¯è¯­é€Ÿè®¡ç®—ï¼ˆ"Hello world" = 11 å­—ç¬¦ï¼Œ1000ms = 1ç§’ï¼Œåº”è¯¥æ˜¯ 11 å­—ç¬¦/ç§’ï¼‰
        let rate = speech_rate.unwrap();
        assert!((rate - 11.0).abs() < 0.1, "Expected ~11 chars/s, got {}", rate);
    }
}


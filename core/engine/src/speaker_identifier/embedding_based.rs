//! åŸºäº Speaker Embedding çš„è¯´è¯è€…è¯†åˆ«
//! 
//! è¿™æ˜¯ä¸€ä¸ªå‡†ç¡®çš„å®ç°ï¼Œé€‚ç”¨äºä»˜è´¹ç”¨æˆ·ï¼š
//! - ä½¿ç”¨è½»é‡çº§ Speaker Embedding æ¨¡å‹ï¼ˆå¦‚ ECAPA-TDNNï¼‰
//! - æå–éŸ³é¢‘ç‰‡æ®µçš„è¯´è¯è€…ç‰¹å¾å‘é‡
//! - ä¸å·²æœ‰è¯´è¯è€…çš„ embedding æ¯”è¾ƒï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºæ–°è¯´è¯è€…
//! 
//! æ³¨æ„ï¼šå½“å‰ä¸ºå ä½ç¬¦å®ç°ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦é›†æˆ Speaker Embedding æ¨¡å‹

use async_trait::async_trait;
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;

use crate::error::{EngineError, EngineResult};
use crate::types::AudioFrame;
use super::{SpeakerIdentifier, SpeakerIdentificationResult, SpeakerEmbeddingClient, SpeakerEmbeddingClientConfig};

/// æå– embedding çš„ç»“æœ
struct ExtractResult {
    embedding: Option<Vec<f32>>,
    estimated_gender: Option<String>,
}

/// åŸºäº Speaker Embedding çš„è¯´è¯è€…è¯†åˆ«å™¨
pub struct EmbeddingBasedSpeakerIdentifier {
    /// HTTP å®¢æˆ·ç«¯ï¼ˆç”¨äºè°ƒç”¨ Python æœåŠ¡ï¼‰
    embedding_client: SpeakerEmbeddingClient,
    /// ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯åŒä¸€è¯´è¯è€…
    similarity_threshold: f32,
    /// å·²æœ‰è¯´è¯è€…çš„ embedding åº“
    /// Key: speaker_id, Value: embedding vector
    speaker_embeddings: Arc<RwLock<HashMap<String, Vec<f32>>>>,
    /// ä¸‹ä¸€ä¸ªè¯´è¯è€… ID çš„è®¡æ•°å™¨
    next_speaker_id: Arc<RwLock<u32>>,
    /// æ¯ä¸ªè¯´è¯è€…çš„å‚è€ƒéŸ³é¢‘ç‰‡æ®µåˆ—è¡¨ï¼ˆç”¨äºåˆå¹¶ï¼‰
    /// Key: speaker_id, Value: Vec<å‚è€ƒéŸ³é¢‘ç‰‡æ®µ>
    /// å½“ç´¯ç§¯åˆ°è¶³å¤Ÿé•¿åº¦æ—¶ï¼Œä¼šåˆå¹¶æˆä¸€ä¸ªæ›´é•¿çš„å‚è€ƒéŸ³é¢‘
    speaker_reference_audio_segments: Arc<RwLock<HashMap<String, Vec<Vec<f32>>>>>,
    /// åˆå¹¶å‚è€ƒéŸ³é¢‘çš„æœ€å°æ€»é•¿åº¦ï¼ˆæ ·æœ¬æ•°ï¼Œ16kHzï¼Œçº¦ 10 ç§’ï¼‰
    min_merged_audio_samples: usize,
}

impl EmbeddingBasedSpeakerIdentifier {
    /// åˆ›å»ºæ–°çš„åŸºäº Speaker Embedding çš„è¯´è¯è€…è¯†åˆ«å™¨
    /// 
    /// # Arguments
    /// * `service_url` - HTTP æœåŠ¡ç«¯ç‚¹ï¼ˆä¾‹å¦‚ï¼šhttp://127.0.0.1:5003ï¼‰
    /// * `similarity_threshold` - ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
    pub fn new(
        service_url: Option<String>,
        similarity_threshold: f32,
    ) -> EngineResult<Self> {
        let config = SpeakerEmbeddingClientConfig {
            endpoint: service_url.unwrap_or_else(|| "http://127.0.0.1:5003".to_string()),
            timeout_ms: 5000,
        };
        
        let embedding_client = SpeakerEmbeddingClient::new(config)?;
        
        Ok(Self {
            embedding_client,
            similarity_threshold,
            speaker_embeddings: Arc::new(RwLock::new(HashMap::new())),
            next_speaker_id: Arc::new(RwLock::new(1)),
            speaker_reference_audio_segments: Arc::new(RwLock::new(HashMap::new())),
            min_merged_audio_samples: 160000,  // 16kHz * 10ç§’ = 160000 æ ·æœ¬
        })
    }
    
    /// ç”Ÿæˆæ–°çš„è¯´è¯è€… ID
    async fn generate_speaker_id(&self) -> String {
        let mut counter = self.next_speaker_id.write().await;
        let id = format!("speaker_{}", *counter);
        *counter += 1;
        id
    }
    
    /// æå–éŸ³é¢‘çš„ speaker embedding
    /// 
    /// é€šè¿‡ HTTP æœåŠ¡è°ƒç”¨ Python æœåŠ¡æå–ç‰¹å¾å‘é‡
    /// å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œè¿”å› None å’Œä¼°è®¡çš„æ€§åˆ«
    async fn extract_embedding(&self, audio_segment: &[AudioFrame]) -> EngineResult<ExtractResult> {
        use std::time::Instant;
        let start_time = Instant::now();
        
        if audio_segment.is_empty() {
            return Err(crate::error::EngineError::new("Empty audio segment"));
        }
        
        eprintln!("[SpeakerIdentifier] ===== Extract Embedding Started =====");
        eprintln!("[SpeakerIdentifier] Audio segment: {} frames", audio_segment.len());
        
        // 1. åˆå¹¶éŸ³é¢‘å¸§
        let merge_start = Instant::now();
        let mut merged_audio = Vec::new();
        let mut total_samples = 0;
        let mut sample_rate = 16000u32;
        for frame in audio_segment {
            // ç¡®ä¿é‡‡æ ·ç‡æ˜¯ 16kHzï¼ˆECAPA-TDNN è¦æ±‚ï¼‰
            if frame.sample_rate != 16000 {
                // TODO: é‡é‡‡æ ·åˆ° 16kHzï¼ˆå½“å‰å‡è®¾å·²ç»æ˜¯ 16kHzï¼‰
                eprintln!("[SpeakerIdentifier] âš  Warning: Audio sample rate is {}Hz, expected 16kHz", frame.sample_rate);
            }
            sample_rate = frame.sample_rate;
            merged_audio.extend_from_slice(&frame.data);
            total_samples += frame.data.len();
        }
        let merge_ms = merge_start.elapsed().as_millis() as u64;
        let duration_sec = total_samples as f32 / sample_rate as f32;
        let duration_ms = (duration_sec * 1000.0) as u64;
        eprintln!("[SpeakerIdentifier] Merged {} frames into {} samples in {}ms", 
                  audio_segment.len(), total_samples, merge_ms);
        eprintln!("[SpeakerIdentifier] Input audio duration: {:.2}s ({:.0}ms) at {}Hz", 
                  duration_sec, duration_ms, sample_rate);
        
        // 2. è°ƒç”¨ HTTP æœåŠ¡æå– embedding
        eprintln!("[SpeakerIdentifier] Calling Speaker Embedding service...");
        let extract_result = self.embedding_client.extract_embedding(&merged_audio).await?;
        
        let total_ms = start_time.elapsed().as_millis() as u64;
        
        if extract_result.use_default {
            let gender = extract_result.estimated_gender.as_deref().unwrap_or("unknown");
            eprintln!("[SpeakerIdentifier] âš  Using default voice (audio too short, estimated gender: {})", gender);
            eprintln!("[SpeakerIdentifier] âœ… Extract embedding completed in {}ms (using default voice)", total_ms);
            eprintln!("[SpeakerIdentifier] ==========================================");
            return Ok(ExtractResult {
                embedding: None,
                estimated_gender: extract_result.estimated_gender,
            });
        }
        
        let embedding = extract_result.embedding.ok_or_else(|| {
            EngineError::new("Embedding extraction returned no embedding")
        })?;
        
        eprintln!("[SpeakerIdentifier] âœ… Extract embedding completed in {}ms (merge: {}ms, service: {}ms)", 
                  total_ms, merge_ms, total_ms - merge_ms);
        eprintln!("[SpeakerIdentifier] ==========================================");
        
        Ok(ExtractResult {
            embedding: Some(embedding),
            estimated_gender: None,
        })
    }
    
    /// è®¡ç®—ä¸¤ä¸ª embedding çš„ä½™å¼¦ç›¸ä¼¼åº¦
    fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
        if a.len() != b.len() {
            return 0.0;
        }
        
        let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
        let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
        let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
        
        if norm_a == 0.0 || norm_b == 0.0 {
            return 0.0;
        }
        
        dot_product / (norm_a * norm_b)
    }
    
    /// æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„è¯´è¯è€…
    async fn find_most_similar_speaker(
        &self,
        embedding: &[f32],
    ) -> Option<(String, f32)> {
        let embeddings = self.speaker_embeddings.read().await;
        
        if embeddings.is_empty() {
            eprintln!("[SpeakerIdentifier] ğŸ“Š No existing speakers in database");
            return None;
        }
        
        eprintln!("[SpeakerIdentifier] ğŸ“Š Comparing with {} existing speaker(s)...", embeddings.len());
        
        let mut best_match: Option<(String, f32)> = None;
        let mut all_similarities: Vec<(String, f32)> = Vec::new();
        
        for (speaker_id, speaker_embedding) in embeddings.iter() {
            let similarity = Self::cosine_similarity(embedding, speaker_embedding);
            all_similarities.push((speaker_id.clone(), similarity));
            
            if let Some((_, best_sim)) = best_match {
                if similarity > best_sim {
                    best_match = Some((speaker_id.clone(), similarity));
                }
            } else {
                best_match = Some((speaker_id.clone(), similarity));
            }
        }
        
        // æ‰“å°æ‰€æœ‰ç›¸ä¼¼åº¦å€¼ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        eprintln!("[SpeakerIdentifier] ğŸ“Š Similarity scores:");
        for (sid, sim) in all_similarities.iter() {
            eprintln!("[SpeakerIdentifier]   - {}: {:.4}", sid, sim);
        }
        
        if let Some((best_id, best_sim)) = best_match.as_ref() {
            eprintln!("[SpeakerIdentifier] ğŸ¯ Best match: {} (similarity: {:.4})", best_id, best_sim);
        }
        
        best_match
    }
}

#[async_trait]
impl SpeakerIdentifier for EmbeddingBasedSpeakerIdentifier {
    async fn identify_speaker(
        &self,
        audio_segment: &[AudioFrame],
        _boundary_timestamp_ms: u64,
    ) -> EngineResult<SpeakerIdentificationResult> {
        // 1. æå–å½“å‰éŸ³é¢‘ç‰‡æ®µçš„ embeddingï¼ˆç”¨äºè¯´è¯è€…è¯†åˆ«å’ŒéŸ³è‰²ç‰¹å¾ï¼‰
        let extract_result = self.extract_embedding(audio_segment).await?;
        
        // 2. å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤å£°éŸ³ï¼ˆåŸºäºæ€§åˆ«ï¼‰
        if extract_result.embedding.is_none() {
            // éŸ³é¢‘å¤ªçŸ­ï¼Œæ— æ³•æå– embeddingï¼Œä½¿ç”¨é»˜è®¤å£°éŸ³
            // æ ¹æ®ä¼°è®¡çš„æ€§åˆ«åˆ†é…ä¸åŒçš„é»˜è®¤è¯´è¯è€… ID
            let estimated_gender = extract_result.estimated_gender.as_deref().unwrap_or("unknown");
            let default_speaker_id = match estimated_gender.to_lowercase().as_str() {
                "male" | "m" => "default_male".to_string(),
                "female" | "f" => "default_female".to_string(),
                _ => "default_speaker".to_string(),  // æœªçŸ¥æ€§åˆ«ä½¿ç”¨é€šç”¨é»˜è®¤
            };
            
            eprintln!("[SpeakerIdentifier] Using default speaker ID: {} (estimated gender: {})", 
                     default_speaker_id, estimated_gender);
            
            // ä¸ä¿å­˜å‚è€ƒéŸ³é¢‘ï¼ˆå› ä¸ºéŸ³é¢‘å¤ªçŸ­ï¼Œä¸é€‚åˆä½œä¸ºå‚è€ƒï¼‰
            return Ok(SpeakerIdentificationResult {
                speaker_id: default_speaker_id,
                is_new_speaker: false,  // é»˜è®¤è¯´è¯è€…ä¸ç®—æ–°è¯´è¯è€…
                confidence: 0.5,  // é»˜è®¤ç½®ä¿¡åº¦è¾ƒä½
                voice_embedding: None,  // æ²¡æœ‰ embedding
                reference_audio: None,  // éŸ³é¢‘å¤ªçŸ­ï¼Œä¸é€‚åˆä½œä¸ºå‚è€ƒ
                estimated_gender: extract_result.estimated_gender,  // ä¿å­˜æ€§åˆ«ä¿¡æ¯
            });
        }
        
        let embedding = extract_result.embedding.unwrap();
        
        // 3. æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å·²æœ‰è¯´è¯è€…
        let most_similar = self.find_most_similar_speaker(&embedding).await;
        
        // 4. åˆ¤æ–­æ˜¯å¦ä¸ºæ–°è¯´è¯è€…
        // ç­–ç•¥ï¼š
        // - å¦‚æœç›¸ä¼¼åº¦ >= 0.6ï¼šç›´æ¥åŒ¹é…ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰
        // - å¦‚æœç›¸ä¼¼åº¦åœ¨ 0.4-0.6 ä¹‹é—´ï¼šåŒ¹é…å¹¶æ›´æ–° embeddingï¼ˆä½¿ç”¨åŠ æƒå¹³å‡ï¼Œæé«˜ç¨³å®šæ€§ï¼‰
        // - å¦‚æœç›¸ä¼¼åº¦ < 0.4ï¼šåˆ›å»ºæ–°è¯´è¯è€…
        let (speaker_id, is_new_speaker, confidence) = if let Some((existing_id, similarity)) = most_similar {
            eprintln!("[SpeakerIdentifier] ğŸ” Found most similar speaker: {} (similarity: {:.3}, threshold: {:.3})", 
                     existing_id, similarity, self.similarity_threshold);
            if similarity >= self.similarity_threshold {
                // ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼ˆ>= 0.6ï¼‰ï¼Œç›´æ¥åŒ¹é…
                eprintln!("[SpeakerIdentifier] âœ… Matched existing speaker: {} (similarity: {:.3} >= {:.3})", 
                         existing_id, similarity, self.similarity_threshold);
                (existing_id, false, similarity)
            } else if similarity >= 0.4 {
                // ç›¸ä¼¼åº¦ä¸­ç­‰ï¼ˆ0.4-0.6ï¼‰ï¼ŒåŒ¹é…å¹¶æ›´æ–° embeddingï¼ˆä½¿ç”¨åŠ æƒå¹³å‡ï¼‰
                eprintln!("[SpeakerIdentifier] âš ï¸  Medium similarity: {:.3} (0.4 <= {:.3} < {:.3}), matching and updating embedding", 
                         similarity, similarity, self.similarity_threshold);
                let mut embeddings = self.speaker_embeddings.write().await;
                if let Some(existing_embedding) = embeddings.get_mut(&existing_id) {
                    // ä½¿ç”¨åŠ æƒå¹³å‡æ›´æ–° embeddingï¼ˆæ–° embedding æƒé‡ 0.3ï¼Œæ—§ embedding æƒé‡ 0.7ï¼‰
                    // è¿™æ ·å¯ä»¥å¹³æ»‘ embeddingï¼Œæé«˜ç¨³å®šæ€§
                    for (i, new_val) in embedding.iter().enumerate() {
                        if i < existing_embedding.len() {
                            existing_embedding[i] = existing_embedding[i] * 0.7 + new_val * 0.3;
                        }
                    }
                    eprintln!("[SpeakerIdentifier] ğŸ“Š Updated embedding for speaker '{}' (weighted average: 0.7 old + 0.3 new)", existing_id);
                }
                (existing_id, false, similarity)
            } else {
                // ç›¸ä¼¼åº¦å¤ªä½ï¼ˆ< 0.4ï¼‰ï¼Œè®¤ä¸ºæ˜¯æ–°è¯´è¯è€…
                eprintln!("[SpeakerIdentifier] âš ï¸  Similarity too low: {:.3} < 0.4, creating new speaker", similarity);
                let new_id = self.generate_speaker_id().await;
                let mut embeddings = self.speaker_embeddings.write().await;
                embeddings.insert(new_id.clone(), embedding.clone());
                (new_id, true, 1.0 - similarity)  // ç½®ä¿¡åº¦åŸºäºä¸ç›¸ä¼¼åº¦
            }
        } else {
            // æ²¡æœ‰å·²æœ‰è¯´è¯è€…ï¼Œåˆ›å»ºç¬¬ä¸€ä¸ª
            eprintln!("[SpeakerIdentifier] ğŸ†• No existing speakers found, creating first speaker");
            let new_id = self.generate_speaker_id().await;
            let mut embeddings = self.speaker_embeddings.write().await;
            embeddings.insert(new_id.clone(), embedding.clone());
            (new_id, true, 0.9)  // ç¬¬ä¸€ä¸ªè¯´è¯è€…ï¼Œç½®ä¿¡åº¦è¾ƒé«˜
        };
        
        // 5. ä¿å­˜å‚è€ƒéŸ³é¢‘ï¼ˆç”¨äº zero-shot TTSï¼‰
        // ç­–ç•¥ï¼šå¦‚æœæ˜¯åŒä¸€è¯´è¯è€…ï¼Œç´¯ç§¯å¤šä¸ªéŸ³é¢‘ç‰‡æ®µï¼›å¦‚æœæ˜¯æ–°è¯´è¯è€…ï¼Œä½¿ç”¨å½“å‰ç‰‡æ®µ
        let reference_audio = if !audio_segment.is_empty() {
            // åˆå¹¶éŸ³é¢‘å¸§ä½œä¸ºå‚è€ƒéŸ³é¢‘
            let mut current_audio = Vec::new();
            for frame in audio_segment {
                current_audio.extend_from_slice(&frame.data);
            }
            
            if !is_new_speaker {
                // åŒä¸€è¯´è¯è€…ï¼šç´¯ç§¯éŸ³é¢‘ç‰‡æ®µ
                let mut segments = self.speaker_reference_audio_segments.write().await;
                let segments_list = segments.entry(speaker_id.clone()).or_insert_with(Vec::new);
                segments_list.push(current_audio.clone());
                
                // è®¡ç®—ç´¯ç§¯çš„æ€»é•¿åº¦
                let total_samples: usize = segments_list.iter().map(|seg| seg.len()).sum();
                eprintln!("[SpeakerIdentifier] ğŸ“Š Accumulating reference audio for speaker '{}': {} segments, {} samples ({:.2}s @ 16kHz)", 
                         speaker_id, segments_list.len(), total_samples, total_samples as f32 / 16000.0);
                
                // å¦‚æœç´¯ç§¯çš„éŸ³é¢‘è¶³å¤Ÿé•¿ï¼Œåˆå¹¶æ‰€æœ‰ç‰‡æ®µ
                if total_samples >= self.min_merged_audio_samples {
                    eprintln!("[SpeakerIdentifier] ğŸ”— Merging {} reference audio segments for speaker '{}' (total: {:.2}s)", 
                             segments_list.len(), speaker_id, total_samples as f32 / 16000.0);
                    let merged: Vec<f32> = segments_list.iter().flat_map(|seg| seg.iter().cloned()).collect();
                    // æ¸…ç©ºç‰‡æ®µåˆ—è¡¨ï¼Œä½¿ç”¨åˆå¹¶åçš„éŸ³é¢‘
                    segments_list.clear();
                    segments_list.push(merged.clone());
                    // æ ‡è®°ä¸ºå·²åˆå¹¶ï¼Œéœ€è¦æ›´æ–° YourTTS ç¼“å­˜
                    eprintln!("[SpeakerIdentifier] âœ… Merged reference audio ready for speaker '{}' ({} samples, {:.2}s) - should update YourTTS cache", 
                             speaker_id, merged.len(), merged.len() as f32 / 16000.0);
                    Some(merged)
                } else {
                    // ç´¯ç§¯çš„éŸ³é¢‘è¿˜ä¸å¤Ÿé•¿ï¼Œä½¿ç”¨å½“å‰ç‰‡æ®µï¼ˆä½†ä¼šåœ¨åç»­åˆå¹¶ï¼‰
                    Some(current_audio)
                }
            } else {
                // æ–°è¯´è¯è€…ï¼šä½¿ç”¨å½“å‰ç‰‡æ®µï¼Œå¹¶åˆå§‹åŒ–ç‰‡æ®µåˆ—è¡¨
                let mut segments = self.speaker_reference_audio_segments.write().await;
                segments.insert(speaker_id.clone(), vec![current_audio.clone()]);
                eprintln!("[SpeakerIdentifier] ğŸ†• New speaker '{}': initializing reference audio ({} samples, {:.2}s @ 16kHz)", 
                         speaker_id, current_audio.len(), current_audio.len() as f32 / 16000.0);
                Some(current_audio)
            }
        } else {
            None
        };
        
        // è·å–ä¼°è®¡çš„æ€§åˆ«ä¿¡æ¯ï¼ˆå³ä½¿éŸ³é¢‘è¶³å¤Ÿé•¿ï¼Œä¹Ÿä¿å­˜æ€§åˆ«ä¿¡æ¯ç”¨äºé€‰æ‹©é»˜è®¤éŸ³è‰²ï¼‰
        let estimated_gender = extract_result.estimated_gender;
        if let Some(ref gender) = estimated_gender {
            eprintln!("[SpeakerIdentifier] ğŸ‘¤ Estimated gender: {} (will use for default voice selection if needed)", gender);
        }
        
        Ok(SpeakerIdentificationResult {
            speaker_id,
            is_new_speaker,
            confidence,
            voice_embedding: Some(embedding),  // è¿”å›æå–çš„ embedding ç”¨äº Voice Cloning
            reference_audio,
            estimated_gender,  // ä¿å­˜æ€§åˆ«ä¿¡æ¯ï¼Œç”¨äºé€‰æ‹©é»˜è®¤éŸ³è‰²
        })
    }
    
    async fn reset(&self) -> EngineResult<()> {
        let mut embeddings = self.speaker_embeddings.write().await;
        let mut counter = self.next_speaker_id.write().await;
        let mut segments = self.speaker_reference_audio_segments.write().await;
        
        embeddings.clear();
        segments.clear();
        *counter = 1;
        
        Ok(())
    }
    
    fn get_info(&self) -> String {
        format!(
            "EmbeddingBasedSpeakerIdentifier(threshold={})",
            self.similarity_threshold
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    fn create_test_frame(timestamp_ms: u64) -> AudioFrame {
        AudioFrame {
            sample_rate: 16000,
            channels: 1,
            data: vec![0.0; 512],
            timestamp_ms,
        }
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦ HTTP æœåŠ¡è¿è¡Œ
    async fn test_first_speaker() {
        let identifier = EmbeddingBasedSpeakerIdentifier::new(
            Some("http://127.0.0.1:5003".to_string()),
            0.7,
        ).unwrap();
        
        let result = identifier.identify_speaker(&[create_test_frame(0)], 0).await.unwrap();
        assert_eq!(result.speaker_id, "speaker_1");
        assert!(result.is_new_speaker);
    }
    
    #[tokio::test]
    #[ignore]  // éœ€è¦ HTTP æœåŠ¡è¿è¡Œ
    async fn test_reset() {
        let identifier = EmbeddingBasedSpeakerIdentifier::new(
            Some("http://127.0.0.1:5003".to_string()),
            0.7,
        ).unwrap();
        
        identifier.identify_speaker(&[create_test_frame(0)], 0).await.unwrap();
        identifier.reset().await.unwrap();
        
        let result = identifier.identify_speaker(&[create_test_frame(1000)], 1000).await.unwrap();
        assert_eq!(result.speaker_id, "speaker_1");
        assert!(result.is_new_speaker);
    }
    
    #[tokio::test]
    async fn test_cosine_similarity() {
        let a = vec![1.0, 0.0, 0.0];
        let b = vec![1.0, 0.0, 0.0];
        let similarity = EmbeddingBasedSpeakerIdentifier::cosine_similarity(&a, &b);
        assert!((similarity - 1.0).abs() < 0.001);
        
        let c = vec![0.0, 1.0, 0.0];
        let similarity = EmbeddingBasedSpeakerIdentifier::cosine_similarity(&a, &c);
        assert!((similarity - 0.0).abs() < 0.001);
    }
}


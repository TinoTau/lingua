// core/engine/src/asr_whisper/faster_whisper_streaming.rs
// Faster-Whisper ASR çš„æµå¼å®ç°ï¼ˆé€šè¿‡ HTTP è°ƒç”¨ Python æœåŠ¡ï¼‰

use std::sync::{Arc, Mutex};
use async_trait::async_trait;

use crate::asr_streaming::{AsrRequest, AsrResult, AsrStreaming, AsrStreamingExt};
use crate::asr_filters::is_meaningless_transcript_with_context;
use crate::asr_http_client::AsrHttpClient;
use crate::error::{EngineError, EngineResult};
use crate::types::{AudioFrame, PartialTranscript, StableTranscript};
use crate::asr_whisper::audio_preprocessing::{preprocess_audio_frame, accumulate_audio_frames};

/// æµå¼æ¨ç†é…ç½®ï¼ˆåŸºäºè‡ªç„¶åœé¡¿ï¼‰
#[derive(Debug, Clone)]
struct StreamingConfig {
    /// éƒ¨åˆ†ç»“æœæ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
    partial_update_interval_seconds: f64,
    /// ä¸Šæ¬¡éƒ¨åˆ†ç»“æœæ›´æ–°çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    last_partial_update_ms: u64,
    /// æ˜¯å¦å¯ç”¨æµå¼æ¨ç†ï¼ˆéƒ¨åˆ†ç»“æœè¾“å‡ºï¼‰
    enabled: bool,
}

/// Faster-Whisper ASR çš„æµå¼å®ç°ï¼ˆé€šè¿‡ HTTP è°ƒç”¨ Python æœåŠ¡ï¼‰
/// 
/// æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
/// 1. åŸºç¡€æ¨¡å¼ï¼šæ¯æ¬¡ `infer()` è°ƒç”¨æ—¶è¿›è¡Œå®Œæ•´æ¨ç†ï¼ˆå½“å‰é»˜è®¤ï¼‰
/// 2. VAD é›†æˆæ¨¡å¼ï¼šä½¿ç”¨ `accumulate_frame()` ç´¯ç§¯å¸§ï¼Œåœ¨ `infer_on_boundary()` æ—¶æ¨ç†
/// 3. æµå¼æ¨¡å¼ï¼šä½¿ç”¨æ»‘åŠ¨çª—å£å®šæœŸæ¨ç†ï¼Œè¿”å›éƒ¨åˆ†ç»“æœï¼ˆæ­¥éª¤ 3.2ï¼‰
pub struct FasterWhisperAsrStreaming {
    /// HTTP å®¢æˆ·ç«¯
    http_client: Arc<AsrHttpClient>,
    /// éŸ³é¢‘å¸§ç¼“å†²åŒºï¼ˆç´¯ç§¯æ‰€æœ‰æ”¶åˆ°çš„å¸§ï¼‰
    audio_buffer: Arc<Mutex<Vec<AudioFrame>>>,
    /// å†å²éŸ³é¢‘å¸§ç¼“å†²åŒºï¼ˆç”¨äºè¯´è¯è€…è¯†åˆ«ï¼Œä¿ç•™æœ€è¿‘ 2-3 ç§’çš„éŸ³é¢‘ï¼‰
    history_buffer: Arc<Mutex<Vec<AudioFrame>>>,
    /// æ˜¯å¦å·²åˆå§‹åŒ–
    initialized: Arc<Mutex<bool>>,
    /// æµå¼æ¨ç†é…ç½®
    streaming_config: Arc<Mutex<StreamingConfig>>,
    /// ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆæœ€è¿‘ 2-3 å¥çš„æ–‡æœ¬ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡å‚è€ƒï¼‰
    context_cache: Arc<Mutex<Vec<String>>>,
    /// è¯­è¨€è®¾ç½®ï¼ˆå¯é€‰ï¼‰
    language: Arc<Mutex<Option<String>>>,
}

impl FasterWhisperAsrStreaming {
    /// ç®€å•çš„å¥å­åˆ†å‰²å‡½æ•°ï¼ˆç”¨äºæå–æœ€åä¸€å¥ï¼‰
    /// æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·ç­‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
    fn split_into_sentences_simple(text: &str) -> Vec<String> {
        let mut sentences = Vec::new();
        let mut current_sentence = String::new();
        
        for ch in text.chars() {
            current_sentence.push(ch);
            
            // æ£€æŸ¥æ˜¯å¦ä¸ºå¥å­ç»“æŸæ ‡ç‚¹
            let is_sentence_end = matches!(
                ch,
                '.' | '!' | '?' | 'ã€‚' | 'ï¼' | 'ï¼Ÿ'
            );
            
            if is_sentence_end {
                let trimmed = current_sentence.trim().to_string();
                if !trimmed.is_empty() {
                    sentences.push(trimmed);
                }
                current_sentence.clear();
            }
        }
        
        // å¤„ç†æœ€åä¸€ä¸ªå¥å­ï¼ˆå¦‚æœæ²¡æœ‰ç»“æŸæ ‡ç‚¹ï¼‰
        let trimmed = current_sentence.trim().to_string();
        if !trimmed.is_empty() {
            sentences.push(trimmed);
        }
        
        sentences
    }
    /// åˆ›å»ºæ–°çš„ FasterWhisperAsrStreaming å®ä¾‹
    /// 
    /// # Arguments
    /// * `service_url` - ASR æœåŠ¡çš„ URLï¼ˆä¾‹å¦‚ï¼š"http://127.0.0.1:6006"ï¼‰
    /// * `timeout_secs` - HTTP è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    pub fn new(service_url: String, timeout_secs: u64) -> Self {
        let http_client = Arc::new(AsrHttpClient::new(service_url, timeout_secs));
        
        Self {
            http_client,
            audio_buffer: Arc::new(Mutex::new(Vec::new())),
            history_buffer: Arc::new(Mutex::new(Vec::new())),
            initialized: Arc::new(Mutex::new(false)),
            streaming_config: Arc::new(Mutex::new(StreamingConfig {
                partial_update_interval_seconds: 1.0,
                last_partial_update_ms: 0,
                enabled: false,
            })),
            context_cache: Arc::new(Mutex::new(Vec::new())),
            language: Arc::new(Mutex::new(None)),
        }
    }

    /// è·å–éŸ³é¢‘ç¼“å†²åŒºä¸­çš„æ‰€æœ‰å¸§å¹¶é¢„å¤„ç†ä¸ºéŸ³é¢‘æ•°æ®
    /// 
    /// # Returns
    /// è¿”å›é¢„å¤„ç†åçš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz å•å£°é“ PCM f32ï¼‰
    pub(crate) fn get_and_preprocess_audio(&self) -> EngineResult<Vec<f32>> {
        let frames = {
            let buffer = self.audio_buffer.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
            buffer.clone()
        };

        if frames.is_empty() {
            return Ok(Vec::new());
        }

        // é¢„å¤„ç†æ‰€æœ‰ç´¯ç§¯çš„å¸§
        let audio_data = accumulate_audio_frames(&frames)
            .map_err(|e| EngineError::new(format!("Failed to preprocess audio frames: {}", e)))?;

        Ok(audio_data)
    }

    /// å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼çš„å­—èŠ‚
    /// 
    /// # Arguments
    /// * `audio_data` - éŸ³é¢‘æ•°æ®ï¼ˆ16kHz å•å£°é“ PCM f32ï¼‰
    /// 
    /// # Returns
    /// è¿”å› WAV æ ¼å¼çš„å­—èŠ‚æ•°æ®
    fn audio_to_wav_bytes(&self, audio_data: &[f32]) -> EngineResult<Vec<u8>> {
        use hound::{WavWriter, WavSpec};
        use std::io::Cursor;

        let spec = WavSpec {
            channels: 1,
            sample_rate: 16000,
            bits_per_sample: 16,
            sample_format: hound::SampleFormat::Int,
        };

        let mut buffer = Vec::new();
        {
            let mut writer = WavWriter::new(Cursor::new(&mut buffer), spec)
                .map_err(|e| EngineError::new(format!("Failed to create WAV writer: {}", e)))?;
            
            for &sample in audio_data {
                // å°† f32 (-1.0 åˆ° 1.0) è½¬æ¢ä¸º i16
                let sample_i16 = (sample.clamp(-1.0, 1.0) * 32767.0) as i16;
                writer.write_sample(sample_i16)
                    .map_err(|e| EngineError::new(format!("Failed to write WAV sample: {}", e)))?;
            }
            
            writer.finalize()
                .map_err(|e| EngineError::new(format!("Failed to finalize WAV: {}", e)))?;
        }

        Ok(buffer)
    }

    /// è·å–ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆå‰ 2 å¥çš„æ–‡æœ¬ï¼‰
    /// 
    /// # Returns
    /// è¿”å›ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆå¦‚æœç¼“å­˜ä¸ä¸ºç©ºï¼‰ï¼Œå¦åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    pub(crate) fn get_context_prompt(&self) -> EngineResult<String> {
        let cache = self.context_cache.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock context cache: {}", e)))?;
        
        if !cache.is_empty() {
            // åªå‘é€æœ€åä¸€å¥ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆé¿å…é‡å¤å’Œæ±¡æŸ“ï¼‰
            // è¿™æ ·æ—¢èƒ½æä¾›ä¸Šä¸‹æ–‡æé«˜å‡†ç¡®åº¦ï¼Œåˆèƒ½é¿å…å‘é€å¤šå¥å¯¼è‡´çš„é‡å¤è¯†åˆ«
            let last_sentence = cache.last().unwrap().clone();
            let context_preview = last_sentence.chars().take(100).collect::<String>();
            
            eprintln!("[ASR] ğŸ“š Context Cache: Found {} previous sentence(s), using last one only", cache.len());
            eprintln!("[ASR] ğŸ“š Using context ({} chars): \"{}\"", last_sentence.len(), context_preview);
            
            Ok(last_sentence)
        } else {
            eprintln!("[ASR] ğŸ“š Context Cache: Empty (no previous sentences)");
            Ok(String::new())
        }
    }

    /// æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆæ·»åŠ æ–°å¥å­ï¼Œåªä¿ç•™æœ€å 1 å¥ï¼‰
    /// 
    /// # Arguments
    /// * `text` - è¦æ·»åŠ åˆ°ç¼“å­˜çš„æ–‡æœ¬
    /// 
    /// # Note
    /// åªä¿ç•™æœ€å 1 å¥ï¼Œå› ä¸ºå‘é€ç»™ faster-whisper çš„ä¸Šä¸‹æ–‡åªéœ€è¦æœ€åä¸€å¥
    /// è¿™æ ·å¯ä»¥é¿å…ç¼“å­˜ç´¯ç§¯å¯¼è‡´çš„é‡å¤è¯†åˆ«é—®é¢˜
    pub(crate) fn update_context_cache(&self, text: &str) -> EngineResult<()> {
        let trimmed_text = text.trim();
        if trimmed_text.is_empty() {
            eprintln!("[ASR] âš ï¸  Context Cache: Skipped update (empty transcript)");
            return Ok(());
        }

        let mut cache = self.context_cache.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock context cache: {}", e)))?;
        
        // åªä¿ç•™æœ€å 1 å¥ï¼ˆæ›¿æ¢è€Œä¸æ˜¯è¿½åŠ ï¼‰
        // è¿™æ ·æ¯æ¬¡å‘é€ç»™ faster-whisper çš„ä¸Šä¸‹æ–‡éƒ½æ˜¯æœ€æ–°çš„ï¼Œä¸ä¼šç´¯ç§¯é‡å¤
        cache.clear();
        cache.push(trimmed_text.to_string());
        
        eprintln!("[ASR Faster-Whisper] ğŸ’¾ Context Cache: Updated (keeping only last sentence)");
        eprintln!("[ASR Faster-Whisper]   Last sentence: \"{}\"", trimmed_text.chars().take(80).collect::<String>());
        
        Ok(())
    }

    /// åœ¨ VAD æ£€æµ‹åˆ°è¾¹ç•Œæ—¶è¿›è¡Œæ¨ç†
    /// 
    /// # Returns
    /// è¿”å› ASR ç»“æœï¼ˆåŒ…å«éƒ¨åˆ†ç»“æœå’Œæœ€ç»ˆç»“æœï¼‰
    pub async fn infer_on_boundary(&self) -> EngineResult<AsrResult> {
        eprintln!("[ASR] ==========================================");
        eprintln!("[ASR] ğŸš€ Starting ASR inference on boundary...");
        
        // 1. å…ˆè·å–å¹¶æ¸…ç©ºç¼“å†²åŒºï¼ˆç¡®ä¿å³ä½¿åç»­å¤±è´¥ï¼Œç¼“å†²åŒºä¹Ÿè¢«æ¸…ç©ºï¼‰
        // è¿™æ ·å¯ä»¥é˜²æ­¢ç¼“å†²åŒºç´¯ç§¯ï¼Œå³ä½¿è¯·æ±‚å¤±è´¥ä¹Ÿä¸ä¼šå¯¼è‡´ä¸‹æ¬¡å¤„ç†æ›´é•¿çš„éŸ³é¢‘
        let (audio_data, frames_to_keep) = {
            let mut buffer = self.audio_buffer.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
            
            // å…‹éš†ç¼“å†²åŒºå†…å®¹ç”¨äºå¤„ç†
            let frames = buffer.clone();
            
            // ç«‹å³æ¸…ç©ºç¼“å†²åŒºï¼ˆé˜²æ­¢ç´¯ç§¯ï¼‰
            buffer.clear();
            
            drop(buffer);
            
            // é¢„å¤„ç†éŸ³é¢‘æ•°æ®
            if frames.is_empty() {
                eprintln!("[ASR] âš ï¸  Audio buffer is empty, skipping inference");
                eprintln!("[ASR] ==========================================");
                return Ok(AsrResult {
                    partial: None,
                    final_transcript: None,
                });
            }
            
            let audio_data = accumulate_audio_frames(&frames)
                .map_err(|e| EngineError::new(format!("Failed to preprocess audio frames: {}", e)))?;
            
            (audio_data, frames)
        };
        
        let audio_duration_sec = audio_data.len() as f32 / 16000.0;
        eprintln!("[ASR] ğŸ“Š Preprocessed audio: {} samples ({:.2}s @ 16kHz)", 
                 audio_data.len(), audio_duration_sec);

        // 2. è·å–ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆç”¨äº faster-whisper å’Œè¿‡æ»¤åˆ¤æ–­ï¼‰
        // æ³¨æ„ï¼šä¸Šä¸‹æ–‡å¯ä»¥æé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼Œä½†éœ€è¦ç¡®ä¿ç¼“å­˜ä¸è¢«æ±¡æŸ“
        let context_prompt = self.get_context_prompt()?;
        let context_for_filter = context_prompt.clone(); // å…‹éš†ç”¨äºåç»­è¿‡æ»¤åˆ¤æ–­
        
        // 3. å°†éŸ³é¢‘è½¬æ¢ä¸º WAV å­—èŠ‚
        let wav_bytes = self.audio_to_wav_bytes(&audio_data)?;
        eprintln!("[ASR] ğŸ“¦ Converted audio to WAV: {} bytes (sending to Faster-Whisper service)", wav_bytes.len());
        
        // 4. è·å–è¯­è¨€è®¾ç½®
        let language = {
            let lang = self.language.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock language: {}", e)))?;
            lang.clone()
        };
        
        // 5. è°ƒç”¨ HTTP æœåŠ¡è¿›è¡Œè½¬å½•
        let asr_response = self.http_client.transcribe(
            wav_bytes,
            context_prompt,
            language,
        ).await.map_err(|e| {
            eprintln!("[ASR] âŒ HTTP request failed: {}", e);
            // æ³¨æ„ï¼šç¼“å†²åŒºå·²ç»åœ¨æ­¥éª¤1ä¸­æ¸…ç©ºäº†ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡æ¸…ç©º
            e
        })?;
        
        // 6. å¤„ç†è¯†åˆ«ç»“æœ
        let transcript_text = asr_response.text.trim().to_string();
        eprintln!("[ASR] âœ… Transcription completed: {} segment(s)", asr_response.segments.len());
        if asr_response.segments.len() > 1 {
            for (i, seg) in asr_response.segments.iter().enumerate() {
                eprintln!("[ASR]   Segment {}: \"{}\"", i + 1, seg.chars().take(80).collect::<String>());
            }
        }
        eprintln!("[ASR] ğŸ“ Final transcript: \"{}\"", transcript_text.chars().take(100).collect::<String>());
        if let Some(ref lang) = asr_response.language {
            eprintln!("[ASR] ğŸŒ Detected language: {}", lang);
        }

        // 7. æ›´æ–°ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆåªæ›´æ–°æœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼‰
        // å…³é”®ï¼šåªå­˜å‚¨å’Œä¼ é€’æœ€åä¸€å¥ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„è¯†åˆ«ç»“æœ
        // faster-whisper çš„ initial_prompt åº”è¯¥åªåŒ…å«"ä¸Šä¸€æ¡è¯­å¥"ï¼Œè€Œä¸æ˜¯"ä¸Šä¸€æ¬¡çš„å®Œæ•´è¯†åˆ«ç»“æœ"
        // ä½¿ç”¨å¸¦ä¸Šä¸‹æ–‡çš„è¿‡æ»¤å‡½æ•°ï¼Œå¯¹"è°¢è°¢å¤§å®¶"ã€"æ„Ÿè°¢è§‚çœ‹"ç­‰æ„Ÿè°¢è¯­è¿›è¡Œä¸Šä¸‹æ–‡åˆ¤æ–­
        if !is_meaningless_transcript_with_context(&transcript_text, &context_for_filter) {
            // ä»è¯†åˆ«ç»“æœä¸­æå–æœ€åä¸€å¥ï¼ˆå¦‚æœåŒ…å«å¤šä¸ªå¥å­ï¼‰
            let last_sentence = if asr_response.segments.len() > 1 {
                // å¦‚æœæœ‰å¤šä¸ª segmentsï¼Œä½¿ç”¨æœ€åä¸€ä¸ª segment
                asr_response.segments.last().unwrap().clone()
            } else {
                // å¦‚æœåªæœ‰ä¸€ä¸ª segmentï¼Œå°è¯•æŒ‰å¥å­åˆ†å‰²ï¼Œå–æœ€åä¸€å¥
                let sentences = Self::split_into_sentences_simple(&transcript_text);
                if sentences.len() > 1 {
                    sentences.last().unwrap().clone()
                } else {
                    transcript_text.trim().to_string()
                }
            };
            
            // æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ç¼“å­˜çš„å†…å®¹ç›¸åŒ
            let should_update = {
                let cache = self.context_cache.lock()
                    .map_err(|e| EngineError::new(format!("Failed to lock context cache: {}", e)))?;
                
                // å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œç›´æ¥æ·»åŠ 
                if cache.is_empty() {
                    true
                } else {
                    // åªæ£€æŸ¥æ˜¯å¦ä¸æœ€åä¸€å¥å®Œå…¨ç›¸åŒ
                    let last_sentence_trimmed = last_sentence.trim();
                    let cached_sentence = cache.last().unwrap().trim();
                    last_sentence_trimmed.to_lowercase() != cached_sentence.to_lowercase()
                }
            };
            
            if should_update {
                self.update_context_cache(&last_sentence)?;
            } else {
                eprintln!("[ASR] âš ï¸  Context Cache: Skipped update (duplicate text: \"{}\")", 
                         last_sentence.chars().take(50).collect::<String>());
            }
        } else {
            eprintln!("[ASR] âš ï¸  Context Cache: Skipped update (meaningless text: \"{}\")", 
                     transcript_text.chars().take(50).collect::<String>());
        }

        // 8. å°†å·²å¤„ç†çš„å¸§æ·»åŠ åˆ°å†å²ç¼“å†²åŒºï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
        {
            let mut history = self.history_buffer.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock history buffer: {}", e)))?;
            history.extend(frames_to_keep);
            
            // åªä¿ç•™æœ€è¿‘ 2-3 ç§’çš„éŸ³é¢‘ï¼ˆå‡è®¾ 16kHzï¼Œçº¦ 32000-48000 æ ·æœ¬ï¼‰
            let max_samples = 48000;
            let mut total_samples = 0;
            let mut keep_from = 0;
            for (i, frame) in history.iter().rev().enumerate() {
                total_samples += frame.data.len();
                if total_samples > max_samples {
                    keep_from = history.len() - i;
                    break;
                }
            }
            if keep_from > 0 {
                history.drain(0..keep_from);
            }
        }
        
        // æ³¨æ„ï¼šç¼“å†²åŒºå·²ç»åœ¨æ­¥éª¤1ä¸­æ¸…ç©ºäº†ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡æ¸…ç©º
        
        eprintln!("[ASR] âœ… ASR inference completed successfully");
        eprintln!("[ASR] ==========================================");

        // 11. æ„é€ ç»“æœ
        if transcript_text.is_empty() {
            return Ok(AsrResult {
                partial: None,
                final_transcript: None,
            });
        }

        let result = AsrResult {
            partial: Some(PartialTranscript {
                text: transcript_text.clone(),
                confidence: 0.95,  // faster-whisper ä¸ç›´æ¥æä¾›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
                is_final: true,
            }),
            final_transcript: Some(StableTranscript {
                text: transcript_text,
                speaker_id: None,
                language: asr_response.language.unwrap_or_else(|| "unknown".to_string()),
            }),
        };

        Ok(result)
    }

    /// è·å–ç´¯ç§¯çš„éŸ³é¢‘å¸§ï¼ˆç”¨äºè¯´è¯è€…è¯†åˆ«ç­‰ï¼‰
    pub fn get_accumulated_frames(&self) -> EngineResult<Vec<AudioFrame>> {
        let buffer = self.audio_buffer.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
        Ok(buffer.clone())
    }

    /// è®¾ç½®è¯­è¨€
    /// 
    /// # Arguments
    /// * `language` - è¯­è¨€ä»£ç ï¼ˆå¦‚ "en", "zh", "ja"ï¼‰ï¼Œ`None` è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    pub fn set_language(&self, language: Option<String>) -> EngineResult<()> {
        let mut lang = self.language.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock language: {}", e)))?;
        *lang = language;
        Ok(())
    }

    /// è·å–å½“å‰è®¾ç½®çš„è¯­è¨€
    pub fn get_language(&self) -> EngineResult<Option<String>> {
        let lang = self.language.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock language: {}", e)))?;
        Ok(lang.clone())
    }

    /// ç´¯ç§¯éŸ³é¢‘å¸§åˆ°ç¼“å†²åŒºï¼ˆç”¨äº VAD é›†æˆæ¨¡å¼ï¼‰
    /// 
    /// # Arguments
    /// * `frame` - éŸ³é¢‘å¸§
    pub fn accumulate_frame(&self, frame: AudioFrame) -> EngineResult<()> {
        let mut buffer = self.audio_buffer.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
        buffer.push(frame);
        Ok(())
    }
    
    /// æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
    pub fn clear_buffer(&self) -> EngineResult<()> {
        let mut buffer = self.audio_buffer.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
        buffer.clear();
        Ok(())
    }
}

#[async_trait]
impl AsrStreaming for FasterWhisperAsrStreaming {
    async fn initialize(&self) -> EngineResult<()> {
        // æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€ï¼ˆåœ¨é”ä¹‹å¤–ï¼Œé¿å…è·¨è¶Š awaitï¼‰
        eprintln!("[ASR] ğŸ” Checking Faster-Whisper service health...");
        match self.http_client.health_check().await {
            Ok(true) => {
                eprintln!("[ASR] âœ… Service health check passed (Faster-Whisper)");
            }
            Ok(false) => {
                eprintln!("[ASR] âš ï¸  Service health check returned false (Faster-Whisper)");
                eprintln!("[ASR] âš ï¸  Please ensure the ASR service is running on the configured port");
            }
            Err(e) => {
                eprintln!("[ASR] âš ï¸  Service health check failed: {} (Faster-Whisper)", e);
                eprintln!("[ASR] âš ï¸  Please ensure the ASR service is running. Check:");
                eprintln!("[ASR]    1. Is the Python ASR service started? (port 6006 by default)");
                eprintln!("[ASR]    2. Is the service URL correct? (check ASR_SERVICE_URL env var)");
                eprintln!("[ASR]    3. Is the model loaded? (check ASR service logs)");
                eprintln!("[ASR] âš ï¸  Continuing anyway, but ASR requests may fail...");
            }
        }
        
        // åœ¨ await ä¹‹åè®¾ç½®åˆå§‹åŒ–æ ‡å¿—
        let mut initialized = self.initialized.lock()
            .map_err(|e| EngineError::new(format!("Failed to lock initialized flag: {}", e)))?;
        *initialized = true;
        Ok(())
    }

    async fn infer(&self, request: AsrRequest) -> EngineResult<AsrResult> {
        // 1. å°†æ–°çš„éŸ³é¢‘å¸§æ·»åŠ åˆ°ç¼“å†²åŒº
        {
            let mut buffer = self.audio_buffer.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock audio buffer: {}", e)))?;
            buffer.push(request.frame.clone());
        }

        // 2. æ£€æŸ¥æ˜¯å¦å¯ç”¨æµå¼æ¨ç†
        let config = {
            let config_guard = self.streaming_config.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock streaming config: {}", e)))?;
            config_guard.clone()
        };

        if !config.enabled {
            // æµå¼æ¨ç†æœªå¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ
            return Ok(AsrResult {
                partial: None,
                final_transcript: None,
            });
        }

        // 3. æ£€æŸ¥æ˜¯å¦åº”è¯¥è¾“å‡ºéƒ¨åˆ†ç»“æœ
        let current_timestamp_ms = request.frame.timestamp_ms;
        let should_update = current_timestamp_ms.saturating_sub(config.last_partial_update_ms)
            >= (config.partial_update_interval_seconds * 1000.0) as u64;

        if !should_update {
            return Ok(AsrResult {
                partial: None,
                final_transcript: None,
            });
        }

        // 4. æ›´æ–°ä¸Šæ¬¡æ›´æ–°æ—¶é—´
        {
            let mut config_guard = self.streaming_config.lock()
                .map_err(|e| EngineError::new(format!("Failed to lock streaming config: {}", e)))?;
            config_guard.last_partial_update_ms = current_timestamp_ms;
        }

        // 5. æ‰§è¡Œæ¨ç†ï¼ˆè¿™é‡Œå¯ä»¥è°ƒç”¨ infer_on_boundary çš„é€»è¾‘ï¼Œä½†è¿”å›éƒ¨åˆ†ç»“æœï¼‰
        // æ³¨æ„ï¼šæµå¼æ¨ç†çš„éƒ¨åˆ†ç»“æœè¾“å‡ºéœ€è¦æ›´å¤æ‚çš„å®ç°ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        Ok(AsrResult {
            partial: None,
            final_transcript: None,
        })
    }

    async fn finalize(&self) -> EngineResult<()> {
        // æ¸…ç©ºç¼“å†²åŒº
        self.clear_buffer()?;
        Ok(())
    }
}

#[async_trait]
impl AsrStreamingExt for FasterWhisperAsrStreaming {
    fn accumulate_frame(&self, frame: AudioFrame) -> EngineResult<()> {
        FasterWhisperAsrStreaming::accumulate_frame(self, frame)
    }

    fn get_accumulated_frames(&self) -> EngineResult<Vec<AudioFrame>> {
        FasterWhisperAsrStreaming::get_accumulated_frames(self)
    }

    fn clear_buffer(&self) -> EngineResult<()> {
        FasterWhisperAsrStreaming::clear_buffer(self)
    }

    fn set_language(&self, language: Option<String>) -> EngineResult<()> {
        FasterWhisperAsrStreaming::set_language(self, language)
    }

    fn get_language(&self) -> EngineResult<Option<String>> {
        FasterWhisperAsrStreaming::get_language(self)
    }

    async fn infer_on_boundary(&self) -> EngineResult<AsrResult> {
        FasterWhisperAsrStreaming::infer_on_boundary(self).await
    }
}



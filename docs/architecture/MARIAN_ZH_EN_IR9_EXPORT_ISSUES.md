# Marian zh-en IR 9 å¯¼å‡ºæ–¹æ¡ˆé—®é¢˜æŠ¥å‘Š

**æ—¥æœŸ**: 2025-11-21  
**çŠ¶æ€**: ğŸ”´ å‘ç°ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ä¿®å¤

---

## é—®é¢˜æ¦‚è¿°

`export_marian_decoder_ir9.py` è„šæœ¬å¯¼å‡ºçš„ Decoder æ¨¡å‹**ç¼ºå°‘ KV cache æ”¯æŒ**ï¼Œæ— æ³•ä¸ç°æœ‰ä»£ç å…¼å®¹ã€‚

---

## è¯¦ç»†é—®é¢˜

### 1. Decoder è¾“å…¥ä¸åŒ¹é… âŒ

**è„šæœ¬å¯¼å‡º** (`export_marian_decoder_ir9.py:100`):
```python
input_names=["decoder_input_ids", "encoder_hidden_states", "encoder_attention_mask"]
# åªæœ‰ 3 ä¸ªè¾“å…¥
```

**ä»£ç æœŸæœ›** (`decoder.rs:161-208`):
```rust
// è¾“å…¥é¡ºåºï¼šencoder_attention_mask, input_ids, encoder_hidden_states, past_key_values.*, use_cache_branch
// æ€»å…± 28 ä¸ªè¾“å…¥ï¼š
//   1. encoder_attention_mask
//   2. input_ids
//   3. encoder_hidden_states
//   4-27. past_key_values.* (æ¯å±‚ 4 ä¸ªï¼šdec_k, dec_v, enc_k, enc_vï¼Œå…± 6 å±‚ = 24 ä¸ª)
//   28. use_cache_branch
```

**é—®é¢˜**:
- âŒ ç¼ºå°‘ 24 ä¸ª KV cache è¾“å…¥
- âŒ ç¼ºå°‘ `use_cache_branch` è¾“å…¥
- âŒ è¾“å…¥é¡ºåºä¸å¯¹

### 2. Decoder è¾“å‡ºä¸åŒ¹é… âŒ

**è„šæœ¬å¯¼å‡º** (`export_marian_decoder_ir9.py:101`):
```python
output_names=["logits"]
# åªæœ‰ 1 ä¸ªè¾“å‡º
```

**ä»£ç æœŸæœ›** (`decoder.rs:217-244`):
```rust
// è¾“å‡ºï¼š
//   1. logits
//   2-25. present.* (æ¯å±‚ 4 ä¸ªï¼šdec_k, dec_v, enc_k, enc_vï¼Œå…± 6 å±‚ = 24 ä¸ª)
// æ€»å…± 25 ä¸ªè¾“å‡º
```

**é—®é¢˜**:
- âŒ ç¼ºå°‘ 24 ä¸ª KV cache è¾“å‡º

### 3. ç°æœ‰æ¨¡å‹ç»“æ„å‚è€ƒ

**`marian-en-zh` æ¨¡å‹**ï¼ˆæ­£å¸¸å·¥ä½œï¼‰:
- âœ… 28 ä¸ªè¾“å…¥ï¼ˆåŒ…å«å®Œæ•´çš„ KV cacheï¼‰
- âœ… 25 ä¸ªè¾“å‡ºï¼ˆåŒ…å«å®Œæ•´çš„ KV cacheï¼‰
- âœ… æ”¯æŒå¢é‡è§£ç 

**æ£€æŸ¥å‘½ä»¤**:
```bash
python -c "import onnxruntime as ort; sess = ort.InferenceSession('core/engine/models/nmt/marian-en-zh/model.onnx'); print('Inputs:', len(sess.get_inputs())); print('Outputs:', len(sess.get_outputs()))"
```

**ç»“æœ**: 28 ä¸ªè¾“å…¥ï¼Œ25 ä¸ªè¾“å‡º

---

## ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä¿®æ”¹ `export_marian_decoder_ir9.py` â­ æ¨è

**å‚è€ƒ**: `scripts/export_marian_onnx.py` çš„ `export_decoder_with_past` å‡½æ•°

**éœ€è¦ä¿®æ”¹**:

1. **æ·»åŠ  KV cache è¾“å…¥**:
   ```python
   # ä¸ºæ¯å±‚åˆ›å»º past_key_values
   past_key_values = []
   for _ in range(num_layers):  # 6 å±‚
       past_key_values.append((
           torch.zeros(batch_size, num_heads, past_decoder_seq_len, head_dim),  # decoder key
           torch.zeros(batch_size, num_heads, past_decoder_seq_len, head_dim),  # decoder value
           torch.zeros(batch_size, num_heads, encoder_seq_len, head_dim),  # encoder key
           torch.zeros(batch_size, num_heads, encoder_seq_len, head_dim),  # encoder value
       ))
   ```

2. **æ·»åŠ  use_cache_branch è¾“å…¥**:
   ```python
   dummy_use_cache = torch.tensor([True], dtype=torch.bool)
   ```

3. **ä¿®æ­£è¾“å…¥é¡ºåº**:
   ```python
   inputs = [encoder_attention_mask, decoder_input_ids, encoder_hidden_states]
   for layer_kv in past_key_values:
       inputs.extend(layer_kv)
   inputs.append(dummy_use_cache)
   ```

4. **æ·»åŠ è¾“å…¥åç§°**:
   ```python
   input_names = ["encoder_attention_mask", "input_ids", "encoder_hidden_states"]
   for i in range(num_layers):
       input_names.extend([
           f"past_key_values.{i}.decoder.key",
           f"past_key_values.{i}.decoder.value",
           f"past_key_values.{i}.encoder.key",
           f"past_key_values.{i}.encoder.value",
       ])
   input_names.append("use_cache_branch")
   ```

5. **æ·»åŠ è¾“å‡ºåç§°**:
   ```python
   output_names = ["logits"]
   for i in range(num_layers):
       output_names.extend([
           f"present.{i}.decoder.key",
           f"present.{i}.decoder.value",
           f"present.{i}.encoder.key",
           f"present.{i}.encoder.value",
       ])
   ```

6. **ä¿®æ”¹ Wrapper ç±»**:
   - éœ€è¦å¤„ç† KV cache è¾“å…¥
   - éœ€è¦è¿”å› KV cache è¾“å‡º
   - å‚è€ƒ `scripts/export_marian_onnx.py` çš„ `DecoderWrapper`

7. **ä½¿ç”¨ opset_version=12**:
   ```python
   opset_version=12,  # è€Œä¸æ˜¯ 14
   ```

### æ–¹æ¡ˆ 2: ä¿®æ”¹ç°æœ‰è„šæœ¬

**ä¿®æ”¹ `scripts/export_marian_onnx.py`**:
- å°† `opset_version=14` æ”¹ä¸º `opset_version=12`
- åœ¨ Python 3.10 + PyTorch 1.13.1 ç¯å¢ƒä¸­è¿è¡Œ

**ä¼˜ç‚¹**:
- âœ… è„šæœ¬å·²ç»æ”¯æŒ KV cache
- âœ… åªéœ€è¦ä¿®æ”¹ opset ç‰ˆæœ¬

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦ç¡®ä¿åœ¨æ—§ç‰ˆæœ¬ PyTorch ç¯å¢ƒä¸­è¿è¡Œ

---

## ä¿®å¤åçš„éªŒè¯

### 1. æ£€æŸ¥æ¨¡å‹ç»“æ„

```bash
python -c "
import onnxruntime as ort
sess = ort.InferenceSession('core/engine/models/nmt/marian-zh-en/model.onnx')
print('Inputs:', len(sess.get_inputs()))
print('Outputs:', len(sess.get_outputs()))
print('Input names:', [i.name for i in sess.get_inputs()])
print('Output names:', [o.name for o in sess.get_outputs()])
"
```

**æœŸæœ›ç»“æœ**:
- 28 ä¸ªè¾“å…¥
- 25 ä¸ªè¾“å‡º
- è¾“å…¥åç§°ä¸ä»£ç æœŸæœ›åŒ¹é…

### 2. æ£€æŸ¥ IR ç‰ˆæœ¬

```bash
python -c "import onnx; m = onnx.load('core/engine/models/nmt/marian-zh-en/model.onnx'); print(f'IR: {m.ir_version}, Opset: {m.opset_import[0].version}')"
```

**æœŸæœ›ç»“æœ**:
- IR â‰¤ 9
- Opset = 12

### 3. æµ‹è¯•åŠ è½½

```bash
cargo run --example test_s2s_full_simple -- test_output/s2s_flow_test.wav
```

---

## æ€»ç»“

### å½“å‰çŠ¶æ€

- âœ… Encoder å¯¼å‡ºè„šæœ¬ï¼šæ­£ç¡®
- âŒ Decoder å¯¼å‡ºè„šæœ¬ï¼š**ç¼ºå°‘ KV cache æ”¯æŒï¼Œæ— æ³•ä½¿ç”¨**

### å¿…é¡»ä¿®å¤

1. **æ·»åŠ  KV cache è¾“å…¥**ï¼ˆ24 ä¸ªï¼‰
2. **æ·»åŠ  use_cache_branch è¾“å…¥**ï¼ˆ1 ä¸ªï¼‰
3. **æ·»åŠ  KV cache è¾“å‡º**ï¼ˆ24 ä¸ªï¼‰
4. **ä¿®æ­£è¾“å…¥é¡ºåº**
5. **ä½¿ç”¨ opset_version=12**

### æ¨èæ–¹æ¡ˆ

**ä¿®æ”¹ `export_marian_decoder_ir9.py`**ï¼Œå‚è€ƒ `scripts/export_marian_onnx.py` çš„ `export_decoder_with_past` å‡½æ•°ï¼Œä½†ä½¿ç”¨ `opset_version=12`ã€‚

---

**æœ€åæ›´æ–°**: 2025-11-21  
**çŠ¶æ€**: ğŸ”´ Decoder å¯¼å‡ºè„šæœ¬éœ€è¦ä¿®å¤æ‰èƒ½ä½¿ç”¨


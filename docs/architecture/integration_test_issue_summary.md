# 集成测试问题总结报告

**状态**: ✅ **已修复并测试通过**  
**修复日期**: 2025-11-21

## 概要

在最近的 NMT + TTS
集成测试中发现：**生成的音频吐字清晰，但完全无法分辨语言**。经过验证模型结构、KV
Cache、输入输出签名以及执行日志，最终确认：**问题并非出在模型本身，而是集成测试流程的设计使用了错误的文本与错误的模型方向**。

本报告总结根因与修复建议。**所有问题已修复，集成测试已通过**。

------------------------------------------------------------------------

## 1. 根因总览（关键结论）

### ✅ 模型本身无崩溃、无结构错误

-   Decoder ONNX 输入数量、顺序、KV Cache 全部正确\
-   Encoder/Decoder KV shape 与模型 signature 匹配\
-   模型推理正常返回 logits

### ❌ 集成测试流程使用了错误的文本

在 TTS 阶段，脚本使用了：

    source_text （ASR 英文输出）

而不是：

    target_text （NMT 翻译输出）

导致：\
- TTS 用中文声库（Piper CN）念一段英文 → 产生"像外星语"的声音\
- 虽然吐字清晰，但语言类别完全不对

### ❌ NMT 使用的模型方向也不对

-   当前路径：`marian-zh-en`（中文→英文）\
-   实际 ASR 输入：英文\
-   导致 NMT 将英文当成"乱码中文"处理\
    → 输出重复、无意义的英文句子（如 *"I'm gonna get you out of
    here..."*）\
-   但这些错误输出并未被送入 TTS

------------------------------------------------------------------------

## 2. 关键日志证据

### 2.1 TTS 阶段实际使用了 `source_text`

日志显示：

    送进 Piper TTS 的文本:
    "Hello welcome. Hello welcome to the video..."

而不是：

    target_text （翻译后的内容）

### 2.2 模型路径为 zh→en

    core/engine/models/nmt/marian-zh-en/model.onnx

### 2.3 ASR 输入语言为英文

    Hello welcome...

构成方向错误：

> **英文语音 → 英文文本 → (丢给中→英模型) → 但 TTS 仍然读英文源文本**

------------------------------------------------------------------------

## 3. 问题为何会造成"听不出语言"

原因组合如下：

  ---------------------------------------------------------------------------
  流程阶段                  使用内容                     问题
  ------------------------- ---------------------------- --------------------
  ASR                       英文文本                     正常

  NMT                       中文→英文模型                ❌ 输入语言方向错误
                                                         → 模型输出无意义

  TTS                       中文声库 + 原始英文文本      ❌
                                                         中文声音念英文文本 →
                                                         听起来像未知语言
  ---------------------------------------------------------------------------

这正是你反馈的现象：

> **"吐字清晰，但是不知道在讲什么语言"**

因为它确实不是正常中文或正常英文。

------------------------------------------------------------------------

## 4. 需开发部门立即修改的内容

### ✔ 修改 1：TTS 输入应使用翻译结果（target_text）

把现有逻辑：

``` rust
tts_input = source_text;
```

改为：

``` rust
tts_input = target_text;
```

### ✔ 修改 2：根据任务选择正确的 NMT 模型

如果流程是 **英文 → 中文**：

  阶段   配置
  ------ ------------------
  ASR    英文音频
  NMT    **marian-en-zh**
  TTS    中文 Piper 声库

如果流程是 **中文 → 英文**：

  阶段   配置
  ------ --------------------
  ASR    中文音频
  NMT    **marian-zh-en**
  TTS    英文 TTS（如 MMS）

### ✔ 修改 3：允许 example 通过命令行参数选择方向

建议为 `test_s2s_full_simple.rs` 添加参数：

    --direction en-zh
    --direction zh-en

自动选择：

-   模型路径\
-   TTS 声库\
-   文本流向

避免未来再出现方向错配。

------------------------------------------------------------------------

## 5. 建议的最终版 pipeline（以英文→中文为例）

    英文语音 → Whisper ASR → 英文文本 (source_text)
    英文文本 → marian-en-zh → 中文文本 (target_text)
    中文文本 → Piper CN → 中文音频

------------------------------------------------------------------------

## 6. 总结

当前问题不是模型问题，也不是推理框架的问题，而是：

### ❗ 集成测试示例使用了错误的文本和错误方向的模型

### ❗ TTS 阶段应使用 target_text 而非 source_text

### ❗ NMT 模型方向必须与 ASR 输出语言一致

只需调整 example 即可立即修复。

------------------------------------------------------------------------

## 7. 修复完成状态 ✅

### ✅ 所有问题已修复

1. **TTS 输入修复**: 已修改为使用 `target_text`
2. **NMT 模型方向修复**: 已添加 `--direction` 参数支持
3. **配置自动匹配**: 已实现 `TranslationDirection` 枚举统一管理

### ✅ 测试通过

- 完整 S2S 流程测试已通过
- 支持 `en-zh` 和 `zh-en` 双向翻译
- 所有模块正常工作

### 📝 相关文档

- 测试通过报告: `docs/architecture/S2S_INTEGRATION_TEST_PASSED.md`
- 测试脚本: `core/engine/examples/test_s2s_full_simple.rs`

------------------------------------------------------------------------

**最后更新**: 2025-11-21  
**状态**: ✅ **已修复并测试通过**

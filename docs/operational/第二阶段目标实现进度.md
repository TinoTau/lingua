# 第二阶段目标实现进度

## 一、已完成功能 ✅

### 1. VAD 接口扩展（为自然停顿识别优化预留接口）✅

**实现内容**：
- 扩展 `DetectionOutcome` 添加 `boundary_type` 字段
- 添加 `BoundaryType` 枚举（NaturalPause, ForcedCutoff, TimeBased, Other）
- 在 `VoiceActivityDetector` trait 中添加 `reset()` 和 `get_info()` 方法
- 更新 `TimeBasedVad` 实现新接口

**文件**：
- `core/engine/src/vad/mod.rs`
- `core/engine/src/vad/time_based_vad.rs`

**预留接口**：
- `boundary_type` 字段可用于区分自然停顿和强制截断
- `reset()` 方法可用于流式处理中的状态重置
- `get_info()` 方法可用于调试和监控

### 2. TranslationResponse 扩展（添加 speaker_id）✅

**实现内容**：
- 在 `TranslationResponse` 中添加 `speaker_id: Option<String>` 字段
- 在 `TranslationRequest` 中添加 `speaker_id: Option<String>` 字段
- 更新所有创建 `TranslationResponse` 的地方传递 `speaker_id`
- 在 `translate_and_publish` 方法中从 `StableTranscript` 传递 `speaker_id`

**文件**：
- `core/engine/src/nmt_incremental/types.rs`
- `core/engine/src/nmt_incremental/m2m100_translation.rs`
- `core/engine/src/nmt_client/adapter.rs`
- `core/engine/src/nmt_incremental/translation.rs`
- `core/engine/src/nmt_incremental/stub.rs`
- `core/engine/src/bootstrap.rs`

### 3. SpeakerVoiceMapper 实现 ✅

**实现内容**：
- 创建 `SpeakerVoiceMapper` 结构体
- 实现用户 ID 到 Voice ID 的映射
- 支持轮询方式分配 voice（当用户数量超过可用 voice 数量时）
- 提供 `assign_voice()`, `get_voice()`, `get_or_assign_voice()`, `set_voice()`, `clear()` 方法
- 完整的单元测试

**文件**：
- `core/engine/src/speaker_voice_mapper.rs`

### 4. TTS 多说话者音色区分集成 ✅

**实现内容**：
- 在 `CoreEngine` 和 `CoreEngineBuilder` 中添加 `speaker_voice_mapper` 字段
- 添加 `with_speaker_voice_mapping()` 配置方法
- 在 `synthesize_and_publish()` 方法中根据 `speaker_id` 选择 voice
- 如果未配置 mapper 或没有 speaker_id，使用默认 voice（向后兼容）

**文件**：
- `core/engine/src/bootstrap.rs`
- `core/engine/src/lib.rs`

**使用示例**：
```rust
let engine = CoreEngineBuilder::new()
    // ... 其他配置 ...
    .with_speaker_voice_mapping(vec![
        "zh_CN-huayan-medium".to_string(),  // 用户1
        "zh_CN-xiaoyan-medium".to_string(), // 用户2
        "en_US-lessac-medium".to_string(),  // 用户3
    ])
    .build()?;
```

## 二、待完成功能 ⏳

### 1. 缓冲区重叠机制（0.5-1秒）⏳

**需求**：第二阶段目标要求每段保留前 0.5-1 秒上下文，保证截断点不丢信息

**实现计划**：
- 修改 `AudioBufferManager` 的 `take_current_buffer()` 方法
- 在提交缓冲区时保留最后 0.5-1 秒的音频
- 将保留的音频添加到下一个缓冲区

**文件**：
- `core/engine/src/audio_buffer.rs`

### 2. 段落合并后处理（同一说话者）⏳

**需求**：第二阶段目标要求同一说话者连续段落合并，插话段落独立显示

**实现计划**：
- 创建 `SegmentMerger` 模块
- 跟踪每个说话者的段落历史
- 如果当前段落的 `speaker_id` 与前一个相同，合并文本
- 如果不同，独立显示

**文件**：
- `core/engine/src/segment_merger.rs`（新建）

### 3. Speaker Embedding 模块 ⏳

**需求**：第二阶段目标要求实现 Speaker Embedding 模块，用于区分不同用户

**实现计划**：
- 选择模型（x-vector / d-vector）
- 实现 speaker embedding 提取
- 实现说话者识别和聚类
- 集成到处理流程

**文件**：
- `core/engine/src/speaker_embedding/`（新建目录）

## 三、接口预留说明

### 1. VAD 接口预留

**已预留的接口**：
- `boundary_type: Option<BoundaryType>` - 可用于区分自然停顿和强制截断
- `reset()` 方法 - 可用于流式处理中的状态重置
- `get_info()` 方法 - 可用于调试和监控

**后续扩展**：
- 实现 `SileroVad` 时，设置 `boundary_type = Some(BoundaryType::NaturalPause)`
- 实现动态缓冲 VAD 时，可以根据策略设置不同的 `boundary_type`

### 2. 动态缓冲接口预留

**当前状态**：
- `AudioBufferManager` 已实现双缓冲机制
- `max_buffer_duration_ms` 和 `min_segment_duration_ms` 可配置
- 可以轻松扩展为动态缓冲策略

**后续扩展**：
- 添加 `short_sentence_threshold_ms` 配置
- 实现基于时间的短句/长句判断
- 实现动态策略切换逻辑

## 四、测试建议

### 1. 单元测试

- ✅ `SpeakerVoiceMapper` 已有完整单元测试
- ⏳ `AudioBufferManager` 需要添加重叠机制测试
- ⏳ `SegmentMerger` 需要添加合并逻辑测试

### 2. 集成测试

- ⏳ 测试多说话者场景（不同 speaker_id 使用不同 voice）
- ⏳ 测试缓冲区重叠机制
- ⏳ 测试段落合并功能

## 五、使用示例

### 启用 TTS 多说话者音色区分

```rust
use core_engine::{CoreEngineBuilder, TimeBasedVad};

let engine = CoreEngineBuilder::new()
    .vad(Arc::new(TimeBasedVad::new(3000)))  // 3秒间隔
    .with_continuous_mode(true, 5000, 200)   // 连续模式
    .with_speaker_voice_mapping(vec![
        "zh_CN-huayan-medium".to_string(),
        "zh_CN-xiaoyan-medium".to_string(),
        "en_US-lessac-medium".to_string(),
    ])
    .build()?;
```

### 后续扩展（自然停顿识别）

```rust
// 当实现 SileroVad 后，可以这样使用：
use core_engine::vad::SileroVad;

let vad = Arc::new(SileroVad::new("path/to/silero_vad.onnx")?);
let engine = CoreEngineBuilder::new()
    .vad(vad)  // 使用 Silero VAD 进行自然停顿识别
    // ... 其他配置 ...
    .build()?;
```

## 六、总结

### 已完成 ✅
1. VAD 接口扩展（为自然停顿识别优化预留接口）
2. TranslationResponse 扩展（添加 speaker_id）
3. SpeakerVoiceMapper 实现
4. TTS 多说话者音色区分集成

### 待完成 ⏳
1. 缓冲区重叠机制
2. 段落合并后处理
3. Speaker Embedding 模块

### 接口预留 ✅
- VAD 接口已为自然停顿识别优化预留好接口
- 动态缓冲接口可以通过扩展 `AudioBufferManager` 实现

### 下一步
1. 实现缓冲区重叠机制
2. 实现段落合并后处理
3. 实现 Speaker Embedding 模块（第二阶段核心功能）


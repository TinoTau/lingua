# TTS GPU æ”¹é€ æ–¹æ¡ˆ

**æœ€åæ›´æ–°**: 2025-01-XX

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•å°† TTS æœåŠ¡æ”¹é€ ä¸ºä½¿ç”¨ GPU åŠ é€Ÿã€‚

---

## ğŸ“Š å½“å‰çŠ¶æ€

### å½“å‰å®ç°
- **TTS å¼•æ“**: Piper TTS
- **æ¨¡å‹æ ¼å¼**: ONNX
- **è¿è¡Œç¯å¢ƒ**: WSL2 (Linux)
- **æ‰§è¡Œæ–¹å¼**: é€šè¿‡å‘½ä»¤è¡Œå·¥å…· `piper` è°ƒç”¨ ONNX Runtime
- **GPU æ”¯æŒ**: âŒ æœªå¯ç”¨ï¼ˆä½¿ç”¨ CPUï¼‰

### æ€§èƒ½ç°çŠ¶
- **CPU æ¨¡å¼**: çº¦ 200-500msï¼ˆå–å†³äºæ–‡æœ¬é•¿åº¦ï¼‰
- **é¢„æœŸ GPU æ¨¡å¼**: çº¦ 50-150ms
- **é¢„æœŸæå‡**: çº¦ 3-4 å€

---

## ğŸ¯ æ”¹é€ æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ ONNX Runtime CUDA æ‰§è¡Œæä¾›ç¨‹åºï¼ˆæ¨èï¼‰â­

**ä¼˜åŠ¿**ï¼š
- âœ… æ— éœ€ä¿®æ”¹æ¨¡å‹ï¼ˆç»§ç»­ä½¿ç”¨ç°æœ‰ ONNX æ¨¡å‹ï¼‰
- âœ… æ”¹åŠ¨æœ€å°ï¼ˆåªéœ€å®‰è£… ONNX Runtime GPU ç‰ˆæœ¬ï¼‰
- âœ… å…¼å®¹æ€§å¥½ï¼ˆPiper åŸç”Ÿæ”¯æŒï¼‰
- âœ… æ€§èƒ½æå‡æ˜æ˜¾

**æ­¥éª¤**ï¼š

#### 1. åœ¨ WSL2 ä¸­å®‰è£… CUDA Toolkit

```bash
# åœ¨ WSL2 ä¸­å®‰è£… CUDA Toolkit 12.4
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-4

# éªŒè¯å®‰è£…
nvcc --version
```

#### 2. å®‰è£… ONNX Runtime GPU ç‰ˆæœ¬

```bash
# è¿›å…¥ Piper è™šæ‹Ÿç¯å¢ƒ
cd ~/piper_env
source .venv/bin/activate

# å¸è½½ CPU ç‰ˆæœ¬çš„ onnxruntimeï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
pip uninstall onnxruntime -y

# å®‰è£… GPU ç‰ˆæœ¬çš„ onnxruntime
pip install onnxruntime-gpu

# éªŒè¯å®‰è£…
python -c "import onnxruntime as ort; print('Available providers:', ort.get_available_providers())"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Available providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']
```

#### 3. é…ç½® Piper ä½¿ç”¨ GPU

Piper é»˜è®¤ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å¯ç”¨çš„æ‰§è¡Œæä¾›ç¨‹åºã€‚å¦‚æœ ONNX Runtime GPU ç‰ˆæœ¬å·²å®‰è£…ï¼ŒPiper ä¼šè‡ªåŠ¨ä½¿ç”¨ CUDAã€‚

**éªŒè¯æ–¹æ³•**ï¼š

```bash
# æµ‹è¯• Piper æ˜¯å¦ä½¿ç”¨ GPU
piper --model ~/piper_models/zh/zh_CN-huayan-medium/zh_CN-huayan-medium.onnx \
      --input_file test.txt \
      --output_file test.wav \
      --verbose
```

æŸ¥çœ‹è¾“å‡ºä¸­æ˜¯å¦æœ‰ CUDA ç›¸å…³ä¿¡æ¯ã€‚

#### 4. ä¿®æ”¹ HTTP æœåŠ¡è„šæœ¬ï¼ˆå¯é€‰ï¼šæ·»åŠ  GPU æ£€æµ‹ï¼‰

ä¿®æ”¹ `scripts/wsl2_piper/piper_http_server.py`ï¼Œæ·»åŠ  GPU æ£€æµ‹å’Œæ—¥å¿—ï¼š

```python
import onnxruntime as ort

# åœ¨å¯åŠ¨æ—¶æ£€æŸ¥å¯ç”¨çš„æ‰§è¡Œæä¾›ç¨‹åº
available_providers = ort.get_available_providers()
if 'CUDAExecutionProvider' in available_providers:
    print("[INFO] âœ“ ONNX Runtime GPU support available (CUDA)")
    print(f"[INFO] Available providers: {available_providers}")
else:
    print("[WARN] âš  ONNX Runtime GPU support not available, using CPU")
    print(f"[INFO] Available providers: {available_providers}")
```

#### 5. éªŒè¯ GPU ä½¿ç”¨

```bash
# åœ¨ WSL2 ä¸­ç›‘æ§ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯å‘é€ TTS è¯·æ±‚
curl -X POST http://127.0.0.1:5005/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "æµ‹è¯•GPUåŠ é€Ÿ", "voice": "zh_CN-huayan-medium"}'
```

å¦‚æœçœ‹åˆ° GPU ä½¿ç”¨ç‡ä¸Šå‡ï¼Œè¯´æ˜ GPU åŠ é€Ÿå·²å¯ç”¨ã€‚

---

### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ PyTorch ç‰ˆæœ¬çš„ TTS æ¨¡å‹

**ä¼˜åŠ¿**ï¼š
- âœ… æ›´å¥½çš„ GPU æ”¯æŒ
- âœ… å¯ä»¥ä½¿ç”¨æ›´å…ˆè¿›çš„æ¨¡å‹ï¼ˆVITSã€FastSpeech2 ç­‰ï¼‰
- âœ… æ›´çµæ´»çš„æ¨¡å‹å®šåˆ¶

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦é‡æ–°è®­ç»ƒæˆ–è½¬æ¢æ¨¡å‹
- âŒ æ”¹åŠ¨è¾ƒå¤§
- âŒ éœ€è¦æ›´å¤šå¼€å‘å·¥ä½œ

**å¦‚æœé€‰æ‹©æ­¤æ–¹æ¡ˆ**ï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **ä½¿ç”¨ Coqui TTS**ï¼ˆæ”¯æŒ GPUï¼‰ï¼š
   ```bash
   pip install TTS
   # ä½¿ç”¨ GPU ç‰ˆæœ¬çš„ PyTorch
   ```

2. **ä½¿ç”¨ ESPnet TTS**ï¼ˆæ”¯æŒ GPUï¼‰ï¼š
   ```bash
   pip install espnet
   ```

3. **ä½¿ç”¨ VITS æ¨¡å‹**ï¼ˆå·²åœ¨ä»£ç ä¸­ï¼Œä½†æœªå¯ç”¨ï¼‰ï¼š
   - ä»£ç ä¸­å·²æœ‰ `VitsTtsEngine` å®ç°
   - éœ€è¦é…ç½®æ¨¡å‹è·¯å¾„å’Œ GPU æ”¯æŒ

---

## ğŸ”§ æ¨èå®æ–½æ–¹æ¡ˆ

### é˜¶æ®µ 1ï¼šå¿«é€Ÿå¯ç”¨ GPUï¼ˆæ–¹æ¡ˆ 1ï¼‰

**ç›®æ ‡**ï¼šæœ€å°æ”¹åŠ¨ï¼Œå¿«é€Ÿå¯ç”¨ GPU åŠ é€Ÿ

**æ­¥éª¤**ï¼š
1. âœ… åœ¨ WSL2 ä¸­å®‰è£… CUDA Toolkit
2. âœ… å®‰è£… `onnxruntime-gpu`
3. âœ… éªŒè¯ Piper è‡ªåŠ¨ä½¿ç”¨ GPU
4. âœ… æµ‹è¯•æ€§èƒ½æå‡

**é¢„è®¡æ—¶é—´**ï¼š1-2 å°æ—¶

### é˜¶æ®µ 2ï¼šä¼˜åŒ–å’Œç›‘æ§ï¼ˆå¯é€‰ï¼‰

**ç›®æ ‡**ï¼šæ·»åŠ  GPU ç›‘æ§å’Œæ€§èƒ½ä¼˜åŒ–

**æ­¥éª¤**ï¼š
1. æ·»åŠ  GPU ä½¿ç”¨ç‡ç›‘æ§
2. æ·»åŠ æ€§èƒ½æ—¥å¿—
3. ä¼˜åŒ–æ‰¹å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰

---

## ğŸ“ è¯¦ç»†å®æ–½æ­¥éª¤

### æ­¥éª¤ 1ï¼šæ£€æŸ¥ WSL2 CUDA æ”¯æŒ

```bash
# åœ¨ WSL2 ä¸­æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# å¦‚æœå‘½ä»¤ä¸å­˜åœ¨ï¼Œéœ€è¦å®‰è£… NVIDIA é©±åŠ¨ï¼ˆåœ¨ Windows ä¸»æœºä¸Šï¼‰
# ç¡®ä¿ Windows ä¸Šå·²å®‰è£… NVIDIA é©±åŠ¨ï¼ˆç‰ˆæœ¬ >= 470.76ï¼‰
```

### æ­¥éª¤ 2ï¼šå®‰è£… CUDA Toolkitï¼ˆWSL2ï¼‰

```bash
# æ·»åŠ  NVIDIA CUDA ä»“åº“
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update

# å®‰è£… CUDA Toolkit 12.4
sudo apt-get -y install cuda-toolkit-12-4

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæ·»åŠ åˆ° ~/.bashrcï¼‰
echo 'export PATH=/usr/local/cuda-12.4/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# éªŒè¯å®‰è£…
nvcc --version
```

### æ­¥éª¤ 3ï¼šå®‰è£… ONNX Runtime GPU

```bash
# è¿›å…¥ Piper è™šæ‹Ÿç¯å¢ƒ
cd ~/piper_env
source .venv/bin/activate

# æ£€æŸ¥å½“å‰ onnxruntime ç‰ˆæœ¬
pip show onnxruntime

# å¸è½½ CPU ç‰ˆæœ¬
pip uninstall onnxruntime -y

# å®‰è£… GPU ç‰ˆæœ¬ï¼ˆç¡®ä¿ CUDA ç‰ˆæœ¬åŒ¹é…ï¼‰
# CUDA 12.4 å¯ä»¥ä½¿ç”¨ onnxruntime-gpuï¼ˆé€šå¸¸æ”¯æŒ CUDA 11.x å’Œ 12.xï¼‰
pip install onnxruntime-gpu

# éªŒè¯å®‰è£…
python -c "import onnxruntime as ort; print('Providers:', ort.get_available_providers())"
```

**æ³¨æ„**ï¼šå¦‚æœé‡åˆ°ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå¯ä»¥å°è¯•ï¼š

```bash
# å®‰è£…ç‰¹å®šç‰ˆæœ¬çš„ onnxruntime-gpu
pip install onnxruntime-gpu==1.16.0
```

### æ­¥éª¤ 4ï¼šéªŒè¯ GPU ä½¿ç”¨

```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨ Python è„šæœ¬æµ‹è¯•
python << EOF
import onnxruntime as ort
import numpy as np

# æ£€æŸ¥å¯ç”¨æä¾›ç¨‹åº
providers = ort.get_available_providers()
print("Available providers:", providers)

if 'CUDAExecutionProvider' in providers:
    print("âœ“ GPU support is available!")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•ä¼šè¯
    # æ³¨æ„ï¼šè¿™éœ€è¦å®é™…çš„ ONNX æ¨¡å‹æ–‡ä»¶
    # è¿™é‡Œåªæ˜¯æ£€æŸ¥æä¾›ç¨‹åºæ˜¯å¦å¯ç”¨
else:
    print("âœ— GPU support is not available")
EOF

# æ–¹æ³• 2ï¼šä½¿ç”¨ Piper å‘½ä»¤è¡Œæµ‹è¯•
echo "æµ‹è¯•æ–‡æœ¬" > test.txt
piper --model ~/piper_models/zh/zh_CN-huayan-medium/zh_CN-huayan-medium.onnx \
      --input_file test.txt \
      --output_file test.wav \
      --verbose 2>&1 | grep -i cuda
```

### æ­¥éª¤ 5ï¼šä¿®æ”¹ HTTP æœåŠ¡æ·»åŠ  GPU æ£€æµ‹

ä¿®æ”¹ `scripts/wsl2_piper/piper_http_server.py`ï¼š

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
try:
    import onnxruntime as ort
    ORT_AVAILABLE = True
except ImportError:
    ORT_AVAILABLE = False

# åœ¨ main() å‡½æ•°ä¸­æ·»åŠ  GPU æ£€æµ‹
def main():
    # ... ç°æœ‰ä»£ç  ...
    
    # æ£€æŸ¥ GPU æ”¯æŒ
    if ORT_AVAILABLE:
        providers = ort.get_available_providers()
        if 'CUDAExecutionProvider' in providers:
            print(f"[INFO] âœ“ GPU support enabled (CUDA)")
            print(f"[INFO] Available providers: {providers}")
        else:
            print(f"[WARN] âš  GPU support not available, using CPU")
            print(f"[INFO] Available providers: {providers}")
    else:
        print("[WARN] âš  onnxruntime not available, cannot check GPU support")
    
    # ... ç»§ç»­ç°æœ‰ä»£ç  ...
```

### æ­¥éª¤ 6ï¼šé‡å¯æœåŠ¡å¹¶æµ‹è¯•

```bash
# åœæ­¢ç°æœ‰æœåŠ¡
pkill -f piper_http_server

# é‡æ–°å¯åŠ¨æœåŠ¡
cd ~/piper_env
source .venv/bin/activate
python /path/to/piper_http_server.py --host 0.0.0.0 --port 5005

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—ï¼Œåº”è¯¥çœ‹åˆ° GPU æ”¯æŒä¿¡æ¯
```

### æ­¥éª¤ 7ï¼šæ€§èƒ½æµ‹è¯•

```bash
# æµ‹è¯• TTS è¯·æ±‚
time curl -X POST http://127.0.0.1:5005/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯GPUåŠ é€Ÿæ•ˆæœã€‚", "voice": "zh_CN-huayan-medium"}' \
  -o test_output.wav

# å¯¹æ¯” CPU å’Œ GPU æ¨¡å¼çš„æ€§èƒ½
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼š`CUDAExecutionProvider` ä¸å¯ç”¨æˆ–åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯ 1**ï¼š
```
Failed to load library libonnxruntime_providers_cuda.so with error: 
libcublasLt.so.12: cannot open shared object file: No such file or directory
```

**é”™è¯¯ä¿¡æ¯ 2**ï¼š
```
Failed to load library libonnxruntime_providers_cuda.so with error: 
libcudnn.so.9: cannot open shared object file: No such file or directory
```

**å¯èƒ½åŸå› **ï¼š
1. CUDA è¿è¡Œæ—¶åº“æœªå®‰è£…ï¼ˆWSL2 ä¸­éœ€è¦å•ç‹¬å®‰è£…ï¼‰
2. cuDNN 9.* æœªå®‰è£…ï¼ˆONNX Runtime è¦æ±‚ cuDNN 9.* å’Œ CUDA 12.*ï¼‰
3. CUDA åº“è·¯å¾„æœªæ­£ç¡®è®¾ç½®
4. CUDA ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ³•**ï¼š

**æ–¹æ³• 1ï¼šå®‰è£… CUDA è¿è¡Œæ—¶åº“ï¼ˆæ¨èï¼‰**

```bash
# åœ¨ WSL2 ä¸­å®‰è£… CUDA è¿è¡Œæ—¶åº“
sudo apt-get update
sudo apt-get install -y cuda-toolkit-12-4

# è®¾ç½®åº“è·¯å¾„
export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH

# æ°¸ä¹…è®¾ç½®ï¼ˆæ·»åŠ åˆ° ~/.bashrcï¼‰
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

**æ–¹æ³• 2ï¼šä½¿ç”¨ Windows ä¸»æœºçš„ CUDA åº“ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰**

```bash
# æŸ¥æ‰¾ Windows ä¸­çš„ CUDA åº“
# CUDA é€šå¸¸å®‰è£…åœ¨ C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin

# åœ¨ WSL2 ä¸­åˆ›å»ºç¬¦å·é“¾æ¥æˆ–è®¾ç½®è·¯å¾„
# æ³¨æ„ï¼šWSL2 å¯ä»¥ç›´æ¥è®¿é—® Windows æ–‡ä»¶ç³»ç»Ÿï¼Œä½†åº“æ–‡ä»¶å¯èƒ½éœ€è¦å¤åˆ¶åˆ° WSL2
```

**æ–¹æ³• 3ï¼šå®‰è£… CUDA è¿è¡Œæ—¶åº“å’Œ cuDNN 9ï¼ˆæ¨èï¼‰**

**æ­¥éª¤ 1ï¼šå®‰è£… CUDA è¿è¡Œæ—¶åº“**

```bash
sudo apt-get update
sudo apt-get install -y cuda-runtime-12-4 cuda-libraries-12-4
```

**æ­¥éª¤ 2ï¼šä¸‹è½½ cuDNN 9**

ONNX Runtime è¦æ±‚ cuDNN 9.*ï¼Œä½† Ubuntu ä»“åº“é€šå¸¸åªæœ‰ 8.xï¼Œéœ€è¦ä» NVIDIA å®˜ç½‘æ‰‹åŠ¨ä¸‹è½½ï¼š

âš ï¸ **é‡è¦ï¼šç‰ˆæœ¬åŒ¹é…è¦æ±‚**
- **CUDA 12.4** åº”ä½¿ç”¨ **cuDNN 9.1.1 for CUDA 12.4**
- ä¸è¦ä½¿ç”¨ cuDNN 9.12 for CUDA 12.9ï¼ˆç‰ˆæœ¬ä¸åŒ¹é…å¯èƒ½å¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€æ€§èƒ½ä¸‹é™æˆ–è¿è¡Œæ—¶é”™è¯¯ï¼‰

**ä¸‹è½½æ–¹å¼ Aï¼šä¸‹è½½ Linux ç‰ˆæœ¬**

ä¸‹è½½æ­¥éª¤ï¼š
1. è®¿é—® https://developer.nvidia.com/cudnn
2. æ³¨å†Œ/ç™»å½• NVIDIA å¼€å‘è€…è´¦å·ï¼ˆå…è´¹ï¼‰
3. ä¸‹è½½ **cuDNN 9.1.1 for CUDA 12.4** (Linux x86_64)
   - é€šå¸¸æä¾› `.deb` æ ¼å¼ï¼ˆUbuntu/Debianï¼‰æˆ– `.rpm` æ ¼å¼ï¼ˆRedHat/CentOSï¼‰
   - æ–‡ä»¶åæ ¼å¼ï¼š`cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb`ï¼ˆUbuntu 22.04ï¼‰
   - âš ï¸ æ³¨æ„ï¼šå¿…é¡»é€‰æ‹© **CUDA 12.4** ç‰ˆæœ¬ï¼Œä¸è¦é€‰æ‹© 12.9 æˆ–å…¶ä»–ç‰ˆæœ¬
   - ğŸ“Œ **Ubuntu ç‰ˆæœ¬è¯´æ˜**ï¼šè™½ç„¶åŒ…æ˜¯ä¸º Ubuntu 22.04 è®¾è®¡çš„ï¼Œä½†å¯ä»¥åœ¨ Ubuntu 24.04 ä¸Šå®‰è£…ã€‚å¦‚æœé‡åˆ°ä¾èµ–é—®é¢˜ï¼Œå®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨å°è¯•ä» `.deb` åŒ…ä¸­æå–æ–‡ä»¶ã€‚

**ä¸‹è½½æ–¹å¼ Bï¼šä½¿ç”¨ Windows å®‰è£…çš„ cuDNNï¼ˆä¸æ¨èï¼‰**

âš ï¸ **æ³¨æ„**ï¼šWindows ç‰ˆæœ¬çš„ cuDNN åŒ…å«çš„æ˜¯ `.dll` æ–‡ä»¶ï¼Œæ— æ³•åœ¨ WSL2ï¼ˆLinuxï¼‰ä¸­ä½¿ç”¨ã€‚WSL2 å¿…é¡»ä½¿ç”¨ Linux ç‰ˆæœ¬çš„ cuDNNï¼ˆ`.so` æ–‡ä»¶ï¼‰ã€‚

å¦‚æœæ‚¨åœ¨ Windows ä¸Šå®‰è£…äº† cuDNNï¼Œåªèƒ½å¤åˆ¶å¤´æ–‡ä»¶ï¼Œä½†åº“æ–‡ä»¶æ— æ³•ä½¿ç”¨ã€‚**å¼ºçƒˆå»ºè®®ä¸‹è½½ Linux ç‰ˆæœ¬çš„ cuDNN**ã€‚

å¦‚æœç¡®å®éœ€è¦ä» Windows è·¯å¾„å¤åˆ¶ï¼ˆä»…å¤´æ–‡ä»¶ï¼‰ï¼Œè¯¦ç»†æ­¥éª¤è¯·å‚è€ƒï¼š`scripts/wsl2_piper/å®‰è£…cuDNN_ä»Windowsè·¯å¾„.md`

**æ­¥éª¤ 3ï¼šå®‰è£… cuDNN 9**

**æ–¹æ³• Aï¼šä½¿ç”¨ .deb åŒ…å®‰è£…ï¼ˆæ¨èï¼‰**

å¦‚æœæ‚¨ä¸‹è½½çš„æ˜¯ `.deb` æ ¼å¼çš„æœ¬åœ°ä»“åº“åŒ…ï¼ˆä¾‹å¦‚ï¼š`cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb`ï¼‰ï¼š

âš ï¸ **æ³¨æ„**ï¼š
- `.deb` åŒ…ä¸èƒ½åœ¨ Windows ä¸­å®‰è£…ï¼Œå¿…é¡»åœ¨ WSL2 çš„ Ubuntu ç¯å¢ƒä¸­å®‰è£…
- æ­¤åŒ…æ˜¯ä¸º Ubuntu 22.04 è®¾è®¡çš„ï¼Œåœ¨ Ubuntu 24.04 ä¸Šå¯èƒ½é‡åˆ°ä¾èµ–é—®é¢˜
- å¦‚æœæ ‡å‡†å®‰è£…å¤±è´¥ï¼Œå®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨å°è¯•ä» `.deb` åŒ…ä¸­æå–æ–‡ä»¶

```bash
# å°†ä¸‹è½½çš„ .deb æ–‡ä»¶æ”¾åˆ°è„šæœ¬ç›®å½•
cd /mnt/d/Programs/github/lingua/scripts/wsl2_piper
# å°†ä¸‹è½½çš„ cudnn-local-repo-ubuntu*.deb æ–‡ä»¶å¤åˆ¶åˆ°è¿™é‡Œ

# è¿è¡Œ .deb å®‰è£…è„šæœ¬
bash install_cudnn9_deb.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. å°è¯•é€šè¿‡ apt å®‰è£…ï¼ˆå¦‚æœå…¼å®¹ï¼‰
2. å¦‚æœå¤±è´¥ï¼Œè‡ªåŠ¨ä» .deb åŒ…ä¸­æå–æ–‡ä»¶å¹¶å®‰è£…

æˆ–è€…æ‰‹åŠ¨å®‰è£…ï¼š

```bash
# å®‰è£… .deb åŒ…ï¼ˆè®¾ç½®æœ¬åœ°ä»“åº“ï¼‰
sudo dpkg -i cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb

# å¦‚æœå‡ºç°ä¾èµ–é”™è¯¯ï¼Œä¿®å¤ä¾èµ–
sudo apt-get install -f -y

# æ›´æ–° apt ä»“åº“
sudo apt-get update

# å®‰è£… cuDNN åº“ï¼ˆå°è¯•å¤šä¸ªå¯èƒ½çš„åŒ…åï¼‰
sudo apt-get install -y libcudnn9 || sudo apt-get install -y libcudnn9-cuda-12

# å®‰è£…å¼€å‘æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
sudo apt-get install -y libcudnn9-dev || sudo apt-get install -y libcudnn9-dev-cuda-12

# æ›´æ–°åº“ç¼“å­˜
sudo ldconfig
```

**å¦‚æœæ ‡å‡†å®‰è£…å¤±è´¥ï¼Œå¯ä»¥ä» .deb åŒ…ä¸­æå–æ–‡ä»¶**ï¼š

```bash
# å®‰è£…å¿…è¦çš„å·¥å…·
sudo apt-get install -y binutils

# åˆ›å»ºä¸´æ—¶ç›®å½•
TEMP_DIR=$(mktemp -d)
cd "$TEMP_DIR"

# æå– .deb åŒ…
ar x /path/to/cudnn-local-repo-ubuntu2204-9.1.1_1.0-1_amd64.deb

# æå–æ•°æ®æ–‡ä»¶
tar -xf data.tar.xz  # æˆ– tar -xzf data.tar.gz

# æŸ¥æ‰¾å¹¶å¤åˆ¶æ–‡ä»¶åˆ° CUDA ç›®å½•
find . -name "cudnn*.h" -exec sudo cp {} /usr/local/cuda-12.4/include/ \;
find . -name "libcudnn.so*" -exec sudo cp {} /usr/local/cuda-12.4/lib64/ \;

# è®¾ç½®æƒé™
sudo chmod a+r /usr/local/cuda-12.4/include/cudnn*.h
sudo chmod a+r /usr/local/cuda-12.4/lib64/libcudnn*

# åˆ›å»ºç¬¦å·é“¾æ¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
cd /usr/local/cuda-12.4/lib64
sudo ln -s libcudnn.so.9.1.1 libcudnn.so.9 2>/dev/null || true

# æ›´æ–°åº“ç¼“å­˜
sudo ldconfig

# æ¸…ç†
cd -
rm -rf "$TEMP_DIR"
```

**æ–¹æ³• Bï¼šæ‰‹åŠ¨å®‰è£…**

```bash
# è§£å‹å¹¶å®‰è£…
cd ~/Downloads  # å‡è®¾ä¸‹è½½æ–‡ä»¶åœ¨è¿™é‡Œ
tar -xvf cudnn-linux-x86_64-9.1.1.*_cuda12.4-archive.tar.xz
cd cudnn-linux-x86_64-9.1.1.*_cuda12.4-archive

# å¤åˆ¶åº“æ–‡ä»¶åˆ° CUDA ç›®å½•
sudo cp include/cudnn*.h /usr/local/cuda-12.4/include
sudo cp lib/libcudnn* /usr/local/cuda-12.4/lib64
sudo chmod a+r /usr/local/cuda-12.4/include/cudnn*.h
sudo chmod a+r /usr/local/cuda-12.4/lib64/libcudnn*

# æ›´æ–°åŠ¨æ€é“¾æ¥å™¨ç¼“å­˜
sudo ldconfig
```

**æ­¥éª¤ 4ï¼šè®¾ç½®åº“è·¯å¾„**

```bash
# ä¸´æ—¶è®¾ç½®
export LD_LIBRARY_PATH=/usr/local/cuda-12.4/targets/x86_64-linux/lib:/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH

# æ°¸ä¹…è®¾ç½®ï¼ˆæ·»åŠ åˆ° ~/.bashrcï¼‰
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/targets/x86_64-linux/lib:/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

**æ–¹æ³• 4ï¼šå°è¯•ä» Ubuntu ä»“åº“å®‰è£…ï¼ˆå¦‚æœå¯ç”¨ï¼‰**

```bash
# æ£€æŸ¥æ˜¯å¦æœ‰ cuDNN 9 åŒ…
apt-cache search cudnn9

# å¦‚æœæœ‰ï¼Œå°è¯•å®‰è£…ï¼ˆä½†é€šå¸¸ Ubuntu ä»“åº“åªæœ‰ 8.xï¼‰
# sudo apt-get install -y libcudnn9-cuda-12  # å¦‚æœå­˜åœ¨
```

**éªŒè¯ä¿®å¤**ï¼š

```bash
# æ£€æŸ¥ CUDA åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ldconfig -p | grep cublas
ldconfig -p | grep cudnn

# æ£€æŸ¥ cuDNN ç‰ˆæœ¬ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
cat /usr/local/cuda-12.4/include/cudnn_version.h | grep CUDNN_MAJOR -A 2

# æµ‹è¯• ONNX Runtime
python -c "import onnxruntime as ort; print(ort.get_available_providers())"
# åº”è¯¥çœ‹åˆ° 'CUDAExecutionProvider' åœ¨åˆ—è¡¨ä¸­

# è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯ GPU ä½¿ç”¨
cd ~/piper_env
source .venv/bin/activate
python /mnt/d/Programs/github/lingua/scripts/wsl2_piper/test_piper_gpu.py
# åº”è¯¥çœ‹åˆ° "å®é™…ä½¿ç”¨çš„æ‰§è¡Œæä¾›ç¨‹åº: ['CUDAExecutionProvider', 'CPUExecutionProvider']"
```

### é—®é¢˜ 2ï¼šcuDNN ç‰ˆæœ¬ä¸åŒ¹é…

**é”™è¯¯ä¿¡æ¯**ï¼š
```
å®‰è£…æ—¶æç¤º cuDNN é€‚é… CUDA 12.9ï¼Œä½†ç³»ç»Ÿ CUDA ç‰ˆæœ¬æ˜¯ 12.4
```

**é—®é¢˜è¯´æ˜**ï¼š
- cuDNN ç‰ˆæœ¬å¿…é¡»ä¸ CUDA ç‰ˆæœ¬åŒ¹é…
- CUDA 12.4 åº”ä½¿ç”¨ cuDNN 9.1.1 for CUDA 12.4
- ä½¿ç”¨ä¸åŒ¹é…çš„ç‰ˆæœ¬å¯èƒ½å¯¼è‡´ï¼š
  - è¿è¡Œæ—¶é”™è¯¯æˆ–å´©æºƒ
  - æ€§èƒ½ä¸‹é™
  - åŠŸèƒ½å¼‚å¸¸

**è§£å†³æ–¹æ³•**ï¼š

1. **æ¨èï¼šä¸‹è½½åŒ¹é…çš„ç‰ˆæœ¬**
   - è®¿é—® https://developer.nvidia.com/cudnn
   - ä¸‹è½½ **cuDNN 9.1.1 for CUDA 12.4**ï¼ˆä¸æ˜¯ 12.9ï¼‰
   - é‡æ–°å®‰è£…

2. **å¦‚æœå·²å®‰è£…ä¸åŒ¹é…ç‰ˆæœ¬ï¼Œå¯ä»¥å°è¯•æµ‹è¯•å…¼å®¹æ€§**ï¼š
   ```bash
   # å®‰è£…åæµ‹è¯•
   python -c "import onnxruntime as ort; print(ort.get_available_providers())"
   
   # è¿è¡Œæµ‹è¯•è„šæœ¬
   python /mnt/d/Programs/github/lingua/scripts/wsl2_piper/test_piper_gpu.py
   
   # å¦‚æœå‡ºç°é”™è¯¯æˆ–æ€§èƒ½å¼‚å¸¸ï¼Œå»ºè®®å¸è½½å¹¶å®‰è£…åŒ¹é…ç‰ˆæœ¬
   ```

3. **å¸è½½å·²å®‰è£…çš„ cuDNN**ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼š
   ```bash
   sudo rm -f /usr/local/cuda-12.4/include/cudnn*.h
   sudo rm -f /usr/local/cuda-12.4/lib64/libcudnn*
   sudo ldconfig
   ```

### é—®é¢˜ 3ï¼šPiper ä»ç„¶ä½¿ç”¨ CPU

**å¯èƒ½åŸå› **ï¼š
1. ONNX Runtime æœªæ£€æµ‹åˆ° GPU
2. cuDNN ç‰ˆæœ¬ä¸åŒ¹é…å¯¼è‡´ CUDA æä¾›ç¨‹åºåŠ è½½å¤±è´¥
3. æ¨¡å‹æ–‡ä»¶è·¯å¾„é—®é¢˜

**è§£å†³æ–¹æ³•**ï¼š
```bash
# æ£€æŸ¥ ONNX Runtime æä¾›ç¨‹åº
python -c "import onnxruntime as ort; print(ort.get_available_providers())"

# å¦‚æœåªæœ‰ CPUï¼Œæ£€æŸ¥ CUDA åº“è·¯å¾„
ldconfig -p | grep cuda

# è®¾ç½® CUDA åº“è·¯å¾„
export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH
```

### é—®é¢˜ 4ï¼šæ€§èƒ½æå‡ä¸æ˜æ˜¾

**å¯èƒ½åŸå› **ï¼š
1. æ–‡æœ¬å¤ªçŸ­ï¼ŒGPU ä¼˜åŠ¿ä¸æ˜æ˜¾
2. æ¨¡å‹å¤ªå°ï¼ŒCPU å·²ç»è¶³å¤Ÿå¿«
3. æ•°æ®ä¼ è¾“å¼€é”€

**è§£å†³æ–¹æ³•**ï¼š
- æµ‹è¯•æ›´é•¿çš„æ–‡æœ¬ï¼ˆ> 100 å­—ç¬¦ï¼‰
- ä½¿ç”¨æ‰¹å¤„ç†ï¼ˆå¦‚æœæ”¯æŒï¼‰
- æ£€æŸ¥ GPU ä½¿ç”¨ç‡ï¼ˆ`nvidia-smi`ï¼‰

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### é¢„æœŸæ€§èƒ½æå‡

| æ–‡æœ¬é•¿åº¦ | CPU æ¨¡å¼ | GPU æ¨¡å¼ | æå‡ |
|---------|---------|---------|------|
| çŸ­æ–‡æœ¬ï¼ˆ< 50 å­—ç¬¦ï¼‰ | 200-300ms | 50-100ms | 2-3x |
| ä¸­ç­‰æ–‡æœ¬ï¼ˆ50-200 å­—ç¬¦ï¼‰ | 300-500ms | 100-150ms | 3-4x |
| é•¿æ–‡æœ¬ï¼ˆ> 200 å­—ç¬¦ï¼‰ | 500-800ms | 150-250ms | 3-4x |

### éªŒè¯æ–¹æ³•

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test_tts_perf.sh << 'EOF'
#!/bin/bash
TEXT="è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯TTSæœåŠ¡çš„GPUåŠ é€Ÿæ•ˆæœã€‚æˆ‘ä»¬å°†æµ‹è¯•ä¸åŒé•¿åº¦çš„æ–‡æœ¬ï¼Œä»¥è¯„ä¼°æ€§èƒ½æå‡ã€‚"
for i in {1..10}; do
    time curl -s -X POST http://127.0.0.1:5005/tts \
      -H "Content-Type: application/json" \
      -d "{\"text\": \"$TEXT\", \"voice\": \"zh_CN-huayan-medium\"}" \
      -o /dev/null
done
EOF

chmod +x test_tts_perf.sh
./test_tts_perf.sh
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ONNX Runtime GPU å®‰è£…æŒ‡å—](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html)
- [Piper TTS å®˜æ–¹æ–‡æ¡£](https://github.com/rhasspy/piper)
- [CUDA Toolkit å®‰è£…æŒ‡å—](./CUDA_Toolkit_å®‰è£…æŒ‡å—.md)
- [GPU æ”¹é€ è¿›åº¦æ€»ç»“](./GPUæ”¹é€ è¿›åº¦æ€»ç»“.md)

---

## âœ… æ£€æŸ¥æ¸…å•

### å‡†å¤‡é˜¶æ®µ
- [ ] WSL2 ä¸­å·²å®‰è£… NVIDIA é©±åŠ¨
- [ ] WSL2 ä¸­å·²å®‰è£… CUDA Toolkit 12.4
- [ ] éªŒè¯ `nvidia-smi` å¯ç”¨
- [ ] éªŒè¯ `nvcc --version` å¯ç”¨

### å®‰è£…é˜¶æ®µ
- [ ] å·²å¸è½½ CPU ç‰ˆæœ¬çš„ `onnxruntime`
- [ ] å·²å®‰è£… GPU ç‰ˆæœ¬çš„ `onnxruntime-gpu`
- [ ] éªŒè¯ `CUDAExecutionProvider` å¯ç”¨

### é…ç½®é˜¶æ®µ
- [ ] å·²ä¿®æ”¹ HTTP æœåŠ¡è„šæœ¬æ·»åŠ  GPU æ£€æµ‹
- [ ] å·²é‡å¯ TTS æœåŠ¡
- [ ] å¯åŠ¨æ—¥å¿—æ˜¾ç¤º GPU æ”¯æŒå·²å¯ç”¨

### éªŒè¯é˜¶æ®µ
- [ ] å‘é€ TTS è¯·æ±‚æ—¶ GPU ä½¿ç”¨ç‡ä¸Šå‡
- [ ] æ€§èƒ½æµ‹è¯•æ˜¾ç¤ºæ˜æ˜¾çš„æ€§èƒ½æå‡
- [ ] æœåŠ¡ç¨³å®šè¿è¡Œæ— é”™è¯¯

---

**æœ€åæ›´æ–°**: 2025-01-XX


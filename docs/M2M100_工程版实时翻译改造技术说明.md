# M2M100 工程版实时翻译改造技术说明

本文档详细说明如何将当前基于 Rust + ONNX 的 M2M100 翻译管线，迁移为 **Python 实时 NMT 服务 + Rust HTTP 客户端** 的工程实现方案。此方案可大幅提升翻译质量、稳定性，并减少对复杂 Decoder KV 逻辑的依赖，同时为未来迁移到云端翻译服务预留扩展能力。

---

## 1. 方案目标

### ✔ 解决现有主要问题
- Rust + ONNX M2M100 Decoder **输出不稳定 / 重复 token / 乱码**
- KV Cache、输入 shape、decoder 分支逻辑高度复杂
- HF 与 ONNX 推理 **无法对齐**

### ✔ 改造成可落地的工程方案
- Python + HF Transformers 运行 M2M100（稳定 + 高质量）
- Rust 侧不再管理 Decoder 逻辑，只通过 HTTP 请求交互
- 预留接入线上翻译 API 的接口（DeepL / 自建服务）

---

## 2. 目标架构

```
┌─────────────────────────┐
│      Whisper ASR (Rust) │
└─────────────┬───────────┘
              │ text
              ▼
┌─────────────┴───────────┐        HTTP POST /v1/translate
│  Rust Translation Client │ ──────────────────────────────►┌──────────────────────────────┐
│  - 统一 NMT 客户端接口   │                                 │ Python M2M100 NMT Service   │
│  - 可选本地 / 云端翻译   │◄───────────────────────────────┤ (HF generate + M2M100 模型)│
└─────────────┬───────────┘          返回翻译结果           └──────────────────────────────┘
              │ translated_text
              ▼
┌─────────────┴───────────┐
│       Piper TTS (Rust)   │
└──────────────────────────┘
```

---

## 3. Python NMT 服务接口规范（本地与未来云端统一）

### 请求示例
```
POST /v1/translate
```

```json
{
  "src_lang": "zh",
  "tgt_lang": "en",
  "text": "你好，欢迎参加测试。"
}
```

### 成功响应
```json
{
  "ok": true,
  "text": "Hello, welcome to the test.",
  "model": "facebook/m2m100_418M",
  "provider": "local-m2m100",
  "extra": { "elapsed_ms": 214, "num_tokens": 18 }
}
```

### 失败响应
```json
{
  "ok": false,
  "error": "Model not loaded",
  "provider": "local-m2m100"
}
```

---

## 4. Python M2M100 服务（可直接运行）

路径建议：`services/nmt_m2m100/nmt_service.py`

```python
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional, Dict, Any
import time
import torch
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

app = FastAPI()

MODEL_NAME = "facebook/m2m100_418M"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

tokenizer = M2M100Tokenizer.from_pretrained(MODEL_NAME)
model = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME)
model = model.to(DEVICE).eval()

class TranslateRequest(BaseModel):
    src_lang: str
    tgt_lang: str
    text: str

class TranslateResponse(BaseModel):
    ok: bool
    text: Optional[str] = None
    model: Optional[str] = None
    provider: str = "local-m2m100"
    extra: Optional[Dict[str, Any]] = None
    error: Optional[str] = None

@app.post("/v1/translate", response_model=TranslateResponse)
def translate(req: TranslateRequest) -> TranslateResponse:
    start = time.time()
    try:
        tokenizer.src_lang = req.src_lang
        encoded = tokenizer(req.text, return_tensors="pt").to(DEVICE)

        forced_bos = tokenizer.get_lang_id(req.tgt_lang)

        gen = model.generate(
            **encoded,
            forced_bos_token_id=forced_bos,
            num_beams=4,
            no_repeat_ngram_size=3,
            repetition_penalty=1.2,
            max_new_tokens=128,
        )

        out = tokenizer.decode(gen[0], skip_special_tokens=True)

        return TranslateResponse(
            ok=True,
            text=out,
            model=MODEL_NAME,
            extra={
                "elapsed_ms": int((time.time() - start) * 1000),
                "num_tokens": int(gen.shape[1])
            }
        )
    except Exception as e:
        return TranslateResponse(ok=False, error=str(e))
```

启动：

```
uvicorn nmt_service:app --host 127.0.0.1 --port 5008
```

---

## 5. Rust 端统一 NMT 客户端接口

路径：`core/engine/src/nmt_client/mod.rs`

```rust
use async_trait::async_trait;
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
pub struct NmtTranslateRequest {
    pub src_lang: String,
    pub tgt_lang: String,
    pub text: String,
}

#[derive(Serialize, Deserialize)]
pub struct NmtTranslateResponse {
    pub ok: bool,
    pub text: Option<String>,
    pub model: Option<String>,
    pub provider: Option<String>,
    pub error: Option<String>,
}

#[async_trait]
pub trait NmtClient {
    async fn translate(
        &self,
        req: &NmtTranslateRequest
    ) -> anyhow::Result<NmtTranslateResponse>;
}
```

---

## 6. 本地 Python 服务客户端（Rust 实现）

路径：`core/engine/src/nmt_client/local_m2m100.rs`

```rust
use super::*;
use async_trait::async_trait;

#[derive(Clone)]
pub struct LocalM2m100HttpClient {
    base_url: String,
    http: reqwest::Client,
}

impl LocalM2m100HttpClient {
    pub fn new(url: impl Into<String>) -> Self {
        Self {
            base_url: url.into(),
            http: reqwest::Client::new()
        }
    }
}

#[async_trait]
impl NmtClient for LocalM2m100HttpClient {
    async fn translate(
        &self,
        req: &NmtTranslateRequest
    ) -> anyhow::Result<NmtTranslateResponse> {

        let url = format!("{}/v1/translate", self.base_url);
        let res = self.http.post(url).json(req).send().await?;
        let body = res.json::<NmtTranslateResponse>().await?;
        Ok(body)
    }
}
```

---

## 7. 预留“线上翻译 API”客户端（未来扩展）

文件：`core/engine/src/nmt_client/remote.rs`

```rust
#[derive(Clone)]
pub struct RemoteNmtHttpClient {
    base_url: String,
    api_key: Option<String>,
    http: reqwest::Client,
}

#[async_trait]
impl NmtClient for RemoteNmtHttpClient {
    async fn translate(&self, req: &NmtTranslateRequest)
        -> anyhow::Result<NmtTranslateResponse> {

        let mut builder = self.http
            .post(format!("{}/v1/translate", self.base_url))
            .json(req);

        if let Some(key) = &self.api_key {
            builder = builder.header("Authorization", format!("Bearer {}", key));
        }

        let res = builder.send().await?;
        Ok(res.json::<NmtTranslateResponse>().await?)
    }
}
```

---

## 8. 在引擎中选择 NMT backend（本地 / 线上）

```rust
match config.nmt_backend {
    NmtBackend::Local => Box::new(LocalM2m100HttpClient::new("http://127.0.0.1:5008")),
    NmtBackend::Remote => Box::new(RemoteNmtHttpClient::new(
        config.remote_url, config.api_key)),
}
```

业务侧不需要修改。

---

## 9. 改造后的优势

### ✔ 翻译质量稳定（HF generate）  
### ✔ 延迟可控（通常 150–600ms）  
### ✔ 完全规避 ONNX + KV Cache 复杂度  
### ✔ 可无缝切换到云端翻译  
### ✔ Whisper → NMT → TTS 全链路清晰稳定  

---

## 10. 适合作为项目文档提交

本文件可直接交给开发部门或作为 COMP693/COMP627 项目技术文档的一部分。

